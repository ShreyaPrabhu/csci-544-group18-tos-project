{"cells":[{"cell_type":"markdown","metadata":{"id":"jmV9H6mqvWD9"},"source":["# Using XLNet Tokenizer and XLNet Model from Huggingface"]},{"cell_type":"markdown","metadata":{},"source":["Resources:\n","\n","- https://github.com/shanayghag/Sentiment-classification-using-XLNet/blob/master/Sentiment_Analysis_Series_part_1.ipynb\n","- https://medium.com/swlh/using-xlnet-for-sentiment-classification-cfa948e65e85\n","- https://stackoverflow.com/questions/70951556/how-to-get-pre-trained-xlnet-sentence-embeddings\n","- https://huggingface.co/xlnet-base-cased?text=My+name+is+Thomas+and+my+main\n","\n","\n","Next Steps:\n","\n","- Using XLNet Classification"]},{"cell_type":"markdown","metadata":{"id":"VxZbM6Hova5G"},"source":["# Aggregated Preprocessing Steps"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":450,"status":"ok","timestamp":1667269770868,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"mVEJFD3J5d0F"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6819,"status":"ok","timestamp":1667269777685,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"8z9-51v1vkfZ","outputId":"7d3a00af-d969-4802-894a-60c149fdc86e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: contractions in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (0.1.72)\n","Requirement already satisfied: textsearch>=0.0.21 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from contractions) (0.0.21)\n","Requirement already satisfied: pyahocorasick in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n","Requirement already satisfied: anyascii in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install contractions"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":681,"status":"ok","timestamp":1667269778359,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"nr-qJW_pvSwv"},"outputs":[],"source":["# Convert all reviews to lower case (optional according to study)\n","def to_lower(data: pd.Series):\n","    return data.str.lower()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1667269778360,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"55QDEpu44_l-"},"outputs":[],"source":["def remove_accented_characters(data: pd.Series):\n","    import unicodedata\n","\n","    \"\"\"Removes accented characters from the Series\n","\n","    Args:\n","        data (pd.Series): Series of string\n","\n","    Returns:\n","        _type_: pd.Series\n","    \"\"\"\n","    import unicodedata\n","\n","    return data.apply(lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\"))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667269778360,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"xgxvlVyH4_j4"},"outputs":[],"source":["def remove_html_encodings(data: pd.Series):\n","  return data.str.replace(r\"&#\\d+;\", \" \", regex=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778360,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"Jj_laKmv4_h0"},"outputs":[],"source":["def remove_html_tags(data: pd.Series):\n","  return data.str.replace(r\"<[a-zA-Z]+\\s?/?>\", \" \", regex=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667269778361,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"2SCBxfm54_fe"},"outputs":[],"source":["def remove_url(data: pd.Series):\n","  return data.str.replace(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \" \", regex=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778361,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"6k59XuMR4_dY"},"outputs":[],"source":["def remove_html_and_url(data: pd.Series):\n","    \"\"\"Function to remove\n","             1. HTML encodings\n","             2. HTML tags (both closed and open)\n","             3. URLs\n","\n","    Args:\n","        data (pd.Series): A Pandas series of type string\n","\n","    Returns:\n","        _type_: pd.Series\n","    \"\"\"\n","    # Remove HTML encodings\n","    data.str.replace(r\"&#\\d+;\", \" \", regex=True)\n","\n","    # Remove HTML tags (both open and closed)\n","    data.str.replace(r\"<[a-zA-Z]+\\s?/?>\", \" \", regex=True)\n","\n","    # Remove URLs\n","    data.str.replace(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \" \", regex=True)\n","\n","    return data\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778361,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"nAxCkw3Z4_bT"},"outputs":[],"source":["# Remove non-alphabetical characters\n","def remove_non_alpha_characters(data: pd.Series):\n","    return data.str.replace(r\"_+|\\\\|[^a-zA-Z0-9\\s]\", \" \", regex=True)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778362,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"oH9UdmFv5LFZ"},"outputs":[],"source":["# Remove extra spaces\n","def remove_extra_spaces(data: pd.Series):\n","    return data.str.replace(r\"^\\s*|\\s\\s*\", \" \", regex=True)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778362,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"ax3lfFii5LDV"},"outputs":[],"source":["# Expanding contractions\n","def fix_contractions(data: pd.Series):\n","    import contractions\n","\n","    def contraction_fixer(txt: str):\n","        return \" \".join([contractions.fix(word) for word in txt.split()])\n","\n","    return data.apply(contraction_fixer)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1667269778362,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"DvY0sG_X5LBN"},"outputs":[],"source":["# remove \"-lrb-\"\n","def remove_special_words(data: pd.Series):\n","  return data.str.replace(r\"\\-[^a-zA-Z]{3}\\-\", \" \", regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778363,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"MVJX0mwP5K_A"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778363,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"4crTpw3L4_ZN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778364,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"_PkNC2de4_XI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (0.1.97)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4108,"status":"ok","timestamp":1667269782462,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"VIX2JXAxviGT","outputId":"ba45a576-4871-457a-cf9c-dbc1e8a52df7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (4.24.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (0.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (0.10.1)\n","Requirement already satisfied: packaging>=20.0 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (2.28.1)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (2022.8.17)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (1.23.2)\n","Requirement already satisfied: filelock in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from requests->transformers) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"UtsBNBqGByOh"},"source":["### Load Data"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667269783589,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"c6kHIKwDw1H3"},"outputs":[],"source":["train_dataset_path = \"./data/tos_clauses_train.csv\"\n","test_dataset_path = \"./data/tos_clauses_dev.csv\""]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":508,"status":"ok","timestamp":1667269784093,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"6QspixPvxmPg"},"outputs":[],"source":["train_df = pd.read_csv(train_dataset_path, header=0)\n","test_df = pd.read_csv(test_dataset_path, header=0)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667269784094,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"mEBefSaI5vxl","outputId":"c999b389-8548-4271-b4bd-df15e80a0fdc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>sentences</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>content license and intellectual property rights</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>reactivated skype credit is not refundable .</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>spotify may change the price for the paid subs...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>the term of your licenses under this eula shal...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>the arbitrator may award declaratory or injunc...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                          sentences\n","0      0   content license and intellectual property rights\n","1      0       reactivated skype credit is not refundable .\n","2      1  spotify may change the price for the paid subs...\n","3      0  the term of your licenses under this eula shal...\n","4      0  the arbitrator may award declaratory or injunc..."]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"jCUaVzt5B3bl"},"source":["### Clean the Data"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24870,"status":"ok","timestamp":1667269808957,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"2jTvjwxN5q4k","outputId":"97b0fc2b-18a5-4685-9ff6-2effb2b6a2fb"},"outputs":[],"source":["# A dictionary containing the columns and a list of functions to perform on it in order\n","def cleaning(df):\n","  data_cleaning_pipeline = {\n","      \"sentences\": [\n","          to_lower,\n","          remove_special_words,\n","          remove_accented_characters,\n","          remove_html_encodings,\n","          remove_html_tags,\n","          remove_url,\n","          fix_contractions,\n","          remove_non_alpha_characters,\n","          remove_extra_spaces,\n","      ]\n","  }\n","\n","  cleaned_data = df.copy()\n","\n","  # Process all the cleaning instructions\n","  for col, pipeline in data_cleaning_pipeline.items():\n","      # Get the column to perform cleaning on\n","      temp_data = cleaned_data[col].copy()\n","\n","      # Perform all the cleaning functions sequencially\n","      for func in pipeline:\n","          print(f\"Starting: {func.__name__}\")\n","          temp_data = func(temp_data)\n","          print(f\"Ended: {func.__name__}\")\n","\n","      # Replace the old column with cleaned one.\n","      cleaned_data[col] = temp_data.copy()\n","\n","  return cleaned_data\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1667269808958,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"pPqnz5yVxn4_","outputId":"03140c2f-da0b-43d3-dfb7-6eaff9a7295e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting: to_lower\n","Ended: to_lower\n","Starting: remove_special_words\n","Ended: remove_special_words\n","Starting: remove_accented_characters\n","Ended: remove_accented_characters\n","Starting: remove_html_encodings\n","Ended: remove_html_encodings\n","Starting: remove_html_tags\n","Ended: remove_html_tags\n","Starting: remove_url\n","Ended: remove_url\n","Starting: fix_contractions\n","Ended: fix_contractions\n","Starting: remove_non_alpha_characters\n","Ended: remove_non_alpha_characters\n","Starting: remove_extra_spaces\n","Ended: remove_extra_spaces\n","Starting: to_lower\n","Ended: to_lower\n","Starting: remove_special_words\n","Ended: remove_special_words\n","Starting: remove_accented_characters\n","Ended: remove_accented_characters\n","Starting: remove_html_encodings\n","Ended: remove_html_encodings\n","Starting: remove_html_tags\n","Ended: remove_html_tags\n","Starting: remove_url\n","Ended: remove_url\n","Starting: fix_contractions\n","Ended: fix_contractions\n","Starting: remove_non_alpha_characters\n","Ended: remove_non_alpha_characters\n","Starting: remove_extra_spaces\n","Ended: remove_extra_spaces\n"]},{"data":{"text/plain":["(   label                                          sentences\n"," 0      0   content license and intellectual property rights\n"," 1      0        reactivated skype credit is not refundable \n"," 2      1   spotify may change the price for the paid sub...\n"," 3      0   the term of your licenses under this eula sha...\n"," 4      0   the arbitrator may award declaratory or injun...,\n","    label                                          sentences\n"," 0      0   uber reserves the right to withhold or deduct...\n"," 1      0   niantic s failure to enforce any right or pro...\n"," 2      0   14 3 if you feel that any member you interact...\n"," 3      0   blizzard entertainment has the right to obtai...\n"," 4      0   myfitnesspal does not lrb i rrb guarantee the...)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["train_df = cleaning(train_df)\n","test_df = cleaning(test_df)\n","\n","train_df.head(), test_df.head()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":868,"status":"ok","timestamp":1667269809815,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"RfwfN8nB6utM","outputId":"d2619bf2-a6dc-4106-c6f4-ed0b1f09921e"},"outputs":[{"data":{"text/plain":["' spotify may change the price for the paid subscriptions pre paid period lrb for periods not yet paid for rrb or codes from time to time and will communicate any price changes to you in advance and if applicable how to accept those changes '"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_df[\"sentences\"][2]"]},{"cell_type":"markdown","metadata":{"id":"sCcsbzgVB7Xb"},"source":["### Using XLNet Tokenizer and XLNet Model to get Embeddings"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2261,"status":"ok","timestamp":1667269812058,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"ipO7FNbD3fnz"},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import logging\n","import torch\n","import numpy as np\n","import warnings\n","from transformers import XLNetTokenizer, XLNetModel\n"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667269812058,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"3dwEs6Z44PS2"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Functions"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["cls = \"[CLS]\"\n","sep = \"[SEP]\"\n","pad = \"[PAD]\"\n","max_pad_length=512"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def create_tensors_XLNET(text):\n","  \"\"\"\n","    Tokenize using BERT Tokenizer for the pd.Series\n","  \"\"\"\n","  print(\"Tokenizing text...\")\n","  logging.basicConfig(level = logging.INFO)\n","\n","  # Load the `bert-base-uncased` model\n","  tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","\n","  # Tokenize every sentence in the pd.Series\n","  tokenized_text = [tokenizer.tokenize(x) for x in text]\n","\n","  # Pad the tokens to be used for BERT Model; BERT takes fixed lengend sequence\n","  tokenized_text = [x + ([pad] * (max_pad_length - len(x))) for x in tokenized_text]\n","\n","  # Convert the tokens to their IDs\n","  indexed_text = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n","\n","  # BERTModel has Q&A format, so setting the context to one for every sentence\n","  segment_ids = [[1] * len(x) for x in tokenized_text]\n","\n","  # Convert to tensor\n","  torch_idx_text = torch.LongTensor(indexed_text)\n","  torch_seg_ids = torch.LongTensor(segment_ids)\n","  \n","  return tokenized_text, torch_idx_text, torch_seg_ids "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["#takes in the index and segment tensors and returns the bert embeddings as a list\n","def get_embeddings(torch_idx_text, torch_seg_ids):\n","    \"\"\"\n","      Create BERT embeddings from tokens\n","    \"\"\"\n","    print(\"Getting Embeddings...\")\n","\n","    # Load pretrained `bert-base-uncased` model, and set to inference\n","    model = XLNetModel.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states = True)\n","    model.eval()\n","\n","    torch_idx_text, torch_seg_ids = torch_idx_text.to(\"cpu\"), torch_seg_ids.to(\"cpu\")\n","    model.to(device)\n","\n","    # Disable gradient and get BERT embeddings\n","    with torch.no_grad():\n","        bert_embeddings = []\n","        for i in range(len(torch_idx_text)):\n","            print(i, end = \"\\r\")\n","            text_temp = torch.unsqueeze(torch_idx_text[i], dim = 0).to(device)\n","            sgmt_temp = torch.unsqueeze(torch_seg_ids[i], dim = 0).to(device)\n","            output = model(text_temp, sgmt_temp)\n","            bert_embeddings.append(output[0])\n","            del text_temp, sgmt_temp\n","    del model\n","  \n","    return bert_embeddings\n"]},{"cell_type":"markdown","metadata":{"id":"l-47_yioCIYR"},"source":["### Tokenize and Create Embeddings"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenizing text...\n","Tokenizing text...\n"]}],"source":["train_tokenized_text, train_torch_idx_text, train_torch_seg_ids = create_tensors_XLNET(train_df.sentences)\n","test_tokenized_text, test_torch_idx_text, test_torch_seg_ids = create_tensors_XLNET(test_df.sentences)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Getting Embeddings...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Getting Embeddings...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["1882\r"]}],"source":["train_xlnet_embeddings = get_embeddings(train_torch_idx_text, train_torch_seg_ids)\n","test_xlnet_embeddings = get_embeddings(test_torch_idx_text, test_torch_seg_ids)\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["train_xlnet_embeddings = torch.cat(train_xlnet_embeddings)\n","test_xlnet_embeddings = torch.cat(test_xlnet_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle as pkl\n","train_embeddings_file_path = \"./embeddings/train_xlnet_embeddings.pkl\"\n","test_embeddings_file_path = \"./embeddings/test_xlnet_embeddings.pkl\"\n","\n","def save_embeddings(embeddings_file_path, embeddings):\n","  with open(embeddings_file_path, mode=\"wb\") as file:\n","    pkl.dump({\"embeddings\": embeddings}, file, protocol=pkl.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_embeddings(train_embeddings_file_path, train_xlnet_embeddings)\n","save_embeddings(test_embeddings_file_path, test_xlnet_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def get_tokens(txt: pd.Series, max_length):\n","    tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","    tokens = list()\n","\n","    for idx, document in enumerate(txt):\n","        print(idx, end = \"\\r\")\n","\n","        tokens.append(tokenizer.encode_plus(document, add_special_tokens=True, return_tensors='pt', max_length=max_pad_length, return_token_type_ids=False, return_attention_mask=True, padding=True, truncation=True))\n","\n","    return tokens\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1882\r"]}],"source":["train_tokenized_txt = get_tokens(train_df.sentences, max_pad_length)\n","test_tokenized_txt = get_tokens(test_df.sentences, max_pad_length)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def get_embeddings(tokenized_txt):\n","    embeddings = list()\n","\n","    model = XLNetModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","\n","    for idx, tokenized in enumerate(tokenized_txt):\n","        print(idx, end = \"\\r\")\n","\n","        outputs = model(**tokenized)\n","        embedding = outputs.last_hidden_state\n","        embeddings.append(embedding)\n","\n","        del outputs, embedding\n","\n","    return embeddings"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["869\r"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mCanceled future for execute_request message before replies were done"]}],"source":["train_xlnet_embeddings = get_embeddings(train_tokenized_txt)\n","test_xlnet_embeddings = get_embeddings(test_tokenized_txt)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["cls = \"[CLS]\"\n","sep = \"[SEP]\"\n","pad = \"[PAD]\""]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["import logging\n","import warnings"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def create_tensors_BERT(text):\n","  \"\"\"\n","    Tokenize using BERT Tokenizer for the pd.Series\n","  \"\"\"\n","  print(\"Tokenizing text...\")\n","  logging.basicConfig(level = logging.INFO)\n","\n","  # Load the `bert-base-uncased` model\n","  tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","\n","  # Tokenize every sentence in the pd.Series\n","  tokenized_text = [tokenizer.tokenize(x) for x in text]\n","\n","  # Pad the tokens to be used for BERT Model; BERT takes fixed lengend sequence\n","  tokenized_text = [x + ([pad] * (max_pad_length - len(x))) for x in tokenized_text]\n","\n","  # Convert the tokens to their IDs\n","  indexed_text = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n","\n","  # BERTModel has Q&A format, so setting the context to one for every sentence\n","  segment_ids = [[1] * len(x) for x in tokenized_text]\n","\n","  # Convert to tensor\n","  torch_idx_text = torch.LongTensor(indexed_text)\n","  torch_seg_ids = torch.LongTensor(segment_ids)\n","  \n","  return tokenized_text, torch_idx_text, torch_seg_ids "]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["#takes in the index and segment tensors and returns the bert embeddings as a list\n","def get_embeddings(torch_idx_text, torch_seg_ids):\n","    \"\"\"\n","      Create BERT embeddings from tokens\n","    \"\"\"\n","    print(\"Getting Embeddings...\")\n","\n","    # Load pretrained `bert-base-uncased` model, and set to inference\n","    model = XLNetModel.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states = True)\n","    model.eval()\n","\n","    torch_idx_text, torch_seg_ids = torch_idx_text.to(\"cpu\"), torch_seg_ids.to(\"cpu\")\n","    model.to(device)\n","\n","    # Disable gradient and get BERT embeddings\n","    with torch.no_grad():\n","        bert_embeddings = []\n","        for i in range(len(torch_idx_text)):\n","            print(i, end = \"\\r\")\n","            text_temp = torch.unsqueeze(torch_idx_text[i], dim = 0).to(device)\n","            sgmt_temp = torch.unsqueeze(torch_seg_ids[i], dim = 0).to(device)\n","            output = model(text_temp, sgmt_temp)\n","            bert_embeddings.append(output[0])\n","            del text_temp, sgmt_temp\n","    del model\n","  \n","    return bert_embeddings"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenizing text...\n","Tokenizing text...\n"]}],"source":["train_tokenized_text, train_torch_idx_text, train_torch_seg_ids = create_tensors_BERT(train_df.sentences)\n","test_tokenized_text, test_torch_idx_text, test_torch_seg_ids = create_tensors_BERT(test_df.sentences)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Getting Embeddings...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["247\r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb Cell 49\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_bert_embeddings \u001b[39m=\u001b[39m get_embeddings(train_torch_idx_text, train_torch_seg_ids)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb#X64sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_bert_embeddings \u001b[39m=\u001b[39m get_embeddings(test_torch_idx_text, test_torch_seg_ids)\n","\u001b[1;32m/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb Cell 49\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(torch_idx_text, torch_seg_ids)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb#X64sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m text_temp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(torch_idx_text[i], dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb#X64sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m sgmt_temp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(torch_seg_ids[i], dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb#X64sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m output \u001b[39m=\u001b[39m model(text_temp, sgmt_temp)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb#X64sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m bert_embeddings\u001b[39m.\u001b[39mappend(output[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/dataTwo/usc/CSCI_544_NLP_FINAL_PROJECT/input_feature_generation/creating_xlnet_embeddings.ipynb#X64sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdel\u001b[39;00m text_temp, sgmt_temp\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/transformers/models/xlnet/modeling_xlnet.py:1241\u001b[0m, in \u001b[0;36mXLNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m   1239\u001b[0m     hidden_states\u001b[39m.\u001b[39mappend((output_h, output_g) \u001b[39mif\u001b[39;00m output_g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m output_h)\n\u001b[0;32m-> 1241\u001b[0m outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1242\u001b[0m     output_h,\n\u001b[1;32m   1243\u001b[0m     output_g,\n\u001b[1;32m   1244\u001b[0m     attn_mask_h\u001b[39m=\u001b[39;49mnon_tgt_mask,\n\u001b[1;32m   1245\u001b[0m     attn_mask_g\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1246\u001b[0m     r\u001b[39m=\u001b[39;49mpos_emb,\n\u001b[1;32m   1247\u001b[0m     seg_mat\u001b[39m=\u001b[39;49mseg_mat,\n\u001b[1;32m   1248\u001b[0m     mems\u001b[39m=\u001b[39;49mmems[i],\n\u001b[1;32m   1249\u001b[0m     target_mapping\u001b[39m=\u001b[39;49mtarget_mapping,\n\u001b[1;32m   1250\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m   1251\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1252\u001b[0m )\n\u001b[1;32m   1253\u001b[0m output_h, output_g \u001b[39m=\u001b[39m outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m   1254\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/transformers/models/xlnet/modeling_xlnet.py:509\u001b[0m, in \u001b[0;36mXLNetLayer.forward\u001b[0;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    497\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    498\u001b[0m     output_h,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m ):\n\u001b[0;32m--> 509\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_attn(\n\u001b[1;32m    510\u001b[0m         output_h,\n\u001b[1;32m    511\u001b[0m         output_g,\n\u001b[1;32m    512\u001b[0m         attn_mask_h,\n\u001b[1;32m    513\u001b[0m         attn_mask_g,\n\u001b[1;32m    514\u001b[0m         r,\n\u001b[1;32m    515\u001b[0m         seg_mat,\n\u001b[1;32m    516\u001b[0m         mems\u001b[39m=\u001b[39;49mmems,\n\u001b[1;32m    517\u001b[0m         target_mapping\u001b[39m=\u001b[39;49mtarget_mapping,\n\u001b[1;32m    518\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    519\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[1;32m    521\u001b[0m     output_h, output_g \u001b[39m=\u001b[39m outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    523\u001b[0m     \u001b[39mif\u001b[39;00m output_g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/transformers/models/xlnet/modeling_xlnet.py:440\u001b[0m, in \u001b[0;36mXLNetRelativeAttention.forward\u001b[0;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    437\u001b[0m k_head_r \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mibh,hnd->ibnd\u001b[39m\u001b[39m\"\u001b[39m, r\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr\u001b[39m.\u001b[39mdtype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr)\n\u001b[1;32m    439\u001b[0m \u001b[39m# core attention ops\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m attn_vec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_attn_core(\n\u001b[1;32m    441\u001b[0m     q_head_h,\n\u001b[1;32m    442\u001b[0m     k_head_h,\n\u001b[1;32m    443\u001b[0m     v_head_h,\n\u001b[1;32m    444\u001b[0m     k_head_r,\n\u001b[1;32m    445\u001b[0m     seg_mat\u001b[39m=\u001b[39;49mseg_mat,\n\u001b[1;32m    446\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattn_mask_h,\n\u001b[1;32m    447\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    448\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    451\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    452\u001b[0m     attn_vec, attn_prob \u001b[39m=\u001b[39m attn_vec\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/transformers/models/xlnet/modeling_xlnet.py:309\u001b[0m, in \u001b[0;36mXLNetRelativeAttention.rel_attn_core\u001b[0;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    306\u001b[0m     attn_prob \u001b[39m=\u001b[39m attn_prob \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mijbn->bnij\u001b[39m\u001b[39m\"\u001b[39m, head_mask)\n\u001b[1;32m    308\u001b[0m \u001b[39m# attention output\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m attn_vec \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49meinsum(\u001b[39m\"\u001b[39;49m\u001b[39mbnij,jbnd->ibnd\u001b[39;49m\u001b[39m\"\u001b[39;49m, attn_prob, v_head_h)\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    312\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_vec, torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mbnij->ijbn\u001b[39m\u001b[39m\"\u001b[39m, attn_prob)\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/torch/functional.py:360\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[39m# recurse incase operands contains value that has torch function\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[39m# in the original implementation this line is omitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[39mreturn\u001b[39;00m einsum(equation, \u001b[39m*\u001b[39m_operands)\n\u001b[0;32m--> 360\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49meinsum(equation, operands)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_bert_embeddings = get_embeddings(train_torch_idx_text, train_torch_seg_ids)\n","test_bert_embeddings = get_embeddings(test_torch_idx_text, test_torch_seg_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOc+htn8Uy0hVIj5B2XsCMZ","collapsed_sections":[],"mount_file_id":"19OZi3COrM1wJnuYgifQAA5bZmnfbzuce","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.6 64-bit ('csci544')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e78917e7f90f3892e7e12462ef46781cf5994bd706032ea53be00d0b1f29dcb9"}}},"nbformat":4,"nbformat_minor":0}
