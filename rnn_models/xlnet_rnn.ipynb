{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VaNmVq3cLLJ6","executionInfo":{"status":"ok","timestamp":1669183002191,"user_tz":480,"elapsed":19081,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"bec79fa5-30cc-462f-f800-c3759f3419d4"},"id":"VaNmVq3cLLJ6","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xCB_14jKli2c"},"id":"xCB_14jKli2c","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"268d41ea","metadata":{"id":"268d41ea"},"outputs":[],"source":["# dependencies to run the notebook\n","\n","# !pip install torch==1.12.1\n","# !pip install torchmetrics==0.10.2\n","# !pip install torchvision==0.14.0\n","# !pip install texttable==1.6.4\n"]},{"cell_type":"markdown","id":"61dd939a","metadata":{"id":"61dd939a"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"3\">Download the below files from https://drive.google.com/drive/folders/1q50QMurzK9a5l4JBHWjf8VuWcZkbF7PM to run this notebook : <br>\n","1) train_bert_embeddings.pkl <br>\n","2) test_bert_embeddings.pkl <br> </font>\n","</span>\n"]},{"cell_type":"code","source":["!pip install pickle5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gML3CkPFLmNy","executionInfo":{"status":"ok","timestamp":1669183006130,"user_tz":480,"elapsed":3944,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"f9ae7278-98f5-40af-d754-d58d0e431363"},"id":"gML3CkPFLmNy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pickle5\n","  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n","\u001b[K     |████████████████████████████████| 256 kB 6.0 MB/s \n","\u001b[?25hInstalling collected packages: pickle5\n","Successfully installed pickle5-0.0.12\n"]}]},{"cell_type":"code","execution_count":null,"id":"0fef83eb","metadata":{"id":"0fef83eb"},"outputs":[],"source":["import pickle5 as pickle\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import warnings\n","import numpy as np\n","import torch.nn.functional as F\n","import pandas as pd\n","from sklearn.metrics import classification_report\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"code","execution_count":null,"id":"cf7a03ca","metadata":{"id":"cf7a03ca"},"outputs":[],"source":["EMBEDDINGS_NAME = \"xlnet\"\n"]},{"cell_type":"code","execution_count":null,"id":"e1167ffb","metadata":{"id":"e1167ffb"},"outputs":[],"source":["BASE_PATH = \"/content/drive/MyDrive/CSCI-544 Group 18/nlp_data\"\n","TRAIN_EMBEDDINGS = f\"{BASE_PATH}/embeddings/train_{EMBEDDINGS_NAME}_embeddings.pkl\"\n","TEST_EMBEDDINGS = f\"{BASE_PATH}/embeddings/test_{EMBEDDINGS_NAME}_embeddings.pkl\"\n","TRAIN_DATASET_PATH = f\"{BASE_PATH}/legal_bert/data/tos_clauses_train.csv\"\n","TEST_DATASET_PATH = f\"{BASE_PATH}/legal_bert/data/tos_clauses_dev.csv\"\n","RNN_MODEL_PATH = f\"{BASE_PATH}/models/rnn_{EMBEDDINGS_NAME}_model.pt\"\n","GRU_MODEL_PATH = f\"{BASE_PATH}/models/gru_{EMBEDDINGS_NAME}_model.pt\"\n","LSTM_MODEL_PATH = f\"{BASE_PATH}/models/lstm_{EMBEDDINGS_NAME}_model.pt\"\n","BILSTM_MODEL_PATH = f\"{BASE_PATH}/models/bilstm_{EMBEDDINGS_NAME}_model.pt\"\n"]},{"cell_type":"code","execution_count":null,"id":"4bf44010","metadata":{"id":"4bf44010"},"outputs":[],"source":["# Read train BERT embeddings\n","with open(TRAIN_EMBEDDINGS, \"rb\") as f:\n","    training_data = pickle.load(f)\n"]},{"cell_type":"code","execution_count":null,"id":"7e45b2ae","metadata":{"id":"7e45b2ae"},"outputs":[],"source":["# Read test BERT embeddings\n","with open(TEST_EMBEDDINGS, \"rb\") as f:\n","    testing_data = pickle.load(f)\n"]},{"cell_type":"code","execution_count":null,"id":"6c2bd91a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6c2bd91a","executionInfo":{"status":"ok","timestamp":1669183200003,"user_tz":480,"elapsed":22,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"ef581566-49b5-43e1-b46b-bf7f7ed6a5d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["The data is :  embeddings\n"]}],"source":["# check\n","for item in training_data:\n","    print(\"The data is : \", item)\n"]},{"cell_type":"code","execution_count":null,"id":"dca0767b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dca0767b","executionInfo":{"status":"ok","timestamp":1669183200004,"user_tz":480,"elapsed":6,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"720d15d1-44d9-4d8e-9a43-816d24e1f271"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7531, torch.Size([512, 768]))"]},"metadata":{},"execution_count":11}],"source":["len(training_data[\"embeddings\"]), training_data[\"embeddings\"][0].shape\n"]},{"cell_type":"markdown","id":"1481e82e","metadata":{"id":"1481e82e"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"4\">Get the labels from train and test files.</font>\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"7ec7097e","metadata":{"id":"7ec7097e"},"outputs":[],"source":["TRAIN_DATASET_PATH = f\"{BASE_PATH}/tos_clauses_train.csv\"\n","TEST_DATASET_PATH = f\"{BASE_PATH}/tos_clauses_dev.csv\"\n"]},{"cell_type":"code","execution_count":null,"id":"7feb1a37","metadata":{"id":"7feb1a37"},"outputs":[],"source":["train_df = pd.read_csv(TRAIN_DATASET_PATH, header=0)\n","test_df = pd.read_csv(TEST_DATASET_PATH, header=0)\n"]},{"cell_type":"code","execution_count":null,"id":"8a29d269","metadata":{"id":"8a29d269"},"outputs":[],"source":["train_targets = train_df.label.values\n","test_targets = test_df.label.values\n"]},{"cell_type":"code","execution_count":null,"id":"541edf2c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"541edf2c","executionInfo":{"status":"ok","timestamp":1669183200982,"user_tz":480,"elapsed":11,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"e71eef5a-f892-4421-de4c-e207296adb40"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 0, 1, 0])"]},"metadata":{},"execution_count":15}],"source":["test_targets\n"]},{"cell_type":"code","execution_count":null,"id":"0378fa66","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0378fa66","executionInfo":{"status":"ok","timestamp":1669183200982,"user_tz":480,"elapsed":9,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"301f3176-348f-49a1-f1cc-ba75c14aee29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using Device: cuda\n"]}],"source":["device = None\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","# elif torch.backends.mps.is_available():\n","#     device = torch.device(\"mps\")\n","else:\n","    device = torch.device(\"cpu\")\n","\n","print(f\"Using Device: {device}\")\n"]},{"cell_type":"markdown","id":"f92206a0","metadata":{"id":"f92206a0"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"4\">Create Dataset, Train and Test Classes</font>\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"efaf4ad4","metadata":{"id":"efaf4ad4"},"outputs":[],"source":["class Dataset(object):\n","    \"\"\"An abstract class representing a Dataset.\n","    All other datasets should subclass it. All subclasses should\n","    override ``__len__``, that provides the size of the dataset,\n","    and ``__getitem__``, supporting integer indexing in range\n","    from 0 to len(self) exclusive.\n","    \"\"\"\n","\n","    def __getitem__(self, index):\n","        raise NotImplementedError\n","\n","    def __len__(self):\n","        raise NotImplementedError\n","\n","    def __add__(self, other):\n","        return ConcatDataset([self, other])\n"]},{"cell_type":"code","execution_count":null,"id":"2bb78e49","metadata":{"id":"2bb78e49"},"outputs":[],"source":["class TOSDataset(Dataset):\n","    def __init__(self, X, Y, transform=None):\n","        self.data1 = X\n","        self.data2 = Y\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data1)\n","\n","    def __getitem__(self, index):\n","        x = self.data1[index]\n","        y = self.data2[index]\n","\n","        if self.transform is not None:\n","            x = torch.tensor(x)\n","\n","        return torch.squeeze(x, dim=1), torch.tensor(y)\n"]},{"cell_type":"code","execution_count":null,"id":"7d37e581","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7d37e581","executionInfo":{"status":"ok","timestamp":1669183225789,"user_tz":480,"elapsed":2,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"34535088-61c7-4e88-ab3c-ba23666aa363"},"outputs":[{"output_type":"stream","name":"stdout","text":["<torch.utils.data.sampler.SubsetRandomSampler object at 0x7fbefdd7f190>\n","train_fair:6705\n","train_unfair:826\n"]}],"source":["test_len = len(test_df)\n","train_len = len(train_df)\n","X_train_tensor = TOSDataset(train_df[\"sentences\"], train_df[\"label\"])\n","# X_test_tensor = Train_Model(test_df)\n","\n","num_train = len(X_train_tensor)\n","indices = list(range(num_train))\n","np.random.shuffle(indices)\n","# split = int(np.floor(num_train))\n","# train_idx = indices[split:]\n","\n","train_sampler = SubsetRandomSampler(indices)\n","# valid_sampler = SubsetRandomSampler(valid_idx)\n","print(train_sampler)\n","train_df_by_index = train_df.loc[indices]\n","# val_df_by_index = df_train.loc[valid_idx]\n","train_fair = sum(train_df_by_index[\"label\"] == 0)\n","train_unfair = sum(train_df_by_index[\"label\"] == 1)\n","# val_fair = sum(val_df_by_index['label'] == 0)\n","# val_unfair = sum(val_df_by_index['label'] == 1)\n","\n","print(\"train_fair:\" + str(train_fair))\n","print(\"train_unfair:\" + str(train_unfair))\n","# print(\"val_fair:\" + str(val_fair))\n","# print(\"val_unfair:\" + str(val_unfair))\n"]},{"cell_type":"code","execution_count":null,"id":"cca2a92d","metadata":{"id":"cca2a92d"},"outputs":[],"source":["train_data = TOSDataset(training_data[\"embeddings\"], train_targets, transform=transforms.ToTensor())\n","test_data = TOSDataset(testing_data[\"embeddings\"], test_targets, transform=transforms.ToTensor())\n"]},{"cell_type":"markdown","id":"046b7413","metadata":{"id":"046b7413"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"4\">Prepare Data loaders</font>\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"db13f108","metadata":{"id":"db13f108"},"outputs":[],"source":["# how many samples per batch to load\n","BATCH_SIZE = 20\n","\n","# number of subprocesses to use for data loading\n","NUM_WORKERS = 0\n"]},{"cell_type":"code","execution_count":null,"id":"14d9572e","metadata":{"id":"14d9572e"},"outputs":[],"source":["# prepare data loaders\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=NUM_WORKERS)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n"]},{"cell_type":"code","execution_count":null,"id":"36811bd1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36811bd1","executionInfo":{"status":"ok","timestamp":1669183241665,"user_tz":480,"elapsed":2,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"eea176ef-1f55-4a0f-8298-4950b1c2e71f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sample input size:  torch.Size([20, 512, 768])\n","\n","Sample label size:  torch.Size([20])\n"]}],"source":["# check sizes\n","dataiter = iter(train_loader)\n","sample_x, sample_y = dataiter.next()\n","\n","print(\"Sample input size: \", sample_x.size())  # batch_size, seq_length\n","# print(\"Sample input: \\n\", sample_x)\n","print()\n","print(\"Sample label size: \", sample_y.size())  # batch_size\n","# print(\"Sample label: \\n\", sample_y)\n"]},{"cell_type":"code","execution_count":null,"id":"b6f98c5b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6f98c5b","executionInfo":{"status":"ok","timestamp":1669183244009,"user_tz":480,"elapsed":7,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"a5c9ff80-22da-4152-c1f2-66f07fb4b080"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([20, 512, 768])"]},"metadata":{},"execution_count":28}],"source":["torch.squeeze(sample_x, dim=1).shape\n"]},{"cell_type":"markdown","id":"f4ccefed","metadata":{"id":"f4ccefed"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"5\">SIMPLE RNN</font><br>\n","<font size=\"2.5\">Number of hidden dimension : 20</font> <br>\n","<font size=\"2.5\">Number of layers: 1</font> <br>\n","<font size=\"2.5\">Number of epochs: 5</font> <br>\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"f35604d4","metadata":{"id":"f35604d4"},"outputs":[],"source":["class RNNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","\n","        super(RNNet, self).__init__()\n","\n","        # Number of hidden dimensions\n","        self.hidden_dim = hidden_dim\n","\n","        # RNN\n","        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=5, batch_first=True, nonlinearity=\"relu\")\n","\n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden state with zeros\n","        h0 = Variable(torch.zeros(5, x.size(0), self.hidden_dim)).to(device)\n","\n","        # One time step\n","        out, hn = self.rnn(x, h0)\n","        out = self.fc(out[:, -1, :])\n","        return out\n"]},{"cell_type":"code","execution_count":null,"id":"cc418eed","metadata":{"id":"cc418eed"},"outputs":[],"source":["# class RNNet(nn.Module):\n","#     def __init__(self, input_dim, hidden_dim, output_dim):\n","\n","#         super(RNNet, self).__init__()\n","\n","#         # Number of hidden dimensions\n","#         self.hidden_dim = hidden_dim\n","\n","#         # RNN\n","#         self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=2, batch_first=True, nonlinearity=\"relu\")\n","\n","#         self.fc_1 = nn.Linear(hidden_dim, 400)\n","\n","#         self.dropout = nn.Dropout(p=0.33)\n","\n","#         # Readout layer\n","#         self.out = nn.Linear(400, output_dim)\n","\n","#     def forward(self, x):\n","\n","#         # Initialize hidden state with zeros\n","#         h0 = Variable(torch.zeros(2, x.size(0), self.hidden_dim)).to(device)\n","\n","#         # One time step\n","#         rnn_out, hn = self.rnn(x, h0)\n","\n","#         fc_1_out = F.relu(self.fc_1(rnn_out[:, -1, :]))\n","\n","#         fc_1_out = self.dropout(fc_1_out)\n","\n","#         out = self.out(fc_1_out)\n","\n","#         return out\n"]},{"cell_type":"code","execution_count":null,"id":"c4a1f44b","metadata":{"id":"c4a1f44b"},"outputs":[],"source":["import time\n","\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs\n"]},{"cell_type":"code","execution_count":null,"id":"b69d3eef","metadata":{"id":"b69d3eef"},"outputs":[],"source":["EMBEDDING_DIM = 768\n","OUTPUT_DIM = 2\n"]},{"cell_type":"code","execution_count":null,"id":"d5c62989","metadata":{"id":"d5c62989"},"outputs":[],"source":["HIDDEN_DIM = 512\n","N_EPOCHS = 20\n"]},{"cell_type":"code","execution_count":null,"id":"acb233cc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acb233cc","executionInfo":{"status":"ok","timestamp":1669183251464,"user_tz":480,"elapsed":2,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"2408c9c6-76b1-47b6-b71b-6d64b20d6569"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.56159582, 4.55871671])"]},"metadata":{},"execution_count":34}],"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","class_weight = compute_class_weight(\n","    \"balanced\", classes=np.unique(train_df_by_index[\"label\"]), y=train_df_by_index[\"label\"]\n",")\n","class_weight\n"]},{"cell_type":"code","execution_count":null,"id":"53e1f120","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53e1f120","outputId":"89965717-48e3-4c05-d2a9-9323e6d5cd35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 0m 39s\n","\tTraining Loss: 0.035666 \\Test Loss: 0.034037\n","Test loss decreased (inf --> 0.034037). Saving model...\n","Epoch: 02 | Epoch Time: 0m 38s\n","\tTraining Loss: 80048359382797482356375552.000000 \\Test Loss: 204335091483009139649544192.000000\n","Epoch: 03 | Epoch Time: 0m 38s\n","\tTraining Loss: 202522704162449624743804928.000000 \\Test Loss: 204335091483009139649544192.000000\n"]}],"source":["model = RNNet(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n","model = model.to(device)\n","\n","loss_fn = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weight)).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","test_min_loss = np.inf\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    model.train()\n","    train_loss = 0.0\n","    test_loss = 0.0\n","    for inputs, target in train_loader:\n","        inputs, target = inputs.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        inputs = torch.squeeze(inputs, dim=1)\n","        output = model(inputs)\n","        loss = loss_fn(output, target)\n","        loss.backward()\n","        # do gradient clipping\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=4.0, norm_type=2)\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    model.eval()\n","    for inputs, target in test_loader:\n","        inputs, target = inputs.to(device), target.to(device)\n","        inputs = torch.squeeze(inputs, dim=1)\n","        output = model(inputs)\n","        loss = loss_fn(output, target)\n","        test_loss += loss.item()\n","\n","    train_loss = train_loss / len(train_loader.dataset)\n","    test_loss = test_loss / len(test_loader.dataset)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n","    print(\"\\tTraining Loss: {:.6f} \\Test Loss: {:.6f}\".format(train_loss, test_loss))\n","    if test_loss <= test_min_loss:\n","        print(\"Test loss decreased ({:.6f} --> {:.6f}). Saving model...\".format(test_min_loss, test_loss))\n","        torch.save(model.state_dict(), RNN_MODEL_PATH)\n","        test_min_loss = test_loss\n"]},{"cell_type":"code","execution_count":null,"id":"490b243d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"490b243d","executionInfo":{"status":"ok","timestamp":1669182326506,"user_tz":480,"elapsed":5468,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"}},"outputId":"deb9f7d3-0c1f-4416-c263-08b12294fde6"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.96      0.83      0.89      1677\n","           1       0.35      0.75      0.48       206\n","\n","    accuracy                           0.82      1883\n","   macro avg       0.66      0.79      0.69      1883\n","weighted avg       0.90      0.82      0.85      1883\n","\n"]}],"source":["y_pred_list = []\n","y_targ_list = []\n","model = RNNet(EMBEDDING_DIM, RNN_HIDDEN_DIM, OUTPUT_DIM).to(device)\n","model.load_state_dict(torch.load(RNN_MODEL_PATH))\n","model.eval()\n","\n","with torch.no_grad():\n","    for inputs, target in test_loader:\n","        inputs, target = inputs.to(device), target.to(device)\n","        inputs = torch.squeeze(inputs, dim=1)\n","        y_test_pred = model(inputs)\n","        _, y_test_pred = torch.max(y_test_pred, 1)\n","        y_pred_tag = y_test_pred\n","        y_pred_list.append(y_pred_tag.cpu().numpy())\n","        y_targ_list.append(target.cpu().numpy())\n","\n","y_pred_list = [x.squeeze().tolist() for x in y_pred_list]\n","y_targ_list = [x.squeeze().tolist() for x in y_targ_list]\n","y_pred_list = [x for sublist in y_pred_list for x in sublist]\n","y_targ_list = [x for sublist in y_targ_list for x in sublist]\n","\n","print(classification_report(y_targ_list, y_pred_list))\n"]},{"cell_type":"code","execution_count":null,"id":"5d4ffec6","metadata":{"id":"5d4ffec6"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"86d8b3a5","metadata":{"id":"86d8b3a5"},"source":["Accuracy of simple RNN : 0.7413701415061951\n","F1 score of simple RNN : 0.5635073184967041\n","Precision of simple RNN : 0.5633978843688965\n","Recall of simple RNN : 0.6227356195449829\n"]},{"cell_type":"markdown","id":"dfe86eec","metadata":{"id":"dfe86eec"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"5\">Gated RNN</font><br>\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"e40ad5f1","metadata":{"id":"e40ad5f1"},"outputs":[],"source":["class GRU_Network(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","\n","        super(GRU_Network, self).__init__()\n","\n","        # Number of hidden dimensions\n","        self.hidden_dim = hidden_dim\n","\n","        # RNN\n","        self.rnn = nn.GRU(input_dim, hidden_dim, num_layers=1, batch_first=True)\n","\n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden state with zeros\n","        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n","\n","        # One time step\n","        out, hn = self.rnn(x, h0)\n","        out = self.fc(out[:, -1, :])\n","        return out\n"]},{"cell_type":"code","execution_count":null,"id":"662cab0f","metadata":{"id":"662cab0f"},"outputs":[],"source":["GRU_HIDDEN_DIM = 512\n","GRU_N_EPOCHS = 6\n"]},{"cell_type":"code","execution_count":null,"id":"ace29e9a","metadata":{"id":"ace29e9a"},"outputs":[],"source":["model_gru = GRU_Network(EMBEDDING_DIM, GRU_HIDDEN_DIM, OUTPUT_DIM)\n","print(model_gru)\n"]},{"cell_type":"code","execution_count":null,"id":"cc5174a8","metadata":{"id":"cc5174a8"},"outputs":[],"source":["def train_GRU(model, train_loader, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in train_loader:\n","\n","        train = Variable(batch[0].view(-1, 512, 768))\n","        labels = Variable(batch[1])\n","\n","        optimizer.zero_grad()\n","\n","        output = model(train)\n","\n","        loss = criterion(output, labels)\n","\n","        acc = binary_accuracy(output.argmax(-1), labels)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n"]},{"cell_type":"code","execution_count":null,"id":"ec37270a","metadata":{"id":"ec37270a"},"outputs":[],"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float(\"inf\")\n","\n","criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1 / train_fair, 1 / train_unfair]))\n","# criterion = nn.NLLLoss()\n","\n","optimizer_gru = optim.Adam(model_gru.parameters(), lr=1e-4)\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    gru_train_loss, gru_train_acc = train_RNN(model_gru, train_loader, optimizer_gru, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n","    print(\n","        f\"\\tTrain Loss: \\\n","    {gru_train_loss:.3f} | Train Acc: {gru_train_acc*100:.2f}%\"\n","    )\n"]},{"cell_type":"code","execution_count":null,"id":"2d4fca45","metadata":{"id":"2d4fca45"},"outputs":[],"source":["test_loader_predict = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=0)\n","\n","\n","def predict(model, dataloader):\n","    prediction_list = []\n","    for i, batch in enumerate(dataloader):\n","        test = Variable(batch.view(-1, 512, 768))\n","        outputs = model(test)\n","        _, predicted = torch.max(outputs.data, 1)\n","        prediction_list.append(predicted.cpu())\n","    return prediction_list\n","\n","\n","predictions_gru = predict(model_gru, test_loader_predict)\n","\n","a_tensor = torch.IntTensor(predictions_gru)\n","b_tensor = torch.IntTensor(test_targets)\n","\n","accuracy = Accuracy()\n","gru_test_acc = accuracy(a_tensor, b_tensor).item()\n","\n","f1 = F1Score(num_classes=2, average=\"macro\")  # checked if weighted can be used\n","gru_f1_score = f1(a_tensor, b_tensor).item()\n","\n","precision = Precision(average=\"macro\", num_classes=2)\n","gru_precision = precision(a_tensor, b_tensor).item()\n","\n","recall = Recall(average=\"macro\", num_classes=2)\n","gru_recall = recall(a_tensor, b_tensor).item()\n","\n","print(\"Accuracy of Gated RNN :\", gru_test_acc)\n","print(\"F1 score of Gated RNN :\", gru_f1_score)\n","print(\"Precision of Gated RNN :\", gru_precision)\n","print(\"Recall of Gated RNN :\", gru_recall)\n"]},{"cell_type":"code","execution_count":null,"id":"32490444","metadata":{"id":"32490444"},"outputs":[],"source":["table = Texttable()\n","table.set_cols_dtype([\"a\", \"f\", \"f\", \"f\", \"f\", \"f\"])\n","table.set_precision(5)\n","table.add_rows(\n","    [\n","        [\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n","        [\"Gated RNN\", gru_train_acc, gru_test_acc, gru_f1_score, gru_precision, gru_recall],\n","    ]\n",")\n","print(table.draw(), \"\\n\")\n"]},{"cell_type":"markdown","id":"f3cdd129","metadata":{"id":"f3cdd129"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"5\">LSTM</font><br>\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"95d8d9cd","metadata":{"id":"95d8d9cd"},"outputs":[],"source":["# LSTM\n","\n","\n","class LSTM_Network(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","\n","        super(LSTM_Network, self).__init__()\n","\n","        # Number of hidden dimensions\n","        self.hidden_dim = hidden_dim\n","\n","        # RNN\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n","\n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden state with zeros\n","        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n","        c0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n","\n","        # One time step\n","        out, (hn, cn) = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])\n","\n","        return out\n"]},{"cell_type":"code","execution_count":null,"id":"e84b0dc6","metadata":{"id":"e84b0dc6"},"outputs":[],"source":["def train_LSTM(model, train_loader, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in train_loader:\n","\n","        train = Variable(batch[0].view(-1, 512, 768))\n","        labels = Variable(batch[1])\n","\n","        optimizer.zero_grad()\n","\n","        output = model(train)\n","\n","        loss = criterion(output, labels)\n","\n","        acc = binary_accuracy(output.argmax(-1), labels)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n"]},{"cell_type":"code","execution_count":null,"id":"05618834","metadata":{"id":"05618834"},"outputs":[],"source":["model_lstm = LSTM_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n","print(model_lstm)\n"]},{"cell_type":"code","execution_count":null,"id":"e6f054f9","metadata":{"id":"e6f054f9"},"outputs":[],"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float(\"inf\")\n","\n","criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1 / train_fair, 1 / train_unfair]))\n","\n","optimizer = optim.Adam(model_lstm.parameters(), lr=1e-4)\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    lstm_train_loss, lstm_train_acc = train_LSTM(model_lstm, train_loader, optimizer, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n","    print(\n","        f\"\\tTrain Loss: \\\n","    {lstm_train_loss:.3f} | Train Acc: {lstm_train_acc*100:.2f}%\"\n","    )\n"]},{"cell_type":"code","execution_count":null,"id":"eb28b03f","metadata":{"id":"eb28b03f"},"outputs":[],"source":["test_loader_predict = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=NUM_WORKERS)\n","\n","\n","def predict(model, dataloader):\n","    prediction_list = []\n","    for i, batch in enumerate(dataloader):\n","        test = Variable(batch.view(-1, 512, 768))\n","        outputs = model(test)\n","        _, predicted = torch.max(outputs.data, 1)\n","        prediction_list.append(predicted.cpu())\n","    return prediction_list\n","\n","\n","predictions_lstm = predict(model_lstm, test_loader_predict)\n","\n","a_tensor = torch.IntTensor(predictions_lstm)\n","b_tensor = torch.IntTensor(test_targets)\n","\n","accuracy = Accuracy()\n","lstm_test_acc = accuracy(a_tensor, b_tensor).item()\n","\n","f1 = F1Score(num_classes=2, average=\"macro\")  # checked if weighted can be used\n","lstm_f1_score = f1(a_tensor, b_tensor).item()\n","\n","precision = Precision(average=\"macro\", num_classes=2)\n","lstm_precision = precision(a_tensor, b_tensor).item()\n","\n","recall = Recall(average=\"macro\", num_classes=2)\n","lstm_recall = recall(a_tensor, b_tensor).item()\n","\n","print(\"Accuracy of LSTM :\", lstm_test_acc)\n","print(\"F1 score of LSTM :\", lstm_f1_score)\n","print(\"Precision of LSTM :\", lstm_precision)\n","print(\"Recall of of LSTM :\", lstm_recall)\n"]},{"cell_type":"code","execution_count":null,"id":"b5d21d51","metadata":{"id":"b5d21d51"},"outputs":[],"source":["table = Texttable()\n","table.set_cols_dtype([\"a\", \"f\", \"f\", \"f\", \"f\", \"f\"])\n","table.set_precision(5)\n","table.add_rows(\n","    [\n","        [\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n","        [\"LSTM\", lstm_train_acc, lstm_test_acc, lstm_f1_score, lstm_precision, lstm_recall],\n","    ]\n",")\n","print(table.draw(), \"\\n\")\n"]},{"cell_type":"markdown","id":"b8cff721","metadata":{"id":"b8cff721"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"5\">Bi-LSTM</font><br>\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"f3bcb948","metadata":{"id":"f3bcb948"},"outputs":[],"source":["# LSTM\n","\n","\n","class Bi_LSTM_Network(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","\n","        super(Bi_LSTM_Network, self).__init__()\n","\n","        # Number of hidden dimensions\n","        self.hidden_dim = hidden_dim\n","\n","        # RNN\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden state with zeros\n","        h0 = Variable(torch.zeros(1 * 2, x.size(0), self.hidden_dim))\n","        c0 = Variable(torch.zeros(1 * 2, x.size(0), self.hidden_dim))\n","\n","        # One time step\n","        out, (hn, cn) = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])\n","\n","        return out\n"]},{"cell_type":"code","execution_count":null,"id":"7a4693f9","metadata":{"id":"7a4693f9"},"outputs":[],"source":["def train_Bi_LSTM(model, train_loader, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in train_loader:\n","\n","        train = Variable(batch[0].view(-1, 512, 768))\n","        labels = Variable(batch[1])\n","\n","        optimizer.zero_grad()\n","\n","        output = model(train)\n","\n","        loss = criterion(output, labels)\n","\n","        acc = binary_accuracy(output.argmax(-1), labels)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n"]},{"cell_type":"code","execution_count":null,"id":"24a277bc","metadata":{"id":"24a277bc"},"outputs":[],"source":["model_bi_lstm = Bi_LSTM_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n","print(model_bi_lstm)\n"]},{"cell_type":"code","execution_count":null,"id":"b75537cd","metadata":{"id":"b75537cd"},"outputs":[],"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float(\"inf\")\n","\n","criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1 / train_fair, 1 / train_unfair]))\n","\n","optimizer = optim.Adam(model_bi_lstm.parameters(), lr=1e-4)\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    bi_lstm_train_loss, bi_lstm_train_acc = train_Bi_LSTM(model_bi_lstm, train_loader, optimizer, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n","    print(\n","        f\"\\tTrain Loss: \\\n","    {bi_lstm_train_loss:.3f} | Train Acc: {bi_lstm_train_acc*100:.2f}%\"\n","    )\n"]},{"cell_type":"code","execution_count":null,"id":"44a07e8d","metadata":{"scrolled":false,"id":"44a07e8d"},"outputs":[],"source":["test_loader_predict = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=NUM_WORKERS)\n","\n","\n","def predict(model, dataloader):\n","    prediction_list = []\n","    for i, batch in enumerate(dataloader):\n","        test = Variable(batch.view(-1, 512, 768))\n","        outputs = model(test)\n","        _, predicted = torch.max(outputs.data, 1)\n","        prediction_list.append(predicted.cpu())\n","    return prediction_list\n","\n","\n","predictions_bi_lstm = predict(model_bi_lstm, test_loader_predict)\n","\n","a_tensor = torch.IntTensor(predictions_bi_lstm)\n","b_tensor = torch.IntTensor(test_targets)\n","\n","accuracy = Accuracy()\n","bi_lstm_test_acc = accuracy(a_tensor, b_tensor).item()\n","\n","f1 = F1Score(num_classes=2, average=\"macro\")  # checked if weighted can be used\n","bi_lstm_f1_score = f1(a_tensor, b_tensor).item()\n","\n","precision = Precision(average=\"macro\", num_classes=2)\n","bi_lstm_precision = precision(a_tensor, b_tensor).item()\n","\n","recall = Recall(average=\"macro\", num_classes=2)\n","bi_lstm_recall = recall(a_tensor, b_tensor).item()\n","\n","print(\"Accuracy of LSTM :\", bi_lstm_test_acc)\n","print(\"F1 score of LSTM :\", bi_lstm_f1_score)\n","print(\"Precision of LSTM :\", bi_lstm_precision)\n","print(\"Recall of of LSTM :\", bi_lstm_recall)\n"]},{"cell_type":"code","execution_count":null,"id":"e99372b4","metadata":{"id":"e99372b4"},"outputs":[],"source":["table = Texttable()\n","table.set_cols_dtype([\"a\", \"f\", \"f\", \"f\", \"f\", \"f\"])\n","table.set_precision(5)\n","table.add_rows(\n","    [\n","        [\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n","        [\"Bi-LSTM\", bi_lstm_train_acc, bi_lstm_test_acc, bi_lstm_f1_score, bi_lstm_precision, bi_lstm_recall],\n","    ]\n",")\n","print(table.draw(), \"\\n\")\n"]},{"cell_type":"code","execution_count":null,"id":"23f916ed","metadata":{"id":"23f916ed"},"outputs":[],"source":["# compare all\n","table = Texttable()\n","table.set_cols_dtype([\"a\", \"f\", \"f\", \"f\", \"f\", \"f\"])\n","table.set_precision(5)\n","table.add_rows(\n","    [\n","        [\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n","        [\"Simple RNN\", rnn_train_acc, rnn_test_acc, rnn_f1_score, rnn_precision, rnn_recall],\n","        [\"Gated RNN\", gru_train_acc, gru_test_acc, gru_f1_score, gru_precision, gru_recall],\n","        [\"LSTM\", lstm_train_acc, lstm_test_acc, lstm_f1_score, lstm_precision, lstm_recall],\n","        [\"Bi-LSTM\", bi_lstm_train_acc, bi_lstm_test_acc, bi_lstm_f1_score, bi_lstm_precision, bi_lstm_recall],\n","    ]\n",")\n","print(table.draw(), \"\\n\")\n"]},{"cell_type":"markdown","id":"95f7eb4d","metadata":{"id":"95f7eb4d"},"source":["<span style=\"color:darkviolet\">\n","<font size=\"3\">Best Performance : Bi-LSTM</font><br>\n","</span>\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 64-bit ('csci544')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e78917e7f90f3892e7e12462ef46781cf5994bd706032ea53be00d0b1f29dcb9"}},"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":5}