{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268d41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies to run the notebook\n",
    "\n",
    "# !pip install torch==1.12.1\n",
    "# !pip install torchmetrics==0.10.2\n",
    "# !pip install torchvision==0.14.0\n",
    "# !pip install texttable==1.6.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd939a",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"3\">Download the below files from https://drive.google.com/drive/folders/1q50QMurzK9a5l4JBHWjf8VuWcZkbF7PM to run this notebook : <br>\n",
    "1) train_bert_embeddings.pkl <br>\n",
    "2) test_bert_embeddings.pkl <br> </font>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fef83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from texttable import Texttable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_NAME = \"xlnet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1167ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \".\"\n",
    "TRAIN_EMBEDDINGS = f\"{BASE_PATH}/../embeddings/train_{EMBEDDINGS_NAME}_embeddings.pkl\"\n",
    "TEST_EMBEDDINGS = f\"{BASE_PATH}/../embeddings/test_{EMBEDDINGS_NAME}_embeddings.pkl\"\n",
    "TRAIN_DATASET_PATH = f\"{BASE_PATH}/../legal_bert/data/tos_clauses_train.csv\"\n",
    "TEST_DATASET_PATH = f\"{BASE_PATH}/../legal_bert/data/tos_clauses_dev.csv\"\n",
    "RNN_MODEL_PATH = \"../models/rnn_{EMBEDDINGS_NAME}_model.pt\"\n",
    "GRU_MODEL_PATH = \"../models/gru_{EMBEDDINGS_NAME}_model.pt\"\n",
    "LSTM_MODEL_PATH = \"../models/lstm_{EMBEDDINGS_NAME}_model.pt\"\n",
    "BILSTM_MODEL_PATH = \"../models/bilstm_{EMBEDDINGS_NAME}_model.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf44010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train BERT embeddings\n",
    "with open(TRAIN_EMBEDDINGS, \"rb\") as f:\n",
    "    training_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e45b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test BERT embeddings\n",
    "with open(TEST_EMBEDDINGS, \"rb\") as f:\n",
    "    testing_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2bd91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is :  embeddings\n",
      "The data is :  tokenized_txt\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "for item in training_data:\n",
    "    print(\"The data is : \", item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca0767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7531, torch.Size([1, 512, 768]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data[\"embeddings\"]), training_data[\"embeddings\"][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c524e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7531, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data[\"tokenized_txt\"]), len(training_data[\"tokenized_txt\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481e82e",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Get the labels from train and test files.</font>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec7097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = \"../legal_bert/data/tos_clauses_train.csv\"\n",
    "TEST_DATASET_PATH = \"../legal_bert/data/tos_clauses_dev.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7feb1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATASET_PATH, header=0)\n",
    "test_df = pd.read_csv(TEST_DATASET_PATH, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a29d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train_df.label.values\n",
    "test_targets = test_df.label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541edf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0378fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92206a0",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Create Dataset, Train and Test Classes</font>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efaf4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \"\"\"An abstract class representing a Dataset.\n",
    "    All other datasets should subclass it. All subclasses should\n",
    "    override ``__len__``, that provides the size of the dataset,\n",
    "    and ``__getitem__``, supporting integer indexing in range\n",
    "    from 0 to len(self) exclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return ConcatDataset([self, other])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb78e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TOSDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.data1 = X\n",
    "        self.data2 = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data1[index]\n",
    "        y = self.data2[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            x = torch.tensor(x)\n",
    "\n",
    "        return torch.squeeze(x, dim=1), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d37e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.sampler.SubsetRandomSampler object at 0x17f907520>\n",
      "train_fair:6705\n",
      "train_unfair:826\n"
     ]
    }
   ],
   "source": [
    "test_len = len(test_df)\n",
    "train_len = len(train_df)\n",
    "X_train_tensor = TOSDataset(train_df[\"sentences\"], train_df[\"label\"])\n",
    "# X_test_tensor = Train_Model(test_df)\n",
    "\n",
    "num_train = len(X_train_tensor)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "# split = int(np.floor(num_train))\n",
    "# train_idx = indices[split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(indices)\n",
    "# valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "print(train_sampler)\n",
    "train_df_by_index = train_df.loc[indices]\n",
    "# val_df_by_index = df_train.loc[valid_idx]\n",
    "train_fair = sum(train_df_by_index[\"label\"] == 0)\n",
    "train_unfair = sum(train_df_by_index[\"label\"] == 1)\n",
    "# val_fair = sum(val_df_by_index['label'] == 0)\n",
    "# val_unfair = sum(val_df_by_index['label'] == 1)\n",
    "\n",
    "print(\"train_fair:\" + str(train_fair))\n",
    "print(\"train_unfair:\" + str(train_unfair))\n",
    "# print(\"val_fair:\" + str(val_fair))\n",
    "# print(\"val_unfair:\" + str(val_unfair))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cca2a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TOSDataset(training_data[\"embeddings\"], train_targets, transform=transforms.ToTensor())\n",
    "test_data = TOSDataset(testing_data[\"embeddings\"], test_targets, transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b7413",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Prepare Data loaders</font>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db13f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples per batch to load\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "NUM_WORKERS = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d9572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36811bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([20, 1, 512, 768])\n",
      "\n",
      "Sample label size:  torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# check sizes\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print(\"Sample input size: \", sample_x.size())  # batch_size, seq_length\n",
    "# print(\"Sample input: \\n\", sample_x)\n",
    "print()\n",
    "print(\"Sample label size: \", sample_y.size())  # batch_size\n",
    "# print(\"Sample label: \\n\", sample_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6f98c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(sample_x, dim=1).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccefed",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">SIMPLE RNN</font><br>\n",
    "<font size=\"2.5\">Number of hidden dimension : 20</font> <br>\n",
    "<font size=\"2.5\">Number of layers: 1</font> <br>\n",
    "<font size=\"2.5\">Number of epochs: 5</font> <br>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f35604d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(RNNet, self).__init__()\n",
    "\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=3, batch_first=True, nonlinearity=\"relu\")\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(3, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4a1f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d3eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "OUTPUT_DIM = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5c62989",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_HIDDEN_DIM = 1024\n",
    "RNN_N_EPOCHS = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acb233cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56159582, 4.55871671])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weight = compute_class_weight(\n",
    "    \"balanced\", classes=np.unique(train_df_by_index[\"label\"]), y=train_df_by_index[\"label\"]\n",
    ")\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53e1f120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 8m 24s\n",
      "\tTraining Loss: 0.034758 \\Test Loss: 0.035049\n",
      "Test loss decreased (inf --> 0.035049). Saving model...\n"
     ]
    }
   ],
   "source": [
    "model = RNNet(EMBEDDING_DIM, RNN_HIDDEN_DIM, OUTPUT_DIM)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weight))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "test_min_loss = np.inf\n",
    "\n",
    "for epoch in range(RNN_N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    for inputs, target in train_loader:\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    for inputs, target in test_loader:\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\"\\tTraining Loss: {:.6f} \\Test Loss: {:.6f}\".format(train_loss, test_loss))\n",
    "    if test_loss <= test_min_loss:\n",
    "        print(\"Test loss decreased ({:.6f} --> {:.6f}). Saving model...\".format(test_min_loss, test_loss))\n",
    "        torch.save(model.state_dict(), RNN_MODEL_PATH)\n",
    "        test_min_loss = test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1677\n",
      "           1       0.11      1.00      0.20       206\n",
      "\n",
      "    accuracy                           0.11      1883\n",
      "   macro avg       0.05      0.50      0.10      1883\n",
      "weighted avg       0.01      0.11      0.02      1883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_targ_list = []\n",
    "model = RNNet(EMBEDDING_DIM, RNN_HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "model.load_state_dict(torch.load(RNN_MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, target in test_loader:\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        y_test_pred = model(inputs)\n",
    "        _, y_test_pred = torch.max(y_test_pred, 1)\n",
    "        y_pred_tag = y_test_pred\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        y_targ_list.append(target.cpu().numpy())\n",
    "\n",
    "y_pred_list = [x.squeeze().tolist() for x in y_pred_list]\n",
    "y_targ_list = [x.squeeze().tolist() for x in y_targ_list]\n",
    "y_pred_list = [x for sublist in y_pred_list for x in sublist]\n",
    "y_targ_list = [x for sublist in y_targ_list for x in sublist]\n",
    "\n",
    "print(classification_report(y_targ_list, y_pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d4ffec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      1677\n",
      "           1       0.22      0.54      0.31       206\n",
      "\n",
      "    accuracy                           0.74      1883\n",
      "   macro avg       0.57      0.65      0.57      1883\n",
      "weighted avg       0.85      0.74      0.78      1883\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86d8b3a5",
   "metadata": {},
   "source": [
    "Accuracy of simple RNN : 0.7413701415061951\n",
    "F1 score of simple RNN : 0.5635073184967041\n",
    "Precision of simple RNN : 0.5633978843688965\n",
    "Recall of simple RNN : 0.6227356195449829\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe86eec",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">Gated RNN</font><br>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e40ad5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(GRU_Network, self).__init__()\n",
    "\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662cab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_HIDDEN_DIM = 512\n",
    "GRU_N_EPOCHS = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ace29e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_Network(\n",
      "  (rnn): GRU(768, 20, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_gru = GRU_Network(EMBEDDING_DIM, GRU_HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_gru)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc5174a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GRU(model, train_loader, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        train = Variable(batch[0].view(-1, 512, 768))\n",
    "        labels = Variable(batch[1])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(train)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        acc = binary_accuracy(output.argmax(-1), labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec37270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 31s\n",
      "\tTrain Loss:     0.679 | Train Acc: 74.31%\n",
      "Epoch: 02 | Epoch Time: 0m 26s\n",
      "\tTrain Loss:     0.656 | Train Acc: 73.69%\n",
      "Epoch: 03 | Epoch Time: 0m 27s\n",
      "\tTrain Loss:     0.644 | Train Acc: 72.74%\n",
      "Epoch: 04 | Epoch Time: 0m 26s\n",
      "\tTrain Loss:     0.633 | Train Acc: 74.21%\n",
      "Epoch: 05 | Epoch Time: 0m 26s\n",
      "\tTrain Loss:     0.627 | Train Acc: 72.91%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1 / train_fair, 1 / train_unfair]))\n",
    "# criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer_gru = optim.Adam(model_gru.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    gru_train_loss, gru_train_acc = train_RNN(model_gru, train_loader, optimizer_gru, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\n",
    "        f\"\\tTrain Loss: \\\n",
    "    {gru_train_loss:.3f} | Train Acc: {gru_train_acc*100:.2f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d4fca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gated RNN : 0.6611789464950562\n",
      "F1 score of Gated RNN : 0.535663366317749\n",
      "Precision of Gated RNN : 0.5644705295562744\n",
      "Recall of Gated RNN : 0.6543599367141724\n"
     ]
    }
   ],
   "source": [
    "test_loader_predict = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=0)\n",
    "\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        test = Variable(batch.view(-1, 512, 768))\n",
    "        outputs = model(test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction_list.append(predicted.cpu())\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "predictions_gru = predict(model_gru, test_loader_predict)\n",
    "\n",
    "a_tensor = torch.IntTensor(predictions_gru)\n",
    "b_tensor = torch.IntTensor(test_targets)\n",
    "\n",
    "accuracy = Accuracy()\n",
    "gru_test_acc = accuracy(a_tensor, b_tensor).item()\n",
    "\n",
    "f1 = F1Score(num_classes=2, average=\"macro\")  # checked if weighted can be used\n",
    "gru_f1_score = f1(a_tensor, b_tensor).item()\n",
    "\n",
    "precision = Precision(average=\"macro\", num_classes=2)\n",
    "gru_precision = precision(a_tensor, b_tensor).item()\n",
    "\n",
    "recall = Recall(average=\"macro\", num_classes=2)\n",
    "gru_recall = recall(a_tensor, b_tensor).item()\n",
    "\n",
    "print(\"Accuracy of Gated RNN :\", gru_test_acc)\n",
    "print(\"F1 score of Gated RNN :\", gru_f1_score)\n",
    "print(\"Precision of Gated RNN :\", gru_precision)\n",
    "print(\"Recall of Gated RNN :\", gru_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32490444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------------+----------+-----------+---------+\n",
      "|   Model   | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+===========+================+===============+==========+===========+=========+\n",
      "| Gated RNN | 0.72912        | 0.66118       | 0.53566  | 0.56447   | 0.65436 |\n",
      "+-----------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = Texttable()\n",
    "table.set_cols_dtype([\"a\", \"f\", \"f\", \"f\", \"f\", \"f\"])\n",
    "table.set_precision(5)\n",
    "table.add_rows(\n",
    "    [\n",
    "        [\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "        [\"Gated RNN\", gru_train_acc, gru_test_acc, gru_f1_score, gru_precision, gru_recall],\n",
    "    ]\n",
    ")\n",
    "print(table.draw(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdd129",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">LSTM</font><br>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95d8d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "\n",
    "class LSTM_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(LSTM_Network, self).__init__()\n",
    "\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "        c0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e84b0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTM(model, train_loader, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        train = Variable(batch[0].view(-1, 512, 768))\n",
    "        labels = Variable(batch[1])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(train)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        acc = binary_accuracy(output.argmax(-1), labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05618834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Network(\n",
      "  (lstm): LSTM(768, 20, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_lstm = LSTM_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6f054f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 31s\n",
      "\tTrain Loss:     0.672 | Train Acc: 74.67%\n",
      "Epoch: 02 | Epoch Time: 0m 27s\n",
      "\tTrain Loss:     0.652 | Train Acc: 73.81%\n",
      "Epoch: 03 | Epoch Time: 0m 27s\n",
      "\tTrain Loss:     0.643 | Train Acc: 74.06%\n",
      "Epoch: 04 | Epoch Time: 0m 27s\n",
      "\tTrain Loss:     0.634 | Train Acc: 73.18%\n",
      "Epoch: 05 | Epoch Time: 0m 28s\n",
      "\tTrain Loss:     0.630 | Train Acc: 74.97%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1 / train_fair, 1 / train_unfair]))\n",
    "\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    lstm_train_loss, lstm_train_acc = train_LSTM(model_lstm, train_loader, optimizer, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\n",
    "        f\"\\tTrain Loss: \\\n",
    "    {lstm_train_loss:.3f} | Train Acc: {lstm_train_acc*100:.2f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb28b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LSTM : 0.7456187009811401\n",
      "F1 score of LSTM : 0.5636465549468994\n",
      "Precision of LSTM : 0.562571108341217\n",
      "Recall of of LSTM : 0.6187337636947632\n"
     ]
    }
   ],
   "source": [
    "test_loader_predict = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        test = Variable(batch.view(-1, 512, 768))\n",
    "        outputs = model(test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction_list.append(predicted.cpu())\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "predictions_lstm = predict(model_lstm, test_loader_predict)\n",
    "\n",
    "a_tensor = torch.IntTensor(predictions_lstm)\n",
    "b_tensor = torch.IntTensor(test_targets)\n",
    "\n",
    "accuracy = Accuracy()\n",
    "lstm_test_acc = accuracy(a_tensor, b_tensor).item()\n",
    "\n",
    "f1 = F1Score(num_classes=2, average=\"macro\")  # checked if weighted can be used\n",
    "lstm_f1_score = f1(a_tensor, b_tensor).item()\n",
    "\n",
    "precision = Precision(average=\"macro\", num_classes=2)\n",
    "lstm_precision = precision(a_tensor, b_tensor).item()\n",
    "\n",
    "recall = Recall(average=\"macro\", num_classes=2)\n",
    "lstm_recall = recall(a_tensor, b_tensor).item()\n",
    "\n",
    "print(\"Accuracy of LSTM :\", lstm_test_acc)\n",
    "print(\"F1 score of LSTM :\", lstm_f1_score)\n",
    "print(\"Precision of LSTM :\", lstm_precision)\n",
    "print(\"Recall of of LSTM :\", lstm_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5d21d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+---------------+----------+-----------+---------+\n",
      "| Model | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+=======+================+===============+==========+===========+=========+\n",
      "| LSTM  | 0.74970        | 0.74562       | 0.56365  | 0.56257   | 0.61873 |\n",
      "+-------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = Texttable()\n",
    "table.set_cols_dtype([\"a\", \"f\", \"f\", \"f\", \"f\", \"f\"])\n",
    "table.set_precision(5)\n",
    "table.add_rows(\n",
    "    [\n",
    "        [\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "        [\"LSTM\", lstm_train_acc, lstm_test_acc, lstm_f1_score, lstm_precision, lstm_recall],\n",
    "    ]\n",
    ")\n",
    "print(table.draw(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cff721",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">Bi-LSTM</font><br>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3bcb948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "\n",
    "class Bi_LSTM_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(Bi_LSTM_Network, self).__init__()\n",
    "\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1 * 2, x.size(0), self.hidden_dim))\n",
    "        c0 = Variable(torch.zeros(1 * 2, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a4693f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Bi_LSTM(model, train_loader, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        train = Variable(batch[0].view(-1, 512, 768))\n",
    "        labels = Variable(batch[1])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(train)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        acc = binary_accuracy(output.argmax(-1), labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24a277bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi_LSTM_Network(\n",
      "  (lstm): LSTM(768, 20, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=40, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_bi_lstm = Bi_LSTM_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_bi_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b75537cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 51s\n",
      "\tTrain Loss:     0.664 | Train Acc: 76.07%\n",
      "Epoch: 02 | Epoch Time: 0m 50s\n",
      "\tTrain Loss:     0.644 | Train Acc: 73.88%\n",
      "Epoch: 03 | Epoch Time: 0m 47s\n",
      "\tTrain Loss:     0.632 | Train Acc: 73.15%\n",
      "Epoch: 04 | Epoch Time: 0m 46s\n",
      "\tTrain Loss:     0.626 | Train Acc: 73.60%\n",
      "Epoch: 05 | Epoch Time: 0m 46s\n",
      "\tTrain Loss:     0.617 | Train Acc: 73.32%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1 / train_fair, 1 / train_unfair]))\n",
    "\n",
    "optimizer = optim.Adam(model_bi_lstm.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    bi_lstm_train_loss, bi_lstm_train_acc = train_Bi_LSTM(model_bi_lstm, train_loader, optimizer, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\n",
    "        f\"\\tTrain Loss: \\\n",
    "    {bi_lstm_train_loss:.3f} | Train Acc: {bi_lstm_train_acc*100:.2f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44a07e8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LSTM : 0.759957492351532\n",
      "F1 score of LSTM : 0.5818121433258057\n",
      "Precision of LSTM : 0.5761378407478333\n",
      "Recall of of LSTM : 0.6416870951652527\n"
     ]
    }
   ],
   "source": [
    "test_loader_predict = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        test = Variable(batch.view(-1, 512, 768))\n",
    "        outputs = model(test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction_list.append(predicted.cpu())\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "predictions_bi_lstm = predict(model_bi_lstm, test_loader_predict)\n",
    "\n",
    "a_tensor = torch.IntTensor(predictions_bi_lstm)\n",
    "b_tensor = torch.IntTensor(test_targets)\n",
    "\n",
    "accuracy = Accuracy()\n",
    "bi_lstm_test_acc = accuracy(a_tensor, b_tensor).item()\n",
    "\n",
    "f1 = F1Score(num_classes=2, average=\"macro\")  # checked if weighted can be used\n",
    "bi_lstm_f1_score = f1(a_tensor, b_tensor).item()\n",
    "\n",
    "precision = Precision(average=\"macro\", num_classes=2)\n",
    "bi_lstm_precision = precision(a_tensor, b_tensor).item()\n",
    "\n",
    "recall = Recall(average=\"macro\", num_classes=2)\n",
    "bi_lstm_recall = recall(a_tensor, b_tensor).item()\n",
    "\n",
    "print(\"Accuracy of LSTM :\", bi_lstm_test_acc)\n",
    "print(\"F1 score of LSTM :\", bi_lstm_f1_score)\n",
    "print(\"Precision of LSTM :\", bi_lstm_precision)\n",
    "print(\"Recall of of LSTM :\", bi_lstm_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e99372b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+----------+-----------+---------+\n",
      "|  Model  | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+=========+================+===============+==========+===========+=========+\n",
      "| Bi-LSTM | 0.73320        | 0.75996       | 0.58181  | 0.57614   | 0.64169 |\n",
      "+---------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = Texttable()\n",
    "table.set_cols_dtype([\"a\", \"f\", \"f\", \"f\", \"f\", \"f\"])\n",
    "table.set_precision(5)\n",
    "table.add_rows(\n",
    "    [\n",
    "        [\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "        [\"Bi-LSTM\", bi_lstm_train_acc, bi_lstm_test_acc, bi_lstm_f1_score, bi_lstm_precision, bi_lstm_recall],\n",
    "    ]\n",
    ")\n",
    "print(table.draw(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23f916ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "|   Model    | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+============+================+===============+==========+===========+=========+\n",
      "| Simple RNN | 0.71450        | 0.74137       | 0.56351  | 0.56340   | 0.62274 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "| Gated RNN  | 0.72912        | 0.66118       | 0.53566  | 0.56447   | 0.65436 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "| LSTM       | 0.74970        | 0.74562       | 0.56365  | 0.56257   | 0.61873 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "| Bi-LSTM    | 0.73320        | 0.75996       | 0.58181  | 0.57614   | 0.64169 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare all\n",
    "table = Texttable()\n",
    "table.set_cols_dtype([\"a\", \"f\", \"f\", \"f\", \"f\", \"f\"])\n",
    "table.set_precision(5)\n",
    "table.add_rows(\n",
    "    [\n",
    "        [\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "        [\"Simple RNN\", rnn_train_acc, rnn_test_acc, rnn_f1_score, rnn_precision, rnn_recall],\n",
    "        [\"Gated RNN\", gru_train_acc, gru_test_acc, gru_f1_score, gru_precision, gru_recall],\n",
    "        [\"LSTM\", lstm_train_acc, lstm_test_acc, lstm_f1_score, lstm_precision, lstm_recall],\n",
    "        [\"Bi-LSTM\", bi_lstm_train_acc, bi_lstm_test_acc, bi_lstm_f1_score, bi_lstm_precision, bi_lstm_recall],\n",
    "    ]\n",
    ")\n",
    "print(table.draw(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7eb4d",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"3\">Best Performance : Bi-LSTM</font><br>\n",
    "</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('csci544')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e78917e7f90f3892e7e12462ef46781cf5994bd706032ea53be00d0b1f29dcb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
