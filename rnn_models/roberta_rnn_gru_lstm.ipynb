{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "031c1925",
   "metadata": {},
   "source": [
    "## BEST SCORES \n",
    "\n",
    "Learning rates - 1e-1, 1e-2, 1e-3, 1e-4  <br>\n",
    "Hidden layers - 1, 3  <br>\n",
    "\n",
    "Hidden layer 3 had all scores around 45-50 and it did not increase after 50 epochs as well. Hidden layer 1 had decent scores for Learning rates 1e-3, 1e-4  <br>\n",
    "\n",
    "#### RNN\n",
    "1e-4 with 1 hidden layer, epoch 48 - 57 <br>\n",
    "Best -  1e-3 with 1 hidden layer, epoch 58 - 63  <br>\n",
    "\n",
    "#### Gated RNN\n",
    "Best -  1e-3 with 1 hidden layer, epoch 51 - 76  <br>\n",
    "\n",
    "#### LSTM \n",
    "1e-3 with 2/3 hidden layer, epoch 8 - 52  <br>\n",
    "Stopped as it started going down and reached 0  <br>\n",
    "\n",
    "Best - 1e-3 and 1 hidden layer, epoch 48 - 65  <br>\n",
    "\n",
    "#### Bi LSTM\n",
    "Best - 1e-3 and 1 hidden layer, epoch 45 - 65  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268d41ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.12.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torch==1.12.1) (4.4.0)\n",
      "Requirement already satisfied: torchmetrics==0.10.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.10.2)\n",
      "Requirement already satisfied: torch>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchmetrics==0.10.2) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchmetrics==0.10.2) (1.23.4)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchmetrics==0.10.2) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchmetrics==0.10.2) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from packaging->torchmetrics==0.10.2) (3.0.9)\n",
      "Requirement already satisfied: torchvision==0.14.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.14.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchvision==0.14.0) (4.4.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchvision==0.14.0) (1.23.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchvision==0.14.0) (9.2.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchvision==0.14.0) (1.12.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchvision==0.14.0) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->torchvision==0.14.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->torchvision==0.14.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->torchvision==0.14.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->torchvision==0.14.0) (2.1.1)\n",
      "Requirement already satisfied: texttable==1.6.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.6.4)\n"
     ]
    }
   ],
   "source": [
    "# dependencies to run the notebook\n",
    "\n",
    "!pip install torch==1.12.1\n",
    "!pip install torchmetrics==0.10.2\n",
    "!pip install torchvision==0.14.0\n",
    "!pip install texttable==1.6.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd939a",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"3\">Download the below files from https://drive.google.com/drive/folders/1q50QMurzK9a5l4JBHWjf8VuWcZkbF7PM to run this notebook : <br>\n",
    "1) train_bert_embeddings.pkl <br>\n",
    "2) test_bert_embeddings.pkl <br> </font>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fef83eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE\n",
      "  Referenced from: /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in: /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from texttable import Texttable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf44010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train BERT embeddings\n",
    "with open(\"train_roberta_embeddings.pkl\", \"rb\") as f:\n",
    "    training_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e45b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test BERT embeddings\n",
    "with open(\"test_roberta_embeddings.pkl\", \"rb\") as f:\n",
    "    testing_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2bd91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is :  embeddings\n",
      "The data is :  tokenized_txt\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "for item in training_data:\n",
    "    print(\"The data is : \", item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca0767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7531, torch.Size([1, 512, 768]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data[\"embeddings\"]), training_data[\"embeddings\"][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c524e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7531, 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data[\"tokenized_txt\"]), len(training_data[\"tokenized_txt\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481e82e",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Get the labels from train and test files.</font>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec7097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"tos_clauses_train.csv\"\n",
    "test_dataset_path = \"tos_clauses_dev.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7feb1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_dataset_path, header=0)\n",
    "test_df = pd.read_csv(test_dataset_path, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a29d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train_df.label.values\n",
    "test_targets = test_df.label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541edf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0378fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92206a0",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Create Dataset, Train and Test Classes</font>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efaf4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \"\"\"An abstract class representing a Dataset.\n",
    "    All other datasets should subclass it. All subclasses should\n",
    "    override ``__len__``, that provides the size of the dataset,\n",
    "    and ``__getitem__``, supporting integer indexing in range\n",
    "    from 0 to len(self) exclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return ConcatDataset([self, other])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb78e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TOSDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.data1 = X\n",
    "        self.data2 = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data1[index]\n",
    "        y = self.data2[index]\n",
    "\n",
    "        x = torch.tensor(x)\n",
    "\n",
    "        return torch.squeeze(x, dim=1), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d37e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.sampler.SubsetRandomSampler object at 0x1524548b0>\n",
      "train_fair:6705\n",
      "train_unfair:826\n"
     ]
    }
   ],
   "source": [
    "test_len = len(test_df)\n",
    "train_len = len(train_df)\n",
    "X_train_tensor = TOSDataset(train_df[\"sentences\"], train_df[\"label\"])\n",
    "# X_test_tensor = Train_Model(test_df)\n",
    "\n",
    "num_train = len(X_train_tensor)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "# split = int(np.floor(num_train))\n",
    "# train_idx = indices[split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(indices)\n",
    "# valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "print(train_sampler)\n",
    "train_df_by_index = train_df.loc[indices]\n",
    "# val_df_by_index = df_train.loc[valid_idx]\n",
    "train_fair = sum(train_df_by_index[\"label\"] == 0)\n",
    "train_unfair = sum(train_df_by_index[\"label\"] == 1)\n",
    "# val_fair = sum(val_df_by_index['label'] == 0)\n",
    "# val_unfair = sum(val_df_by_index['label'] == 1)\n",
    "\n",
    "print(\"train_fair:\" + str(train_fair))\n",
    "print(\"train_unfair:\" + str(train_unfair))\n",
    "# print(\"val_fair:\" + str(val_fair))\n",
    "# print(\"val_unfair:\" + str(val_unfair))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cca2a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TOSDataset(training_data[\"embeddings\"], train_targets)\n",
    "test_data = TOSDataset(testing_data[\"embeddings\"], test_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b7413",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Prepare Data loaders</font>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db13f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples per batch to load\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "NUM_WORKERS = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14d9572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=NUM_WORKERS\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36811bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([20, 1, 512, 768])\n",
      "\n",
      "Sample label size:  torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# check sizes\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print(\"Sample input size: \", sample_x.size())  # batch_size, seq_length\n",
    "# print(\"Sample input: \\n\", sample_x)\n",
    "print()\n",
    "print(\"Sample label size: \", sample_y.size())  # batch_size\n",
    "# print(\"Sample label: \\n\", sample_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6f98c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(sample_x, dim=1).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccefed",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">SIMPLE RNN</font><br>\n",
    "<font size=\"2.5\">Number of hidden dimension : 20</font> <br>\n",
    "<font size=\"2.5\">Number of layers: 1</font> <br>\n",
    "<font size=\"2.5\">Number of epochs: 5</font> <br>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f35604d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(RNNet, self).__init__()\n",
    "\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=1, batch_first=True, nonlinearity=\"relu\")\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4a1f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5c62989",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "HIDDEN_DIM = 512\n",
    "OUTPUT_DIM = 2\n",
    "N_EPOCHS = 75\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acb233cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56159582, 4.55871671])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weight = compute_class_weight(\n",
    "    \"balanced\", classes=np.unique(train_df_by_index[\"label\"]), y=train_df_by_index[\"label\"]\n",
    ")\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53e1f120",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1677\n",
      "           1       0.26      0.50      0.34       206\n",
      "\n",
      "    accuracy                           0.79      1883\n",
      "   macro avg       0.60      0.66      0.61      1883\n",
      "weighted avg       0.86      0.79      0.82      1883\n",
      "\n",
      "Epoch: 01 | Epoch Time: 1m 2s\n",
      "\tTraining Loss: 0.034089 \\Test Loss: 0.032139\n",
      "Test loss decreased (inf --> 0.032139). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.87      1677\n",
      "           1       0.28      0.62      0.38       206\n",
      "\n",
      "    accuracy                           0.78      1883\n",
      "   macro avg       0.61      0.71      0.62      1883\n",
      "weighted avg       0.87      0.78      0.81      1883\n",
      "\n",
      "Epoch: 02 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.030792 \\Test Loss: 0.028430\n",
      "Test loss decreased (0.032139 --> 0.028430). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91      1677\n",
      "           1       0.37      0.55      0.44       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.65      0.72      0.68      1883\n",
      "weighted avg       0.88      0.85      0.86      1883\n",
      "\n",
      "Epoch: 03 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.027826 \\Test Loss: 0.026112\n",
      "Test loss decreased (0.028430 --> 0.026112). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      1677\n",
      "           1       0.36      0.68      0.47       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.66      0.77      0.69      1883\n",
      "weighted avg       0.89      0.83      0.85      1883\n",
      "\n",
      "Epoch: 04 | Epoch Time: 1m 9s\n",
      "\tTraining Loss: 0.024767 \\Test Loss: 0.023736\n",
      "Test loss decreased (0.026112 --> 0.023736). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.73      1677\n",
      "           1       0.21      0.93      0.35       206\n",
      "\n",
      "    accuracy                           0.61      1883\n",
      "   macro avg       0.60      0.75      0.54      1883\n",
      "weighted avg       0.90      0.61      0.68      1883\n",
      "\n",
      "Epoch: 05 | Epoch Time: 1m 6s\n",
      "\tTraining Loss: 0.024445 \\Test Loss: 0.026733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      1677\n",
      "           1       0.45      0.57      0.51       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.70      0.74      0.72      1883\n",
      "weighted avg       0.89      0.88      0.88      1883\n",
      "\n",
      "Epoch: 06 | Epoch Time: 1m 7s\n",
      "\tTraining Loss: 0.022415 \\Test Loss: 0.023683\n",
      "Test loss decreased (0.023736 --> 0.023683). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      1677\n",
      "           1       0.56      0.39      0.46       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.74      0.68      0.70      1883\n",
      "weighted avg       0.89      0.90      0.89      1883\n",
      "\n",
      "Epoch: 07 | Epoch Time: 1m 9s\n",
      "\tTraining Loss: 0.021412 \\Test Loss: 0.027370\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      1677\n",
      "           1       0.32      0.85      0.47       206\n",
      "\n",
      "    accuracy                           0.79      1883\n",
      "   macro avg       0.65      0.82      0.67      1883\n",
      "weighted avg       0.91      0.79      0.82      1883\n",
      "\n",
      "Epoch: 08 | Epoch Time: 1m 9s\n",
      "\tTraining Loss: 0.020809 \\Test Loss: 0.021086\n",
      "Test loss decreased (0.023683 --> 0.021086). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82      1677\n",
      "           1       0.27      0.91      0.42       206\n",
      "\n",
      "    accuracy                           0.73      1883\n",
      "   macro avg       0.63      0.81      0.62      1883\n",
      "weighted avg       0.91      0.73      0.78      1883\n",
      "\n",
      "Epoch: 09 | Epoch Time: 1m 8s\n",
      "\tTraining Loss: 0.020247 \\Test Loss: 0.022471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1677\n",
      "           1       0.48      0.67      0.56       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.72      0.79      0.75      1883\n",
      "weighted avg       0.91      0.88      0.89      1883\n",
      "\n",
      "Epoch: 10 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.020135 \\Test Loss: 0.021325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86      1677\n",
      "           1       0.31      0.88      0.46       206\n",
      "\n",
      "    accuracy                           0.78      1883\n",
      "   macro avg       0.65      0.82      0.66      1883\n",
      "weighted avg       0.91      0.78      0.82      1883\n",
      "\n",
      "Epoch: 11 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.019340 \\Test Loss: 0.020879\n",
      "Test loss decreased (0.021086 --> 0.020879). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      1677\n",
      "           1       0.51      0.64      0.57       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.78      0.75      1883\n",
      "weighted avg       0.91      0.89      0.90      1883\n",
      "\n",
      "Epoch: 12 | Epoch Time: 0m 59s\n",
      "\tTraining Loss: 0.019390 \\Test Loss: 0.022054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1677\n",
      "           1       0.54      0.57      0.55       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.74      0.75      0.75      1883\n",
      "weighted avg       0.90      0.90      0.90      1883\n",
      "\n",
      "Epoch: 13 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.018961 \\Test Loss: 0.023447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91      1677\n",
      "           1       0.39      0.80      0.53       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.68      0.82      0.72      1883\n",
      "weighted avg       0.91      0.84      0.86      1883\n",
      "\n",
      "Epoch: 14 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.018431 \\Test Loss: 0.019362\n",
      "Test loss decreased (0.020879 --> 0.019362). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91      1677\n",
      "           1       0.40      0.81      0.54       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.69      0.83      0.72      1883\n",
      "weighted avg       0.91      0.85      0.87      1883\n",
      "\n",
      "Epoch: 15 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.017688 \\Test Loss: 0.019237\n",
      "Test loss decreased (0.019362 --> 0.019237). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87      1677\n",
      "           1       0.34      0.88      0.49       206\n",
      "\n",
      "    accuracy                           0.80      1883\n",
      "   macro avg       0.66      0.83      0.68      1883\n",
      "weighted avg       0.91      0.80      0.83      1883\n",
      "\n",
      "Epoch: 16 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.017766 \\Test Loss: 0.019738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      1677\n",
      "           1       0.50      0.69      0.58       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.80      0.76      1883\n",
      "weighted avg       0.91      0.89      0.90      1883\n",
      "\n",
      "Epoch: 17 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.017754 \\Test Loss: 0.020338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      1677\n",
      "           1       0.41      0.79      0.54       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.69      0.83      0.73      1883\n",
      "weighted avg       0.91      0.85      0.87      1883\n",
      "\n",
      "Epoch: 18 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.017687 \\Test Loss: 0.018983\n",
      "Test loss decreased (0.019237 --> 0.018983). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      1677\n",
      "           1       0.43      0.75      0.55       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.70      0.82      0.74      1883\n",
      "weighted avg       0.91      0.87      0.88      1883\n",
      "\n",
      "Epoch: 19 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.016835 \\Test Loss: 0.019510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81      1677\n",
      "           1       0.26      0.92      0.41       206\n",
      "\n",
      "    accuracy                           0.71      1883\n",
      "   macro avg       0.62      0.80      0.61      1883\n",
      "weighted avg       0.91      0.71      0.76      1883\n",
      "\n",
      "Epoch: 20 | Epoch Time: 1m 9s\n",
      "\tTraining Loss: 0.017191 \\Test Loss: 0.023261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1677\n",
      "           1       0.43      0.78      0.55       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.70      0.82      0.74      1883\n",
      "weighted avg       0.91      0.86      0.88      1883\n",
      "\n",
      "Epoch: 21 | Epoch Time: 1m 9s\n",
      "\tTraining Loss: 0.016744 \\Test Loss: 0.018985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      1677\n",
      "           1       0.37      0.86      0.52       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.68      0.84      0.71      1883\n",
      "weighted avg       0.91      0.83      0.85      1883\n",
      "\n",
      "Epoch: 22 | Epoch Time: 1m 8s\n",
      "\tTraining Loss: 0.016675 \\Test Loss: 0.019014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1677\n",
      "           1       0.48      0.72      0.58       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.72      0.81      0.76      1883\n",
      "weighted avg       0.91      0.88      0.89      1883\n",
      "\n",
      "Epoch: 23 | Epoch Time: 1m 8s\n",
      "\tTraining Loss: 0.016860 \\Test Loss: 0.019734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86      1677\n",
      "           1       0.32      0.89      0.47       206\n",
      "\n",
      "    accuracy                           0.78      1883\n",
      "   macro avg       0.65      0.83      0.66      1883\n",
      "weighted avg       0.91      0.78      0.82      1883\n",
      "\n",
      "Epoch: 24 | Epoch Time: 1m 8s\n",
      "\tTraining Loss: 0.016806 \\Test Loss: 0.019934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1677\n",
      "           1       0.47      0.75      0.58       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.72      0.82      0.75      1883\n",
      "weighted avg       0.91      0.88      0.89      1883\n",
      "\n",
      "Epoch: 25 | Epoch Time: 1m 6s\n",
      "\tTraining Loss: 0.016362 \\Test Loss: 0.019108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1677\n",
      "           1       0.53      0.69      0.60       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.81      0.77      1883\n",
      "weighted avg       0.91      0.90      0.91      1883\n",
      "\n",
      "Epoch: 26 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.015746 \\Test Loss: 0.020796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1677\n",
      "           1       0.46      0.77      0.57       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.71      0.83      0.75      1883\n",
      "weighted avg       0.91      0.87      0.89      1883\n",
      "\n",
      "Epoch: 27 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.016391 \\Test Loss: 0.018984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      1677\n",
      "           1       0.37      0.86      0.52       206\n",
      "\n",
      "    accuracy                           0.82      1883\n",
      "   macro avg       0.67      0.84      0.70      1883\n",
      "weighted avg       0.91      0.82      0.85      1883\n",
      "\n",
      "Epoch: 28 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.015833 \\Test Loss: 0.018642\n",
      "Test loss decreased (0.018983 --> 0.018642). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1677\n",
      "           1       0.50      0.74      0.60       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.82      0.77      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 29 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.016348 \\Test Loss: 0.019325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1677\n",
      "           1       0.35      0.89      0.50       206\n",
      "\n",
      "    accuracy                           0.81      1883\n",
      "   macro avg       0.67      0.84      0.69      1883\n",
      "weighted avg       0.91      0.81      0.84      1883\n",
      "\n",
      "Epoch: 30 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.015789 \\Test Loss: 0.018849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1677\n",
      "           1       0.59      0.57      0.58       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.76      0.77      1883\n",
      "weighted avg       0.91      0.91      0.91      1883\n",
      "\n",
      "Epoch: 31 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.016036 \\Test Loss: 0.024380\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1677\n",
      "           1       0.46      0.78      0.58       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.71      0.83      0.75      1883\n",
      "weighted avg       0.91      0.88      0.89      1883\n",
      "\n",
      "Epoch: 32 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.015619 \\Test Loss: 0.018595\n",
      "Test loss decreased (0.018642 --> 0.018595). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      1677\n",
      "           1       0.37      0.86      0.51       206\n",
      "\n",
      "    accuracy                           0.82      1883\n",
      "   macro avg       0.67      0.84      0.70      1883\n",
      "weighted avg       0.91      0.82      0.85      1883\n",
      "\n",
      "Epoch: 33 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.015032 \\Test Loss: 0.018752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1677\n",
      "           1       0.41      0.84      0.55       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.69      0.85      0.73      1883\n",
      "weighted avg       0.92      0.85      0.87      1883\n",
      "\n",
      "Epoch: 34 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.015370 \\Test Loss: 0.018120\n",
      "Test loss decreased (0.018595 --> 0.018120). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      1677\n",
      "           1       0.37      0.86      0.52       206\n",
      "\n",
      "    accuracy                           0.82      1883\n",
      "   macro avg       0.67      0.84      0.70      1883\n",
      "weighted avg       0.91      0.82      0.85      1883\n",
      "\n",
      "Epoch: 35 | Epoch Time: 1m 2s\n",
      "\tTraining Loss: 0.014750 \\Test Loss: 0.018875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1677\n",
      "           1       0.53      0.69      0.60       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.81      0.77      1883\n",
      "weighted avg       0.91      0.90      0.91      1883\n",
      "\n",
      "Epoch: 36 | Epoch Time: 1m 7s\n",
      "\tTraining Loss: 0.014849 \\Test Loss: 0.020431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      1677\n",
      "           1       0.33      0.89      0.48       206\n",
      "\n",
      "    accuracy                           0.79      1883\n",
      "   macro avg       0.66      0.83      0.67      1883\n",
      "weighted avg       0.91      0.79      0.83      1883\n",
      "\n",
      "Epoch: 37 | Epoch Time: 1m 9s\n",
      "\tTraining Loss: 0.014836 \\Test Loss: 0.019513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1677\n",
      "           1       0.50      0.76      0.61       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.74      0.83      0.77      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 38 | Epoch Time: 1m 8s\n",
      "\tTraining Loss: 0.014825 \\Test Loss: 0.018919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1677\n",
      "           1       0.54      0.72      0.62       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.82      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 39 | Epoch Time: 1m 8s\n",
      "\tTraining Loss: 0.014476 \\Test Loss: 0.020672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94      1677\n",
      "           1       0.50      0.77      0.60       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.84      0.77      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 40 | Epoch Time: 1m 11s\n",
      "\tTraining Loss: 0.014501 \\Test Loss: 0.018890\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      1677\n",
      "           1       0.35      0.91      0.50       206\n",
      "\n",
      "    accuracy                           0.80      1883\n",
      "   macro avg       0.67      0.85      0.69      1883\n",
      "weighted avg       0.92      0.80      0.84      1883\n",
      "\n",
      "Epoch: 41 | Epoch Time: 1m 10s\n",
      "\tTraining Loss: 0.014599 \\Test Loss: 0.019250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      1677\n",
      "           1       0.37      0.87      0.52       206\n",
      "\n",
      "    accuracy                           0.82      1883\n",
      "   macro avg       0.68      0.85      0.71      1883\n",
      "weighted avg       0.91      0.82      0.85      1883\n",
      "\n",
      "Epoch: 42 | Epoch Time: 1m 3s\n",
      "\tTraining Loss: 0.014475 \\Test Loss: 0.018600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1677\n",
      "           1       0.35      0.89      0.50       206\n",
      "\n",
      "    accuracy                           0.81      1883\n",
      "   macro avg       0.67      0.84      0.69      1883\n",
      "weighted avg       0.91      0.81      0.84      1883\n",
      "\n",
      "Epoch: 43 | Epoch Time: 1m 2s\n",
      "\tTraining Loss: 0.014425 \\Test Loss: 0.018689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85      1677\n",
      "           1       0.31      0.91      0.46       206\n",
      "\n",
      "    accuracy                           0.76      1883\n",
      "   macro avg       0.65      0.83      0.65      1883\n",
      "weighted avg       0.91      0.76      0.81      1883\n",
      "\n",
      "Epoch: 44 | Epoch Time: 1m 6s\n",
      "\tTraining Loss: 0.014727 \\Test Loss: 0.020068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1677\n",
      "           1       0.56      0.69      0.62       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.76      0.81      0.78      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 45 | Epoch Time: 1m 5s\n",
      "\tTraining Loss: 0.014553 \\Test Loss: 0.021043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1677\n",
      "           1       0.54      0.69      0.61       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.81      0.77      1883\n",
      "weighted avg       0.91      0.90      0.91      1883\n",
      "\n",
      "Epoch: 46 | Epoch Time: 1m 4s\n",
      "\tTraining Loss: 0.013920 \\Test Loss: 0.020498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1677\n",
      "           1       0.47      0.79      0.59       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.72      0.84      0.76      1883\n",
      "weighted avg       0.92      0.88      0.89      1883\n",
      "\n",
      "Epoch: 47 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.013643 \\Test Loss: 0.018292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1677\n",
      "           1       0.59      0.62      0.60       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.78      0.78      1883\n",
      "weighted avg       0.91      0.91      0.91      1883\n",
      "\n",
      "Epoch: 48 | Epoch Time: 1m 4s\n",
      "\tTraining Loss: 0.013537 \\Test Loss: 0.023632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1677\n",
      "           1       0.47      0.80      0.59       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.72      0.84      0.76      1883\n",
      "weighted avg       0.92      0.88      0.89      1883\n",
      "\n",
      "Epoch: 49 | Epoch Time: 1m 5s\n",
      "\tTraining Loss: 0.013301 \\Test Loss: 0.018343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1677\n",
      "           1       0.52      0.74      0.61       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.74      0.83      0.78      1883\n",
      "weighted avg       0.92      0.90      0.90      1883\n",
      "\n",
      "Epoch: 50 | Epoch Time: 1m 8s\n",
      "\tTraining Loss: 0.013725 \\Test Loss: 0.019415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1677\n",
      "           1       0.54      0.71      0.61       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.82      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 51 | Epoch Time: 1m 12s\n",
      "\tTraining Loss: 0.013481 \\Test Loss: 0.020315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      1677\n",
      "           1       0.44      0.83      0.58       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.71      0.85      0.75      1883\n",
      "weighted avg       0.92      0.87      0.88      1883\n",
      "\n",
      "Epoch: 52 | Epoch Time: 1m 8s\n",
      "\tTraining Loss: 0.013375 \\Test Loss: 0.017952\n",
      "Test loss decreased (0.018120 --> 0.017952). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      1677\n",
      "           1       0.41      0.87      0.56       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.69      0.86      0.73      1883\n",
      "weighted avg       0.92      0.85      0.87      1883\n",
      "\n",
      "Epoch: 53 | Epoch Time: 1m 10s\n",
      "\tTraining Loss: 0.013455 \\Test Loss: 0.017992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      1677\n",
      "           1       0.38      0.89      0.53       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.68      0.85      0.71      1883\n",
      "weighted avg       0.92      0.83      0.85      1883\n",
      "\n",
      "Epoch: 54 | Epoch Time: 1m 12s\n",
      "\tTraining Loss: 0.013410 \\Test Loss: 0.018385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1677\n",
      "           1       0.53      0.74      0.62       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.83      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 55 | Epoch Time: 1m 9s\n",
      "\tTraining Loss: 0.014176 \\Test Loss: 0.018828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      1677\n",
      "           1       0.46      0.83      0.59       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.72      0.85      0.76      1883\n",
      "weighted avg       0.92      0.87      0.89      1883\n",
      "\n",
      "Epoch: 56 | Epoch Time: 1m 2s\n",
      "\tTraining Loss: 0.013063 \\Test Loss: 0.017992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1677\n",
      "           1       0.53      0.72      0.61       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.82      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 57 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.013250 \\Test Loss: 0.019391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1677\n",
      "           1       0.54      0.76      0.63       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.84      0.79      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 58 | Epoch Time: 1m 3s\n",
      "\tTraining Loss: 0.012897 \\Test Loss: 0.019393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      1677\n",
      "           1       0.45      0.82      0.58       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.71      0.85      0.75      1883\n",
      "weighted avg       0.92      0.87      0.89      1883\n",
      "\n",
      "Epoch: 59 | Epoch Time: 1m 4s\n",
      "\tTraining Loss: 0.012845 \\Test Loss: 0.018324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85      1677\n",
      "           1       0.31      0.91      0.46       206\n",
      "\n",
      "    accuracy                           0.77      1883\n",
      "   macro avg       0.65      0.83      0.66      1883\n",
      "weighted avg       0.91      0.77      0.81      1883\n",
      "\n",
      "Epoch: 60 | Epoch Time: 1m 1s\n",
      "\tTraining Loss: 0.012736 \\Test Loss: 0.020691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1677\n",
      "           1       0.49      0.79      0.61       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.85      0.77      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 61 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.013079 \\Test Loss: 0.018156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      1677\n",
      "           1       0.35      0.91      0.51       206\n",
      "\n",
      "    accuracy                           0.81      1883\n",
      "   macro avg       0.67      0.85      0.69      1883\n",
      "weighted avg       0.92      0.81      0.84      1883\n",
      "\n",
      "Epoch: 62 | Epoch Time: 1m 0s\n",
      "\tTraining Loss: 0.012634 \\Test Loss: 0.019204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1677\n",
      "           1       0.58      0.62      0.60       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.78      0.77      1883\n",
      "weighted avg       0.91      0.91      0.91      1883\n",
      "\n",
      "Epoch: 63 | Epoch Time: 1m 3s\n",
      "\tTraining Loss: 0.012629 \\Test Loss: 0.022949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      1677\n",
      "           1       0.65      0.52      0.58       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.80      0.74      0.77      1883\n",
      "weighted avg       0.91      0.92      0.91      1883\n",
      "\n",
      "Epoch: 64 | Epoch Time: 1m 3s\n",
      "\tTraining Loss: 0.012389 \\Test Loss: 0.027500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1677\n",
      "           1       0.47      0.80      0.59       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.72      0.84      0.76      1883\n",
      "weighted avg       0.92      0.88      0.89      1883\n",
      "\n",
      "Epoch: 65 | Epoch Time: 1m 12s\n",
      "\tTraining Loss: 0.012586 \\Test Loss: 0.018492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87      1677\n",
      "           1       0.34      0.91      0.50       206\n",
      "\n",
      "    accuracy                           0.80      1883\n",
      "   macro avg       0.66      0.85      0.68      1883\n",
      "weighted avg       0.92      0.80      0.83      1883\n",
      "\n",
      "Epoch: 66 | Epoch Time: 1m 10s\n",
      "\tTraining Loss: 0.012079 \\Test Loss: 0.019067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1677\n",
      "           1       0.53      0.74      0.62       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.83      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 67 | Epoch Time: 1m 10s\n",
      "\tTraining Loss: 0.012594 \\Test Loss: 0.019915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1677\n",
      "           1       0.49      0.79      0.60       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.84      0.77      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 68 | Epoch Time: 1m 11s\n",
      "\tTraining Loss: 0.012166 \\Test Loss: 0.018058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1677\n",
      "           1       0.41      0.87      0.56       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.70      0.86      0.73      1883\n",
      "weighted avg       0.92      0.85      0.87      1883\n",
      "\n",
      "Epoch: 69 | Epoch Time: 1m 12s\n",
      "\tTraining Loss: 0.011911 \\Test Loss: 0.018217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1677\n",
      "           1       0.56      0.66      0.60       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.76      0.80      0.78      1883\n",
      "weighted avg       0.91      0.91      0.91      1883\n",
      "\n",
      "Epoch: 70 | Epoch Time: 1m 5s\n",
      "\tTraining Loss: 0.012387 \\Test Loss: 0.021977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1677\n",
      "           1       0.40      0.90      0.55       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.69      0.87      0.73      1883\n",
      "weighted avg       0.92      0.84      0.86      1883\n",
      "\n",
      "Epoch: 71 | Epoch Time: 1m 2s\n",
      "\tTraining Loss: 0.011988 \\Test Loss: 0.018318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      1677\n",
      "           1       0.37      0.91      0.52       206\n",
      "\n",
      "    accuracy                           0.82      1883\n",
      "   macro avg       0.68      0.86      0.71      1883\n",
      "weighted avg       0.92      0.82      0.85      1883\n",
      "\n",
      "Epoch: 72 | Epoch Time: 1m 2s\n",
      "\tTraining Loss: 0.011419 \\Test Loss: 0.018795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      1677\n",
      "           1       0.35      0.92      0.51       206\n",
      "\n",
      "    accuracy                           0.80      1883\n",
      "   macro avg       0.67      0.85      0.69      1883\n",
      "weighted avg       0.92      0.80      0.84      1883\n",
      "\n",
      "Epoch: 73 | Epoch Time: 1m 5s\n",
      "\tTraining Loss: 0.011357 \\Test Loss: 0.019916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1677\n",
      "           1       0.58      0.66      0.62       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.80      0.78      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 74 | Epoch Time: 1m 6s\n",
      "\tTraining Loss: 0.011923 \\Test Loss: 0.021563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1677\n",
      "           1       0.71      0.53      0.61       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.82      0.75      0.78      1883\n",
      "weighted avg       0.92      0.92      0.92      1883\n",
      "\n",
      "Epoch: 75 | Epoch Time: 1m 5s\n",
      "\tTraining Loss: 0.011343 \\Test Loss: 0.028059\n"
     ]
    }
   ],
   "source": [
    "model = RNNet(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weight))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "test_min_loss = np.inf\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    for inputs, target in train_loader:\n",
    "        model.zero_grad()\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    y_pred_list = []\n",
    "    y_targ_list = []\n",
    "    model.eval()\n",
    "    for inputs, target in test_loader:\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, target)\n",
    "        test_loss += loss.item()\n",
    "        _, y_test_pred = torch.max(output, 1)\n",
    "        y_pred_tag = y_test_pred\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        y_targ_list.append(target.cpu().numpy())\n",
    "    \n",
    "\n",
    "    if(epoch%1 == 0):\n",
    "        y_pred_list = [x.squeeze().tolist() for x in y_pred_list]\n",
    "        y_targ_list = [x.squeeze().tolist() for x in y_targ_list]\n",
    "        y_pred_list = [x for sublist in y_pred_list for x in sublist]\n",
    "        y_targ_list = [x for sublist in y_targ_list for x in sublist]\n",
    "\n",
    "        print(classification_report(y_targ_list, y_pred_list))\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\"\\tTraining Loss: {:.6f} \\Test Loss: {:.6f}\".format(train_loss, test_loss))\n",
    "    if test_loss <= test_min_loss:\n",
    "        print(\"Test loss decreased ({:.6f} --> {:.6f}). Saving model...\".format(test_min_loss, test_loss))\n",
    "        torch.save(model.state_dict(), \"models_rnn_roberta/rnn_bert_model_1_3.pt\")\n",
    "        test_min_loss = test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe86eec",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">Gated RNN</font><br>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40ad5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(GRU_Network, self).__init__()\n",
    "\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf1a077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "HIDDEN_DIM = 512\n",
    "OUTPUT_DIM = 2\n",
    "N_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ace29e9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_Network(\n",
      "  (rnn): GRU(768, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.13      0.23      1677\n",
      "           1       0.12      0.98      0.22       206\n",
      "\n",
      "    accuracy                           0.22      1883\n",
      "   macro avg       0.55      0.56      0.22      1883\n",
      "weighted avg       0.89      0.22      0.23      1883\n",
      "\n",
      "Epoch: 01 | Epoch Time: 3m 33s\n",
      "\tTraining Loss: 0.032791 \\Test Loss: 0.038170\n",
      "Test loss decreased (inf --> 0.038170). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90      1677\n",
      "           1       0.35      0.62      0.45       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.65      0.74      0.68      1883\n",
      "weighted avg       0.88      0.83      0.85      1883\n",
      "\n",
      "Epoch: 02 | Epoch Time: 3m 27s\n",
      "\tTraining Loss: 0.027904 \\Test Loss: 0.024995\n",
      "Test loss decreased (0.038170 --> 0.024995). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      1677\n",
      "           1       0.38      0.69      0.49       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.67      0.78      0.70      1883\n",
      "weighted avg       0.89      0.84      0.86      1883\n",
      "\n",
      "Epoch: 03 | Epoch Time: 3m 25s\n",
      "\tTraining Loss: 0.025401 \\Test Loss: 0.023107\n",
      "Test loss decreased (0.024995 --> 0.023107). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91      1677\n",
      "           1       0.39      0.79      0.52       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.68      0.82      0.71      1883\n",
      "weighted avg       0.91      0.84      0.86      1883\n",
      "\n",
      "Epoch: 04 | Epoch Time: 3m 24s\n",
      "\tTraining Loss: 0.022191 \\Test Loss: 0.020728\n",
      "Test loss decreased (0.023107 --> 0.020728). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.78      1677\n",
      "           1       0.24      0.94      0.39       206\n",
      "\n",
      "    accuracy                           0.68      1883\n",
      "   macro avg       0.62      0.79      0.58      1883\n",
      "weighted avg       0.91      0.68      0.74      1883\n",
      "\n",
      "Epoch: 05 | Epoch Time: 3m 30s\n",
      "\tTraining Loss: 0.020565 \\Test Loss: 0.024077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.82      1677\n",
      "           1       0.28      0.90      0.42       206\n",
      "\n",
      "    accuracy                           0.73      1883\n",
      "   macro avg       0.63      0.80      0.62      1883\n",
      "weighted avg       0.91      0.73      0.78      1883\n",
      "\n",
      "Epoch: 06 | Epoch Time: 3m 18s\n",
      "\tTraining Loss: 0.018601 \\Test Loss: 0.022218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.92      1677\n",
      "           1       0.42      0.81      0.55       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.70      0.83      0.73      1883\n",
      "weighted avg       0.91      0.86      0.88      1883\n",
      "\n",
      "Epoch: 07 | Epoch Time: 3m 17s\n",
      "\tTraining Loss: 0.018762 \\Test Loss: 0.017960\n",
      "Test loss decreased (0.020728 --> 0.017960). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1677\n",
      "           1       0.56      0.75      0.64       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.76      0.84      0.79      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 08 | Epoch Time: 3m 18s\n",
      "\tTraining Loss: 0.015353 \\Test Loss: 0.017703\n",
      "Test loss decreased (0.017960 --> 0.017703). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1677\n",
      "           1       0.65      0.72      0.68       206\n",
      "\n",
      "    accuracy                           0.93      1883\n",
      "   macro avg       0.81      0.84      0.82      1883\n",
      "weighted avg       0.93      0.93      0.93      1883\n",
      "\n",
      "Epoch: 09 | Epoch Time: 3m 30s\n",
      "\tTraining Loss: 0.012897 \\Test Loss: 0.018796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95      1677\n",
      "           1       0.55      0.76      0.64       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.76      0.84      0.79      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 10 | Epoch Time: 3m 25s\n",
      "\tTraining Loss: 0.010112 \\Test Loss: 0.018336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1677\n",
      "           1       0.71      0.68      0.70       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.84      0.82      0.83      1883\n",
      "weighted avg       0.93      0.94      0.93      1883\n",
      "\n",
      "Epoch: 11 | Epoch Time: 3m 31s\n",
      "\tTraining Loss: 0.008641 \\Test Loss: 0.022903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      1677\n",
      "           1       0.46      0.87      0.60       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.72      0.87      0.76      1883\n",
      "weighted avg       0.92      0.87      0.89      1883\n",
      "\n",
      "Epoch: 12 | Epoch Time: 3m 29s\n",
      "\tTraining Loss: 0.005666 \\Test Loss: 0.016482\n",
      "Test loss decreased (0.017703 --> 0.016482). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.95      1677\n",
      "           1       0.61      0.81      0.69       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.79      0.87      0.82      1883\n",
      "weighted avg       0.94      0.92      0.93      1883\n",
      "\n",
      "Epoch: 13 | Epoch Time: 3m 38s\n",
      "\tTraining Loss: 0.004241 \\Test Loss: 0.017061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1677\n",
      "           1       0.72      0.78      0.75       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.85      0.87      0.86      1883\n",
      "weighted avg       0.95      0.94      0.94      1883\n",
      "\n",
      "Epoch: 14 | Epoch Time: 3m 41s\n",
      "\tTraining Loss: 0.003149 \\Test Loss: 0.021878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1677\n",
      "           1       0.39      0.88      0.54       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.69      0.86      0.72      1883\n",
      "weighted avg       0.92      0.84      0.86      1883\n",
      "\n",
      "Epoch: 15 | Epoch Time: 3m 36s\n",
      "\tTraining Loss: 0.003159 \\Test Loss: 0.022875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1677\n",
      "           1       0.73      0.72      0.73       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.85      0.84      0.85      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 16 | Epoch Time: 3m 36s\n",
      "\tTraining Loss: 0.002094 \\Test Loss: 0.029456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1677\n",
      "           1       0.74      0.72      0.73       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.86      0.85      0.85      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 17 | Epoch Time: 3m 33s\n",
      "\tTraining Loss: 0.002228 \\Test Loss: 0.026252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1677\n",
      "           1       0.71      0.68      0.69       206\n",
      "\n",
      "    accuracy                           0.93      1883\n",
      "   macro avg       0.84      0.82      0.83      1883\n",
      "weighted avg       0.93      0.93      0.93      1883\n",
      "\n",
      "Epoch: 18 | Epoch Time: 3m 29s\n",
      "\tTraining Loss: 0.001919 \\Test Loss: 0.033619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1677\n",
      "           1       0.70      0.75      0.73       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.84      0.86      0.85      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 19 | Epoch Time: 79m 30s\n",
      "\tTraining Loss: 0.001296 \\Test Loss: 0.029735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1677\n",
      "           1       0.74      0.73      0.73       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.85      0.85      0.85      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 20 | Epoch Time: 3m 28s\n",
      "\tTraining Loss: 0.001983 \\Test Loss: 0.032882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1677\n",
      "           1       0.74      0.72      0.73       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.85      0.84      0.85      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 21 | Epoch Time: 3m 25s\n",
      "\tTraining Loss: 0.000808 \\Test Loss: 0.038451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1677\n",
      "           1       0.80      0.72      0.76       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.89      0.85      0.87      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 22 | Epoch Time: 3m 18s\n",
      "\tTraining Loss: 0.001056 \\Test Loss: 0.039462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.81      0.70      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.89      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 23 | Epoch Time: 3m 17s\n",
      "\tTraining Loss: 0.000520 \\Test Loss: 0.037867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.81      0.70      0.76       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.89      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 24 | Epoch Time: 3m 17s\n",
      "\tTraining Loss: 0.000265 \\Test Loss: 0.047458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1677\n",
      "           1       0.63      0.78      0.70       206\n",
      "\n",
      "    accuracy                           0.93      1883\n",
      "   macro avg       0.80      0.86      0.83      1883\n",
      "weighted avg       0.93      0.93      0.93      1883\n",
      "\n",
      "Epoch: 25 | Epoch Time: 3m 19s\n",
      "\tTraining Loss: 0.003216 \\Test Loss: 0.021910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1677\n",
      "           1       0.79      0.74      0.76       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.88      0.86      0.87      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 26 | Epoch Time: 3m 30s\n",
      "\tTraining Loss: 0.001394 \\Test Loss: 0.036882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.81      0.68      0.74       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.89      0.83      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 27 | Epoch Time: 3m 28s\n",
      "\tTraining Loss: 0.000489 \\Test Loss: 0.045993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1677\n",
      "           1       0.79      0.71      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.88      0.85      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 28 | Epoch Time: 3m 30s\n",
      "\tTraining Loss: 0.000759 \\Test Loss: 0.042938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1677\n",
      "           1       0.71      0.75      0.73       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.84      0.86      0.85      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 29 | Epoch Time: 3m 34s\n",
      "\tTraining Loss: 0.000416 \\Test Loss: 0.037072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1677\n",
      "           1       0.65      0.75      0.70       206\n",
      "\n",
      "    accuracy                           0.93      1883\n",
      "   macro avg       0.81      0.85      0.83      1883\n",
      "weighted avg       0.93      0.93      0.93      1883\n",
      "\n",
      "Epoch: 30 | Epoch Time: 3m 24s\n",
      "\tTraining Loss: 0.001827 \\Test Loss: 0.039236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1677\n",
      "           1       0.81      0.61      0.69       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.88      0.79      0.83      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 31 | Epoch Time: 3m 36s\n",
      "\tTraining Loss: 0.000975 \\Test Loss: 0.063824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1677\n",
      "           1       0.74      0.68      0.71       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.85      0.83      0.84      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 32 | Epoch Time: 3m 49s\n",
      "\tTraining Loss: 0.000788 \\Test Loss: 0.045034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      1677\n",
      "           1       0.86      0.51      0.64       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.90      0.75      0.80      1883\n",
      "weighted avg       0.93      0.94      0.93      1883\n",
      "\n",
      "Epoch: 33 | Epoch Time: 3m 48s\n",
      "\tTraining Loss: 0.000223 \\Test Loss: 0.081169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1677\n",
      "           1       0.75      0.74      0.75       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.86      0.85      0.86      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 34 | Epoch Time: 3m 48s\n",
      "\tTraining Loss: 0.001133 \\Test Loss: 0.039825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.80      0.70      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.88      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 35 | Epoch Time: 3m 45s\n",
      "\tTraining Loss: 0.000202 \\Test Loss: 0.050997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1677\n",
      "           1       0.77      0.72      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.87      0.85      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 36 | Epoch Time: 3m 47s\n",
      "\tTraining Loss: 0.000117 \\Test Loss: 0.048223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.81      0.70      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.88      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 37 | Epoch Time: 3m 56s\n",
      "\tTraining Loss: 0.000058 \\Test Loss: 0.056528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.83      0.67      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.90      0.83      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 38 | Epoch Time: 3m 59s\n",
      "\tTraining Loss: 0.000031 \\Test Loss: 0.064483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.80      0.70      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.88      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 39 | Epoch Time: 3m 57s\n",
      "\tTraining Loss: 0.000032 \\Test Loss: 0.057990\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.83      0.67      0.74       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.90      0.83      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 40 | Epoch Time: 3m 56s\n",
      "\tTraining Loss: 0.000023 \\Test Loss: 0.067534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.81      0.71      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.89      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 41 | Epoch Time: 3m 49s\n",
      "\tTraining Loss: 0.000023 \\Test Loss: 0.061413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.81      0.71      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.89      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 42 | Epoch Time: 3m 30s\n",
      "\tTraining Loss: 0.000015 \\Test Loss: 0.060986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.83      0.66      0.73       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.90      0.82      0.85      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 43 | Epoch Time: 3m 21s\n",
      "\tTraining Loss: 0.000040 \\Test Loss: 0.066547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1677\n",
      "           1       0.76      0.67      0.72       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.86      0.82      0.84      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 44 | Epoch Time: 3m 27s\n",
      "\tTraining Loss: 0.004977 \\Test Loss: 0.038880\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94      1677\n",
      "           1       0.54      0.82      0.65       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.76      0.87      0.80      1883\n",
      "weighted avg       0.93      0.90      0.91      1883\n",
      "\n",
      "Epoch: 45 | Epoch Time: 3m 22s\n",
      "\tTraining Loss: 0.002239 \\Test Loss: 0.027260\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1677\n",
      "           1       0.73      0.70      0.72       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.85      0.83      0.84      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 46 | Epoch Time: 3m 22s\n",
      "\tTraining Loss: 0.001453 \\Test Loss: 0.037748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1677\n",
      "           1       0.68      0.76      0.72       206\n",
      "\n",
      "    accuracy                           0.94      1883\n",
      "   macro avg       0.83      0.86      0.84      1883\n",
      "weighted avg       0.94      0.94      0.94      1883\n",
      "\n",
      "Epoch: 47 | Epoch Time: 3m 28s\n",
      "\tTraining Loss: 0.001549 \\Test Loss: 0.036703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.79      0.71      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.88      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 48 | Epoch Time: 3m 18s\n",
      "\tTraining Loss: 0.000636 \\Test Loss: 0.045875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.80      0.70      0.74       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.88      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 49 | Epoch Time: 3m 24s\n",
      "\tTraining Loss: 0.000114 \\Test Loss: 0.051015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.81      0.70      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.89      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 50 | Epoch Time: 3m 29s\n",
      "\tTraining Loss: 0.000037 \\Test Loss: 0.052050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.80      0.70      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.88      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 51 | Epoch Time: 3m 33s\n",
      "\tTraining Loss: 0.000027 \\Test Loss: 0.050581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.84      0.69      0.76       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.90      0.84      0.87      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 52 | Epoch Time: 3m 29s\n",
      "\tTraining Loss: 0.000026 \\Test Loss: 0.056630\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.84      0.69      0.76       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.90      0.84      0.87      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 53 | Epoch Time: 3m 28s\n",
      "\tTraining Loss: 0.000024 \\Test Loss: 0.058323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.85      0.69      0.76       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.90      0.84      0.87      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 54 | Epoch Time: 3m 20s\n",
      "\tTraining Loss: 0.000029 \\Test Loss: 0.059774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.81      0.70      0.75       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.89      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 55 | Epoch Time: 3m 19s\n",
      "\tTraining Loss: 0.000027 \\Test Loss: 0.055726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1677\n",
      "           1       0.83      0.69      0.76       206\n",
      "\n",
      "    accuracy                           0.95      1883\n",
      "   macro avg       0.90      0.84      0.86      1883\n",
      "weighted avg       0.95      0.95      0.95      1883\n",
      "\n",
      "Epoch: 56 | Epoch Time: 3m 22s\n",
      "\tTraining Loss: 0.000023 \\Test Loss: 0.061590\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1677\n",
      "           1       0.71      0.67      0.69       206\n",
      "\n",
      "    accuracy                           0.93      1883\n",
      "   macro avg       0.84      0.82      0.83      1883\n",
      "weighted avg       0.93      0.93      0.93      1883\n",
      "\n",
      "Epoch: 57 | Epoch Time: 3m 24s\n",
      "\tTraining Loss: 0.001287 \\Test Loss: 0.035680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m model_gru(inputs)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     19\u001b[0m optimizer_gru\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_gru = GRU_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_gru)\n",
    "test_min_loss = np.inf\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weight))\n",
    "optimizer_gru = optim.Adam(model_gru.parameters(), lr=1e-3)\n",
    "    \n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model_gru.train()\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    for inputs, target in train_loader:\n",
    "        model_gru.zero_grad()\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model_gru(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer_gru.step()\n",
    "\n",
    "    y_pred_list = []\n",
    "    y_targ_list = []\n",
    "    model_gru.eval()\n",
    "    for inputs, target in test_loader:\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model_gru(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        _, y_test_pred = torch.max(output, 1)\n",
    "        y_pred_tag = y_test_pred\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        y_targ_list.append(target.cpu().numpy())\n",
    "    \n",
    "\n",
    "    if(epoch%1 == 0):\n",
    "        y_pred_list = [x.squeeze().tolist() for x in y_pred_list]\n",
    "        y_targ_list = [x.squeeze().tolist() for x in y_targ_list]\n",
    "        y_pred_list = [x for sublist in y_pred_list for x in sublist]\n",
    "        y_targ_list = [x for sublist in y_targ_list for x in sublist]\n",
    "\n",
    "        print(classification_report(y_targ_list, y_pred_list))\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\"\\tTraining Loss: {:.6f} \\Test Loss: {:.6f}\".format(train_loss, test_loss))\n",
    "    if test_loss <= test_min_loss:\n",
    "        print(\"Test loss decreased ({:.6f} --> {:.6f}). Saving model...\".format(test_min_loss, test_loss))\n",
    "        torch.save(model_gru.state_dict(), \"models_gru_roberta/gru_bert_model_1_3.pt\")\n",
    "        test_min_loss = test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdd129",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">LSTM</font><br>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95d8d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "\n",
    "class LSTM_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(LSTM_Network, self).__init__()\n",
    "\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "        c0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05618834",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Network(\n",
      "  (lstm): LSTM(768, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.43      0.59      1677\n",
      "           1       0.16      0.89      0.27       206\n",
      "\n",
      "    accuracy                           0.48      1883\n",
      "   macro avg       0.57      0.66      0.43      1883\n",
      "weighted avg       0.88      0.48      0.56      1883\n",
      "\n",
      "Epoch: 01 | Epoch Time: 5m 34s\n",
      "\tTraining Loss: 0.033429 \\Test Loss: 0.031960\n",
      "Test loss decreased (inf --> 0.031960). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.62      0.75      1677\n",
      "           1       0.22      0.87      0.35       206\n",
      "\n",
      "    accuracy                           0.64      1883\n",
      "   macro avg       0.60      0.74      0.55      1883\n",
      "weighted avg       0.89      0.64      0.71      1883\n",
      "\n",
      "Epoch: 02 | Epoch Time: 5m 18s\n",
      "\tTraining Loss: 0.029390 \\Test Loss: 0.027660\n",
      "Test loss decreased (0.031960 --> 0.027660). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83      1677\n",
      "           1       0.27      0.84      0.41       206\n",
      "\n",
      "    accuracy                           0.74      1883\n",
      "   macro avg       0.62      0.78      0.62      1883\n",
      "weighted avg       0.90      0.74      0.78      1883\n",
      "\n",
      "Epoch: 03 | Epoch Time: 5m 13s\n",
      "\tTraining Loss: 0.026289 \\Test Loss: 0.024728\n",
      "Test loss decreased (0.027660 --> 0.024728). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      1677\n",
      "           1       0.41      0.61      0.49       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.68      0.75      0.70      1883\n",
      "weighted avg       0.89      0.86      0.87      1883\n",
      "\n",
      "Epoch: 04 | Epoch Time: 5m 35s\n",
      "\tTraining Loss: 0.023752 \\Test Loss: 0.023486\n",
      "Test loss decreased (0.024728 --> 0.023486). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.89      1677\n",
      "           1       0.36      0.79      0.50       206\n",
      "\n",
      "    accuracy                           0.82      1883\n",
      "   macro avg       0.67      0.81      0.69      1883\n",
      "weighted avg       0.90      0.82      0.85      1883\n",
      "\n",
      "Epoch: 05 | Epoch Time: 5m 29s\n",
      "\tTraining Loss: 0.021998 \\Test Loss: 0.021383\n",
      "Test loss decreased (0.023486 --> 0.021383). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1677\n",
      "           1       0.47      0.65      0.55       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.71      0.78      0.74      1883\n",
      "weighted avg       0.90      0.88      0.89      1883\n",
      "\n",
      "Epoch: 06 | Epoch Time: 5m 23s\n",
      "\tTraining Loss: 0.020986 \\Test Loss: 0.022563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      1677\n",
      "           1       0.41      0.73      0.52       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.69      0.80      0.72      1883\n",
      "weighted avg       0.90      0.86      0.87      1883\n",
      "\n",
      "Epoch: 07 | Epoch Time: 5m 11s\n",
      "\tTraining Loss: 0.021906 \\Test Loss: 0.020843\n",
      "Test loss decreased (0.021383 --> 0.020843). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1677\n",
      "           1       0.46      0.70      0.55       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.71      0.80      0.74      1883\n",
      "weighted avg       0.91      0.88      0.89      1883\n",
      "\n",
      "Epoch: 08 | Epoch Time: 4m 53s\n",
      "\tTraining Loss: 0.020095 \\Test Loss: 0.020999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1677\n",
      "           1       0.47      0.69      0.56       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.71      0.80      0.75      1883\n",
      "weighted avg       0.91      0.88      0.89      1883\n",
      "\n",
      "Epoch: 09 | Epoch Time: 5m 2s\n",
      "\tTraining Loss: 0.019736 \\Test Loss: 0.021135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      1677\n",
      "           1       0.41      0.78      0.53       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.69      0.82      0.72      1883\n",
      "weighted avg       0.91      0.85      0.87      1883\n",
      "\n",
      "Epoch: 10 | Epoch Time: 5m 1s\n",
      "\tTraining Loss: 0.018973 \\Test Loss: 0.019664\n",
      "Test loss decreased (0.020843 --> 0.019664). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1677\n",
      "           1       0.46      0.69      0.55       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.71      0.80      0.74      1883\n",
      "weighted avg       0.90      0.88      0.89      1883\n",
      "\n",
      "Epoch: 11 | Epoch Time: 6m 21s\n",
      "\tTraining Loss: 0.018675 \\Test Loss: 0.020528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1677\n",
      "           1       0.42      0.77      0.54       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.69      0.82      0.73      1883\n",
      "weighted avg       0.91      0.86      0.87      1883\n",
      "\n",
      "Epoch: 12 | Epoch Time: 5m 7s\n",
      "\tTraining Loss: 0.017770 \\Test Loss: 0.019505\n",
      "Test loss decreased (0.019664 --> 0.019505). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1677\n",
      "           1       0.48      0.67      0.56       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.72      0.79      0.75      1883\n",
      "weighted avg       0.91      0.89      0.89      1883\n",
      "\n",
      "Epoch: 13 | Epoch Time: 4m 55s\n",
      "\tTraining Loss: 0.018606 \\Test Loss: 0.020659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93      1677\n",
      "           1       0.45      0.72      0.56       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.71      0.81      0.74      1883\n",
      "weighted avg       0.91      0.87      0.89      1883\n",
      "\n",
      "Epoch: 14 | Epoch Time: 8m 54s\n",
      "\tTraining Loss: 0.018181 \\Test Loss: 0.019607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1677\n",
      "           1       0.46      0.72      0.56       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.71      0.81      0.74      1883\n",
      "weighted avg       0.91      0.88      0.89      1883\n",
      "\n",
      "Epoch: 15 | Epoch Time: 7m 54s\n",
      "\tTraining Loss: 0.017885 \\Test Loss: 0.019484\n",
      "Test loss decreased (0.019505 --> 0.019484). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1677\n",
      "           1       0.39      0.83      0.53       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.68      0.84      0.72      1883\n",
      "weighted avg       0.91      0.84      0.86      1883\n",
      "\n",
      "Epoch: 16 | Epoch Time: 5m 20s\n",
      "\tTraining Loss: 0.017447 \\Test Loss: 0.019063\n",
      "Test loss decreased (0.019484 --> 0.019063). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1677\n",
      "           1       0.43      0.78      0.55       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.70      0.83      0.74      1883\n",
      "weighted avg       0.91      0.86      0.88      1883\n",
      "\n",
      "Epoch: 17 | Epoch Time: 5m 7s\n",
      "\tTraining Loss: 0.017457 \\Test Loss: 0.018773\n",
      "Test loss decreased (0.019063 --> 0.018773). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1677\n",
      "           1       0.35      0.87      0.50       206\n",
      "\n",
      "    accuracy                           0.81      1883\n",
      "   macro avg       0.66      0.84      0.69      1883\n",
      "weighted avg       0.91      0.81      0.84      1883\n",
      "\n",
      "Epoch: 18 | Epoch Time: 5m 9s\n",
      "\tTraining Loss: 0.017300 \\Test Loss: 0.019348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1677\n",
      "           1       0.44      0.82      0.57       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.70      0.84      0.74      1883\n",
      "weighted avg       0.92      0.86      0.88      1883\n",
      "\n",
      "Epoch: 19 | Epoch Time: 5m 13s\n",
      "\tTraining Loss: 0.016716 \\Test Loss: 0.018516\n",
      "Test loss decreased (0.018773 --> 0.018516). Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1677\n",
      "           1       0.55      0.67      0.60       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.76      0.80      0.77      1883\n",
      "weighted avg       0.91      0.90      0.91      1883\n",
      "\n",
      "Epoch: 20 | Epoch Time: 5m 14s\n",
      "\tTraining Loss: 0.016358 \\Test Loss: 0.021525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1677\n",
      "           1       0.64      0.53      0.58       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.79      0.75      0.77      1883\n",
      "weighted avg       0.91      0.92      0.91      1883\n",
      "\n",
      "Epoch: 21 | Epoch Time: 5m 0s\n",
      "\tTraining Loss: 0.016672 \\Test Loss: 0.026087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1677\n",
      "           1       0.43      0.79      0.56       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.70      0.83      0.74      1883\n",
      "weighted avg       0.91      0.86      0.88      1883\n",
      "\n",
      "Epoch: 22 | Epoch Time: 4m 43s\n",
      "\tTraining Loss: 0.015945 \\Test Loss: 0.018493\n",
      "Test loss decreased (0.018516 --> 0.018493). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.88      1677\n",
      "           1       0.35      0.86      0.50       206\n",
      "\n",
      "    accuracy                           0.81      1883\n",
      "   macro avg       0.67      0.83      0.69      1883\n",
      "weighted avg       0.91      0.81      0.84      1883\n",
      "\n",
      "Epoch: 23 | Epoch Time: 4m 46s\n",
      "\tTraining Loss: 0.015897 \\Test Loss: 0.019519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1677\n",
      "           1       0.52      0.69      0.59       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.74      0.81      0.77      1883\n",
      "weighted avg       0.91      0.90      0.90      1883\n",
      "\n",
      "Epoch: 24 | Epoch Time: 4m 55s\n",
      "\tTraining Loss: 0.015895 \\Test Loss: 0.020005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1677\n",
      "           1       0.40      0.84      0.54       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.69      0.84      0.72      1883\n",
      "weighted avg       0.91      0.84      0.86      1883\n",
      "\n",
      "Epoch: 25 | Epoch Time: 4m 54s\n",
      "\tTraining Loss: 0.015444 \\Test Loss: 0.018260\n",
      "Test loss decreased (0.018493 --> 0.018260). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1677\n",
      "           1       0.41      0.84      0.55       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.69      0.84      0.73      1883\n",
      "weighted avg       0.91      0.85      0.87      1883\n",
      "\n",
      "Epoch: 26 | Epoch Time: 4m 57s\n",
      "\tTraining Loss: 0.016024 \\Test Loss: 0.018381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1677\n",
      "           1       0.49      0.75      0.59       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.83      0.76      1883\n",
      "weighted avg       0.91      0.89      0.90      1883\n",
      "\n",
      "Epoch: 27 | Epoch Time: 5m 10s\n",
      "\tTraining Loss: 0.015222 \\Test Loss: 0.018546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1677\n",
      "           1       0.46      0.79      0.58       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.72      0.84      0.76      1883\n",
      "weighted avg       0.92      0.88      0.89      1883\n",
      "\n",
      "Epoch: 28 | Epoch Time: 4m 58s\n",
      "\tTraining Loss: 0.015335 \\Test Loss: 0.018297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1677\n",
      "           1       0.55      0.67      0.60       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.80      0.77      1883\n",
      "weighted avg       0.91      0.90      0.91      1883\n",
      "\n",
      "Epoch: 29 | Epoch Time: 4m 51s\n",
      "\tTraining Loss: 0.015463 \\Test Loss: 0.020554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1677\n",
      "           1       0.49      0.80      0.61       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.85      0.77      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 30 | Epoch Time: 4m 55s\n",
      "\tTraining Loss: 0.014499 \\Test Loss: 0.018932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1677\n",
      "           1       0.51      0.70      0.59       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.74      0.81      0.77      1883\n",
      "weighted avg       0.91      0.89      0.90      1883\n",
      "\n",
      "Epoch: 31 | Epoch Time: 4m 54s\n",
      "\tTraining Loss: 0.014767 \\Test Loss: 0.020133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1677\n",
      "           1       0.55      0.69      0.61       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.81      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 32 | Epoch Time: 4m 57s\n",
      "\tTraining Loss: 0.014933 \\Test Loss: 0.020245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1677\n",
      "           1       0.58      0.65      0.61       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.80      0.78      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 33 | Epoch Time: 4m 55s\n",
      "\tTraining Loss: 0.014569 \\Test Loss: 0.021687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1677\n",
      "           1       0.57      0.69      0.63       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.81      0.79      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 34 | Epoch Time: 4m 55s\n",
      "\tTraining Loss: 0.014583 \\Test Loss: 0.021097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.93      1677\n",
      "           1       0.46      0.81      0.59       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.72      0.85      0.76      1883\n",
      "weighted avg       0.92      0.87      0.89      1883\n",
      "\n",
      "Epoch: 35 | Epoch Time: 5m 6s\n",
      "\tTraining Loss: 0.013703 \\Test Loss: 0.017704\n",
      "Test loss decreased (0.018260 --> 0.017704). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92      1677\n",
      "           1       0.45      0.83      0.58       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.71      0.85      0.75      1883\n",
      "weighted avg       0.92      0.87      0.89      1883\n",
      "\n",
      "Epoch: 36 | Epoch Time: 5m 9s\n",
      "\tTraining Loss: 0.014260 \\Test Loss: 0.017324\n",
      "Test loss decreased (0.017704 --> 0.017324). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      1677\n",
      "           1       0.31      0.92      0.46       206\n",
      "\n",
      "    accuracy                           0.76      1883\n",
      "   macro avg       0.65      0.83      0.65      1883\n",
      "weighted avg       0.91      0.76      0.81      1883\n",
      "\n",
      "Epoch: 37 | Epoch Time: 5m 5s\n",
      "\tTraining Loss: 0.013872 \\Test Loss: 0.021236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1677\n",
      "           1       0.52      0.74      0.61       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.74      0.83      0.78      1883\n",
      "weighted avg       0.92      0.90      0.90      1883\n",
      "\n",
      "Epoch: 38 | Epoch Time: 5m 2s\n",
      "\tTraining Loss: 0.013987 \\Test Loss: 0.019321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1677\n",
      "           1       0.56      0.70      0.62       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.76      0.82      0.78      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 39 | Epoch Time: 5m 6s\n",
      "\tTraining Loss: 0.013323 \\Test Loss: 0.019921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1677\n",
      "           1       0.54      0.68      0.60       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.80      0.77      1883\n",
      "weighted avg       0.91      0.90      0.91      1883\n",
      "\n",
      "Epoch: 40 | Epoch Time: 4m 58s\n",
      "\tTraining Loss: 0.013047 \\Test Loss: 0.020871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1677\n",
      "           1       0.53      0.74      0.62       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.83      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 41 | Epoch Time: 4m 52s\n",
      "\tTraining Loss: 0.013374 \\Test Loss: 0.018890\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1677\n",
      "           1       0.57      0.69      0.62       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.81      0.79      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 42 | Epoch Time: 5m 7s\n",
      "\tTraining Loss: 0.012542 \\Test Loss: 0.021317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1677\n",
      "           1       0.36      0.89      0.51       206\n",
      "\n",
      "    accuracy                           0.81      1883\n",
      "   macro avg       0.67      0.85      0.70      1883\n",
      "weighted avg       0.92      0.81      0.84      1883\n",
      "\n",
      "Epoch: 43 | Epoch Time: 4m 57s\n",
      "\tTraining Loss: 0.012786 \\Test Loss: 0.019605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94      1677\n",
      "           1       0.51      0.81      0.62       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.74      0.86      0.78      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 44 | Epoch Time: 5m 18s\n",
      "\tTraining Loss: 0.012767 \\Test Loss: 0.018372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      1677\n",
      "           1       0.44      0.86      0.58       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.71      0.86      0.75      1883\n",
      "weighted avg       0.92      0.87      0.88      1883\n",
      "\n",
      "Epoch: 45 | Epoch Time: 5m 5s\n",
      "\tTraining Loss: 0.012006 \\Test Loss: 0.018474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1677\n",
      "           1       0.53      0.76      0.62       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.84      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 46 | Epoch Time: 5m 25s\n",
      "\tTraining Loss: 0.012083 \\Test Loss: 0.017672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1677\n",
      "           1       0.62      0.63      0.63       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.79      0.79      0.79      1883\n",
      "weighted avg       0.92      0.92      0.92      1883\n",
      "\n",
      "Epoch: 47 | Epoch Time: 5m 39s\n",
      "\tTraining Loss: 0.010186 \\Test Loss: 0.023668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      1677\n",
      "           1       0.60      0.65      0.63       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.78      0.80      0.79      1883\n",
      "weighted avg       0.92      0.92      0.92      1883\n",
      "\n",
      "Epoch: 48 | Epoch Time: 5m 28s\n",
      "\tTraining Loss: 0.010022 \\Test Loss: 0.022909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1677\n",
      "           1       0.61      0.70      0.65       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.78      0.82      0.80      1883\n",
      "weighted avg       0.92      0.92      0.92      1883\n",
      "\n",
      "Epoch: 49 | Epoch Time: 18m 14s\n",
      "\tTraining Loss: 0.008617 \\Test Loss: 0.023466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      1677\n",
      "           1       0.47      0.83      0.60       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.72      0.86      0.76      1883\n",
      "weighted avg       0.92      0.88      0.89      1883\n",
      "\n",
      "Epoch: 50 | Epoch Time: 5m 27s\n",
      "\tTraining Loss: 0.007554 \\Test Loss: 0.018123\n"
     ]
    }
   ],
   "source": [
    "model_lstm = LSTM_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_lstm)\n",
    "\n",
    "test_min_loss = np.inf\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weight))\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=1e-3)\n",
    "    \n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model_lstm.train()\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    for inputs, target in train_loader:\n",
    "        model_lstm.zero_grad()\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model_lstm(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    y_pred_list = []\n",
    "    y_targ_list = []\n",
    "    model_lstm.eval()\n",
    "    for inputs, target in test_loader:\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model_lstm(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        _, y_test_pred = torch.max(output, 1)\n",
    "        y_pred_tag = y_test_pred\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        y_targ_list.append(target.cpu().numpy())\n",
    "    \n",
    "\n",
    "    if(epoch%1 == 0):\n",
    "        y_pred_list = [x.squeeze().tolist() for x in y_pred_list]\n",
    "        y_targ_list = [x.squeeze().tolist() for x in y_targ_list]\n",
    "        y_pred_list = [x for sublist in y_pred_list for x in sublist]\n",
    "        y_targ_list = [x for sublist in y_targ_list for x in sublist]\n",
    "\n",
    "        print(classification_report(y_targ_list, y_pred_list))\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\"\\tTraining Loss: {:.6f} \\Test Loss: {:.6f}\".format(train_loss, test_loss))\n",
    "    if test_loss <= test_min_loss:\n",
    "        print(\"Test loss decreased ({:.6f} --> {:.6f}). Saving model...\".format(test_min_loss, test_loss))\n",
    "        torch.save(model_lstm.state_dict(), \"models_lstm_roberta/lstm_bert_model_1_3.pt\")\n",
    "        test_min_loss = test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cff721",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">Bi-LSTM</font><br>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3bcb948",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bi_LSTM_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(Bi_LSTM_Network, self).__init__()\n",
    "\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1 * 2, x.size(0), self.hidden_dim))\n",
    "        c0 = Variable(torch.zeros(1 * 2, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a277bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi_LSTM_Network(\n",
      "  (lstm): LSTM(768, 512, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      1677\n",
      "           1       0.34      0.49      0.40       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.64      0.69      0.66      1883\n",
      "weighted avg       0.87      0.84      0.85      1883\n",
      "\n",
      "Epoch: 01 | Epoch Time: 11m 53s\n",
      "\tTraining Loss: 0.032383 \\Test Loss: 0.028116\n",
      "Test loss decreased (inf --> 0.028116). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1677\n",
      "           1       0.44      0.38      0.41       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.68      0.66      0.67      1883\n",
      "weighted avg       0.87      0.88      0.88      1883\n",
      "\n",
      "Epoch: 02 | Epoch Time: 12m 28s\n",
      "\tTraining Loss: 0.027589 \\Test Loss: 0.028915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85      1677\n",
      "           1       0.30      0.83      0.44       206\n",
      "\n",
      "    accuracy                           0.77      1883\n",
      "   macro avg       0.63      0.79      0.64      1883\n",
      "weighted avg       0.90      0.77      0.81      1883\n",
      "\n",
      "Epoch: 03 | Epoch Time: 11m 58s\n",
      "\tTraining Loss: 0.024640 \\Test Loss: 0.022823\n",
      "Test loss decreased (0.028116 --> 0.022823). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77      1677\n",
      "           1       0.24      0.93      0.38       206\n",
      "\n",
      "    accuracy                           0.66      1883\n",
      "   macro avg       0.61      0.78      0.57      1883\n",
      "weighted avg       0.90      0.66      0.73      1883\n",
      "\n",
      "Epoch: 04 | Epoch Time: 42m 4s\n",
      "\tTraining Loss: 0.022541 \\Test Loss: 0.024989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88      1677\n",
      "           1       0.34      0.81      0.48       206\n",
      "\n",
      "    accuracy                           0.81      1883\n",
      "   macro avg       0.66      0.81      0.68      1883\n",
      "weighted avg       0.90      0.81      0.84      1883\n",
      "\n",
      "Epoch: 05 | Epoch Time: 11m 53s\n",
      "\tTraining Loss: 0.021461 \\Test Loss: 0.020753\n",
      "Test loss decreased (0.022823 --> 0.020753). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.89      1677\n",
      "           1       0.36      0.79      0.50       206\n",
      "\n",
      "    accuracy                           0.82      1883\n",
      "   macro avg       0.67      0.81      0.69      1883\n",
      "weighted avg       0.90      0.82      0.85      1883\n",
      "\n",
      "Epoch: 06 | Epoch Time: 10m 14s\n",
      "\tTraining Loss: 0.020140 \\Test Loss: 0.020225\n",
      "Test loss decreased (0.020753 --> 0.020225). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1677\n",
      "           1       0.42      0.76      0.54       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.69      0.82      0.73      1883\n",
      "weighted avg       0.91      0.86      0.87      1883\n",
      "\n",
      "Epoch: 07 | Epoch Time: 11m 40s\n",
      "\tTraining Loss: 0.020269 \\Test Loss: 0.019973\n",
      "Test loss decreased (0.020225 --> 0.019973). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      1677\n",
      "           1       0.40      0.78      0.53       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.68      0.82      0.72      1883\n",
      "weighted avg       0.91      0.85      0.87      1883\n",
      "\n",
      "Epoch: 08 | Epoch Time: 11m 22s\n",
      "\tTraining Loss: 0.019211 \\Test Loss: 0.019830\n",
      "Test loss decreased (0.019973 --> 0.019830). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90      1677\n",
      "           1       0.39      0.81      0.53       206\n",
      "\n",
      "    accuracy                           0.84      1883\n",
      "   macro avg       0.68      0.83      0.72      1883\n",
      "weighted avg       0.91      0.84      0.86      1883\n",
      "\n",
      "Epoch: 09 | Epoch Time: 11m 16s\n",
      "\tTraining Loss: 0.020769 \\Test Loss: 0.019660\n",
      "Test loss decreased (0.019830 --> 0.019660). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.83      1677\n",
      "           1       0.29      0.90      0.43       206\n",
      "\n",
      "    accuracy                           0.74      1883\n",
      "   macro avg       0.63      0.81      0.63      1883\n",
      "weighted avg       0.91      0.74      0.79      1883\n",
      "\n",
      "Epoch: 10 | Epoch Time: 12m 39s\n",
      "\tTraining Loss: 0.018980 \\Test Loss: 0.021194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      1677\n",
      "           1       0.44      0.73      0.55       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.70      0.81      0.74      1883\n",
      "weighted avg       0.91      0.87      0.88      1883\n",
      "\n",
      "Epoch: 11 | Epoch Time: 12m 17s\n",
      "\tTraining Loss: 0.018275 \\Test Loss: 0.019609\n",
      "Test loss decreased (0.019660 --> 0.019609). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.49      0.66      1677\n",
      "           1       0.19      0.96      0.32       206\n",
      "\n",
      "    accuracy                           0.54      1883\n",
      "   macro avg       0.59      0.73      0.49      1883\n",
      "weighted avg       0.90      0.54      0.62      1883\n",
      "\n",
      "Epoch: 12 | Epoch Time: 11m 38s\n",
      "\tTraining Loss: 0.018798 \\Test Loss: 0.029439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89      1677\n",
      "           1       0.36      0.86      0.51       206\n",
      "\n",
      "    accuracy                           0.82      1883\n",
      "   macro avg       0.67      0.84      0.70      1883\n",
      "weighted avg       0.91      0.82      0.85      1883\n",
      "\n",
      "Epoch: 13 | Epoch Time: 11m 18s\n",
      "\tTraining Loss: 0.018358 \\Test Loss: 0.019098\n",
      "Test loss decreased (0.019609 --> 0.019098). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1677\n",
      "           1       0.51      0.63      0.56       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.78      0.75      1883\n",
      "weighted avg       0.90      0.89      0.90      1883\n",
      "\n",
      "Epoch: 14 | Epoch Time: 27m 17s\n",
      "\tTraining Loss: 0.018055 \\Test Loss: 0.021053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82      1677\n",
      "           1       0.28      0.94      0.43       206\n",
      "\n",
      "    accuracy                           0.73      1883\n",
      "   macro avg       0.63      0.82      0.62      1883\n",
      "weighted avg       0.91      0.73      0.78      1883\n",
      "\n",
      "Epoch: 15 | Epoch Time: 11m 33s\n",
      "\tTraining Loss: 0.017787 \\Test Loss: 0.021612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1677\n",
      "           1       0.43      0.81      0.56       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.70      0.84      0.74      1883\n",
      "weighted avg       0.91      0.86      0.88      1883\n",
      "\n",
      "Epoch: 16 | Epoch Time: 12m 19s\n",
      "\tTraining Loss: 0.017442 \\Test Loss: 0.018457\n",
      "Test loss decreased (0.019098 --> 0.018457). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1677\n",
      "           1       0.38      0.83      0.52       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.68      0.83      0.71      1883\n",
      "weighted avg       0.91      0.83      0.86      1883\n",
      "\n",
      "Epoch: 17 | Epoch Time: 10m 47s\n",
      "\tTraining Loss: 0.016941 \\Test Loss: 0.018547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1677\n",
      "           1       0.43      0.81      0.57       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.70      0.84      0.74      1883\n",
      "weighted avg       0.91      0.86      0.88      1883\n",
      "\n",
      "Epoch: 18 | Epoch Time: 10m 49s\n",
      "\tTraining Loss: 0.017354 \\Test Loss: 0.018166\n",
      "Test loss decreased (0.018457 --> 0.018166). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.79      1677\n",
      "           1       0.25      0.96      0.40       206\n",
      "\n",
      "    accuracy                           0.69      1883\n",
      "   macro avg       0.62      0.80      0.59      1883\n",
      "weighted avg       0.91      0.69      0.75      1883\n",
      "\n",
      "Epoch: 19 | Epoch Time: 20m 41s\n",
      "\tTraining Loss: 0.016498 \\Test Loss: 0.024060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1677\n",
      "           1       0.54      0.64      0.59       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.79      0.76      1883\n",
      "weighted avg       0.91      0.90      0.90      1883\n",
      "\n",
      "Epoch: 20 | Epoch Time: 11m 15s\n",
      "\tTraining Loss: 0.016337 \\Test Loss: 0.020810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1677\n",
      "           1       0.35      0.86      0.50       206\n",
      "\n",
      "    accuracy                           0.81      1883\n",
      "   macro avg       0.66      0.83      0.69      1883\n",
      "weighted avg       0.91      0.81      0.84      1883\n",
      "\n",
      "Epoch: 21 | Epoch Time: 12m 17s\n",
      "\tTraining Loss: 0.016335 \\Test Loss: 0.018521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1677\n",
      "           1       0.52      0.72      0.61       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.74      0.82      0.77      1883\n",
      "weighted avg       0.92      0.90      0.90      1883\n",
      "\n",
      "Epoch: 22 | Epoch Time: 12m 23s\n",
      "\tTraining Loss: 0.016585 \\Test Loss: 0.018909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.88      1677\n",
      "           1       0.34      0.87      0.49       206\n",
      "\n",
      "    accuracy                           0.80      1883\n",
      "   macro avg       0.66      0.83      0.68      1883\n",
      "weighted avg       0.91      0.80      0.83      1883\n",
      "\n",
      "Epoch: 23 | Epoch Time: 10m 57s\n",
      "\tTraining Loss: 0.015906 \\Test Loss: 0.018921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1677\n",
      "           1       0.38      0.85      0.53       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.68      0.84      0.71      1883\n",
      "weighted avg       0.91      0.83      0.86      1883\n",
      "\n",
      "Epoch: 24 | Epoch Time: 10m 39s\n",
      "\tTraining Loss: 0.015803 \\Test Loss: 0.017976\n",
      "Test loss decreased (0.018166 --> 0.017976). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      1677\n",
      "           1       0.31      0.92      0.46       206\n",
      "\n",
      "    accuracy                           0.76      1883\n",
      "   macro avg       0.65      0.83      0.65      1883\n",
      "weighted avg       0.91      0.76      0.81      1883\n",
      "\n",
      "Epoch: 25 | Epoch Time: 10m 25s\n",
      "\tTraining Loss: 0.015163 \\Test Loss: 0.020343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.91      1677\n",
      "           1       0.41      0.83      0.55       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.70      0.84      0.73      1883\n",
      "weighted avg       0.91      0.85      0.87      1883\n",
      "\n",
      "Epoch: 26 | Epoch Time: 11m 17s\n",
      "\tTraining Loss: 0.014498 \\Test Loss: 0.017898\n",
      "Test loss decreased (0.017976 --> 0.017898). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1677\n",
      "           1       0.58      0.57      0.58       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.76      0.76      1883\n",
      "weighted avg       0.91      0.91      0.91      1883\n",
      "\n",
      "Epoch: 27 | Epoch Time: 11m 8s\n",
      "\tTraining Loss: 0.015227 \\Test Loss: 0.022969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1677\n",
      "           1       0.53      0.73      0.62       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.75      0.83      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 28 | Epoch Time: 10m 45s\n",
      "\tTraining Loss: 0.014120 \\Test Loss: 0.018414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1677\n",
      "           1       0.58      0.65      0.61       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.77      0.80      0.78      1883\n",
      "weighted avg       0.91      0.91      0.91      1883\n",
      "\n",
      "Epoch: 29 | Epoch Time: 17m 6s\n",
      "\tTraining Loss: 0.014184 \\Test Loss: 0.021280\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94      1677\n",
      "           1       0.50      0.80      0.62       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.74      0.85      0.78      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 30 | Epoch Time: 11m 0s\n",
      "\tTraining Loss: 0.013925 \\Test Loss: 0.017444\n",
      "Test loss decreased (0.017898 --> 0.017444). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1677\n",
      "           1       0.56      0.68      0.61       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.76      0.81      0.78      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 31 | Epoch Time: 11m 59s\n",
      "\tTraining Loss: 0.013393 \\Test Loss: 0.019851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.93      1677\n",
      "           1       0.49      0.82      0.61       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.73      0.86      0.77      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 32 | Epoch Time: 30m 19s\n",
      "\tTraining Loss: 0.013378 \\Test Loss: 0.017361\n",
      "Test loss decreased (0.017444 --> 0.017361). Saving model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1677\n",
      "           1       0.41      0.86      0.56       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.70      0.85      0.73      1883\n",
      "weighted avg       0.92      0.85      0.87      1883\n",
      "\n",
      "Epoch: 33 | Epoch Time: 12m 33s\n",
      "\tTraining Loss: 0.013397 \\Test Loss: 0.017762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1677\n",
      "           1       0.51      0.76      0.61       206\n",
      "\n",
      "    accuracy                           0.89      1883\n",
      "   macro avg       0.74      0.84      0.77      1883\n",
      "weighted avg       0.92      0.89      0.90      1883\n",
      "\n",
      "Epoch: 34 | Epoch Time: 43m 55s\n",
      "\tTraining Loss: 0.012888 \\Test Loss: 0.017766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.90      1677\n",
      "           1       0.38      0.88      0.53       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.68      0.85      0.71      1883\n",
      "weighted avg       0.92      0.83      0.86      1883\n",
      "\n",
      "Epoch: 35 | Epoch Time: 12m 45s\n",
      "\tTraining Loss: 0.012902 \\Test Loss: 0.018459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1677\n",
      "           1       0.39      0.88      0.54       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.68      0.85      0.72      1883\n",
      "weighted avg       0.92      0.83      0.86      1883\n",
      "\n",
      "Epoch: 36 | Epoch Time: 12m 0s\n",
      "\tTraining Loss: 0.012413 \\Test Loss: 0.018230\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1677\n",
      "           1       0.43      0.84      0.57       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.70      0.85      0.74      1883\n",
      "weighted avg       0.92      0.86      0.88      1883\n",
      "\n",
      "Epoch: 37 | Epoch Time: 11m 19s\n",
      "\tTraining Loss: 0.011841 \\Test Loss: 0.018378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1677\n",
      "           1       0.55      0.70      0.62       206\n",
      "\n",
      "    accuracy                           0.90      1883\n",
      "   macro avg       0.76      0.82      0.78      1883\n",
      "weighted avg       0.92      0.90      0.91      1883\n",
      "\n",
      "Epoch: 38 | Epoch Time: 12m 43s\n",
      "\tTraining Loss: 0.013096 \\Test Loss: 0.019374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      1677\n",
      "           1       0.44      0.83      0.58       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.71      0.85      0.75      1883\n",
      "weighted avg       0.92      0.87      0.88      1883\n",
      "\n",
      "Epoch: 39 | Epoch Time: 90m 56s\n",
      "\tTraining Loss: 0.011855 \\Test Loss: 0.017639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1677\n",
      "           1       0.72      0.51      0.60       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.83      0.74      0.78      1883\n",
      "weighted avg       0.92      0.92      0.92      1883\n",
      "\n",
      "Epoch: 40 | Epoch Time: 13m 10s\n",
      "\tTraining Loss: 0.011564 \\Test Loss: 0.028233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      1677\n",
      "           1       0.44      0.86      0.58       206\n",
      "\n",
      "    accuracy                           0.87      1883\n",
      "   macro avg       0.71      0.86      0.75      1883\n",
      "weighted avg       0.92      0.87      0.88      1883\n",
      "\n",
      "Epoch: 41 | Epoch Time: 12m 29s\n",
      "\tTraining Loss: 0.011372 \\Test Loss: 0.018191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      1677\n",
      "           1       0.31      0.93      0.46       206\n",
      "\n",
      "    accuracy                           0.76      1883\n",
      "   macro avg       0.65      0.84      0.66      1883\n",
      "weighted avg       0.91      0.76      0.81      1883\n",
      "\n",
      "Epoch: 42 | Epoch Time: 13m 40s\n",
      "\tTraining Loss: 0.011652 \\Test Loss: 0.021114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.90      1677\n",
      "           1       0.38      0.90      0.53       206\n",
      "\n",
      "    accuracy                           0.83      1883\n",
      "   macro avg       0.68      0.86      0.71      1883\n",
      "weighted avg       0.92      0.83      0.86      1883\n",
      "\n",
      "Epoch: 43 | Epoch Time: 13m 54s\n",
      "\tTraining Loss: 0.011147 \\Test Loss: 0.019724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      1677\n",
      "           1       0.48      0.83      0.61       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.73      0.86      0.77      1883\n",
      "weighted avg       0.92      0.88      0.90      1883\n",
      "\n",
      "Epoch: 44 | Epoch Time: 141m 22s\n",
      "\tTraining Loss: 0.011205 \\Test Loss: 0.018226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1677\n",
      "           1       0.69      0.59      0.63       206\n",
      "\n",
      "    accuracy                           0.93      1883\n",
      "   macro avg       0.82      0.78      0.80      1883\n",
      "weighted avg       0.92      0.93      0.92      1883\n",
      "\n",
      "Epoch: 45 | Epoch Time: 13m 6s\n",
      "\tTraining Loss: 0.010703 \\Test Loss: 0.026675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1677\n",
      "           1       0.66      0.63      0.65       206\n",
      "\n",
      "    accuracy                           0.92      1883\n",
      "   macro avg       0.81      0.80      0.80      1883\n",
      "weighted avg       0.92      0.92      0.92      1883\n",
      "\n",
      "Epoch: 46 | Epoch Time: 13m 13s\n",
      "\tTraining Loss: 0.010337 \\Test Loss: 0.024862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1677\n",
      "           1       0.43      0.85      0.58       206\n",
      "\n",
      "    accuracy                           0.86      1883\n",
      "   macro avg       0.71      0.86      0.75      1883\n",
      "weighted avg       0.92      0.86      0.88      1883\n",
      "\n",
      "Epoch: 47 | Epoch Time: 13m 16s\n",
      "\tTraining Loss: 0.010617 \\Test Loss: 0.018943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1677\n",
      "           1       0.56      0.72      0.63       206\n",
      "\n",
      "    accuracy                           0.91      1883\n",
      "   macro avg       0.76      0.82      0.79      1883\n",
      "weighted avg       0.92      0.91      0.91      1883\n",
      "\n",
      "Epoch: 48 | Epoch Time: 11m 21s\n",
      "\tTraining Loss: 0.010315 \\Test Loss: 0.021868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1677\n",
      "           1       0.48      0.80      0.60       206\n",
      "\n",
      "    accuracy                           0.88      1883\n",
      "   macro avg       0.73      0.85      0.77      1883\n",
      "weighted avg       0.92      0.88      0.90      1883\n",
      "\n",
      "Epoch: 49 | Epoch Time: 37m 5s\n",
      "\tTraining Loss: 0.009970 \\Test Loss: 0.020501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1677\n",
      "           1       0.41      0.85      0.56       206\n",
      "\n",
      "    accuracy                           0.85      1883\n",
      "   macro avg       0.70      0.85      0.73      1883\n",
      "weighted avg       0.92      0.85      0.87      1883\n",
      "\n",
      "Epoch: 50 | Epoch Time: 10m 36s\n",
      "\tTraining Loss: 0.010186 \\Test Loss: 0.018730\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 75\n",
    "model_bi_lstm = Bi_LSTM_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_bi_lstm)\n",
    "\n",
    "test_min_loss = np.inf\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weight))\n",
    "optimizer = optim.Adam(model_bi_lstm.parameters(), lr=1e-3)\n",
    "    \n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model_bi_lstm.train()\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    for inputs, target in train_loader:\n",
    "        model_bi_lstm.zero_grad()\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model_bi_lstm(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    y_pred_list = []\n",
    "    y_targ_list = []\n",
    "    model_bi_lstm.eval()\n",
    "    for inputs, target in test_loader:\n",
    "        inputs = torch.squeeze(inputs, dim=1)\n",
    "        output = model_bi_lstm(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        _, y_test_pred = torch.max(output, 1)\n",
    "        y_pred_tag = y_test_pred\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        y_targ_list.append(target.cpu().numpy())\n",
    "    \n",
    "\n",
    "    if(epoch%1 == 0):\n",
    "        y_pred_list = [x.squeeze().tolist() for x in y_pred_list]\n",
    "        y_targ_list = [x.squeeze().tolist() for x in y_targ_list]\n",
    "        y_pred_list = [x for sublist in y_pred_list for x in sublist]\n",
    "        y_targ_list = [x for sublist in y_targ_list for x in sublist]\n",
    "\n",
    "        print(classification_report(y_targ_list, y_pred_list))\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\"\\tTraining Loss: {:.6f} \\Test Loss: {:.6f}\".format(train_loss, test_loss))\n",
    "    if test_loss <= test_min_loss:\n",
    "        print(\"Test loss decreased ({:.6f} --> {:.6f}). Saving model...\".format(test_min_loss, test_loss))\n",
    "        torch.save(model_bi_lstm.state_dict(), \"models_lstm_roberta/bilstm_bert_model_1_3.pt\")\n",
    "        test_min_loss = test_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762fd290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e78917e7f90f3892e7e12462ef46781cf5994bd706032ea53be00d0b1f29dcb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
