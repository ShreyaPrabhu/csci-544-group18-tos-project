{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268d41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies to run the notebook\n",
    "\n",
    "# !pip install torch==1.12.1\n",
    "# !pip install torchmetrics==0.10.2\n",
    "# !pip install torchvision==0.14.0\n",
    "# !pip install texttable==1.6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd939a",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"3\">Download the below files from https://drive.google.com/drive/folders/1q50QMurzK9a5l4JBHWjf8VuWcZkbF7PM to run this notebook : <br>\n",
    "1) train_bert_embeddings.pkl <br>\n",
    "2) test_bert_embeddings.pkl <br> </font>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fef83eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akankshanogaja/Library/Python/3.9/lib/python/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/akankshanogaja/Library/Python/3.9/lib/python/site-packages/torchvision/image.so, 0x0006): Symbol not found: (__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE)\n",
      "  Referenced from: '/Users/akankshanogaja/Library/Python/3.9/lib/python/site-packages/torchvision/image.so'\n",
      "  Expected in: '/Users/akankshanogaja/Library/Python/3.9/lib/python/site-packages/torch/lib/libtorch_cpu.dylib'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall\n",
    "from texttable import Texttable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf44010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train BERT embeddings\n",
    "with open('../../../train_bert_embeddings.pkl', 'rb') as f:\n",
    "    training_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e45b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test BERT embeddings\n",
    "with open('../../../test_bert_embeddings.pkl', 'rb') as f:\n",
    "    testing_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2bd91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is :  embeddings\n",
      "The data is :  tokenized_txt\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "for item in training_data:\n",
    "    print('The data is : ', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5dd710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content',\n",
       " 'license',\n",
       " 'and',\n",
       " 'intellectual',\n",
       " 'property',\n",
       " 'rights',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "training_data['tokenized_txt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca0767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7531, torch.Size([1, 512, 768]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data['embeddings']), training_data['embeddings'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c524e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7531, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data['tokenized_txt']) , len(training_data['tokenized_txt'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481e82e",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Get the labels from train and test files.</font>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec7097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"../legal_bert/data/tos_clauses_train.csv\"\n",
    "test_dataset_path = \"../legal_bert/data/tos_clauses_dev.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7feb1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_dataset_path, header=0)\n",
    "test_df = pd.read_csv(test_dataset_path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a29d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train_df.label.values\n",
    "test_targets = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541edf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0378fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.backends.mps.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92206a0",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Create Dataset, Train and Test Classes</font>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efaf4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \"\"\"An abstract class representing a Dataset.\n",
    "    All other datasets should subclass it. All subclasses should\n",
    "    override ``__len__``, that provides the size of the dataset,\n",
    "    and ``__getitem__``, supporting integer indexing in range\n",
    "    from 0 to len(self) exclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return ConcatDataset([self, other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb78e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Model(Dataset):\n",
    "    \n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.data1 = X\n",
    "        self.data2 = Y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data1[index]\n",
    "        y = self.data2[index]\n",
    "        \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            x = torch.tensor(x)\n",
    "            \n",
    "        return x, torch.tensor(y)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f16d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Model(Dataset):\n",
    "    \n",
    "    def __init__(self, X, transform=None):\n",
    "        self.data1 = X\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data1[index]\n",
    "                \n",
    "        if self.transform is not None:\n",
    "            x = torch.tensor(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d37e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.sampler.SubsetRandomSampler object at 0x127baaf70>\n",
      "train_fair:6705\n",
      "train_unfair:826\n"
     ]
    }
   ],
   "source": [
    "test_len = len(test_df)\n",
    "train_len = len(train_df)\n",
    "X_train_tensor = Train_Model(train_df['sentences'], train_df['label'])\n",
    "# X_test_tensor = Train_Model(test_df)\n",
    "\n",
    "num_train = len(X_train_tensor)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "# split = int(np.floor(num_train))\n",
    "# train_idx = indices[split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(indices)\n",
    "# valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "print(train_sampler)\n",
    "train_df_by_index = train_df.loc[indices]\n",
    "# val_df_by_index = df_train.loc[valid_idx]\n",
    "train_fair = sum(train_df_by_index['label'] == 0)\n",
    "train_unfair = sum(train_df_by_index['label'] == 1)\n",
    "# val_fair = sum(val_df_by_index['label'] == 0)\n",
    "# val_unfair = sum(val_df_by_index['label'] == 1)\n",
    "\n",
    "print(\"train_fair:\" + str(train_fair))\n",
    "print(\"train_unfair:\" + str(train_unfair))\n",
    "# print(\"val_fair:\" + str(val_fair))\n",
    "# print(\"val_unfair:\" + str(val_unfair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cca2a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Train_Model(training_data['embeddings'],\n",
    "                              train_targets,\n",
    "                              transform=transforms.ToTensor())\n",
    "test_data = Test_Model(testing_data['embeddings'],\n",
    "                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b7413",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"4\">Prepare Data loaders</font>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14d9572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                             batch_size=batch_size,\n",
    "                                             sampler=train_sampler,\n",
    "                                             num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36811bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([20, 1, 512, 768])\n",
      "Sample input: \n",
      " tensor([[[[-2.8706e-01,  6.1735e-01, -2.3448e-01,  ..., -9.7076e-01,\n",
      "            2.5709e-01,  1.2075e-01],\n",
      "          [-3.2604e-01,  5.5187e-01, -3.7295e-01,  ..., -9.7760e-01,\n",
      "            2.2979e-01,  1.0412e-01],\n",
      "          [-1.0446e-01,  5.7523e-01, -2.4535e-01,  ..., -1.0362e+00,\n",
      "            1.5000e-01,  1.9841e-01],\n",
      "          ...,\n",
      "          [ 1.2669e-01,  5.3392e-01,  1.1415e-01,  ..., -6.9526e-01,\n",
      "            6.3592e-01, -5.2406e-01],\n",
      "          [ 8.6486e-02,  5.2498e-01,  9.8095e-02,  ..., -7.2906e-01,\n",
      "            5.7085e-01, -5.2807e-01],\n",
      "          [ 1.0867e-01,  6.2397e-01,  6.2752e-02,  ..., -7.4564e-01,\n",
      "            4.5398e-01, -6.4892e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2182e-01,  7.8907e-01, -5.7088e-02,  ..., -1.1375e+00,\n",
      "           -1.9145e-01,  5.7700e-01],\n",
      "          [-3.8029e-01,  8.7917e-01, -1.0616e-02,  ..., -1.2875e+00,\n",
      "           -7.3494e-01,  8.6777e-01],\n",
      "          [-5.9302e-01,  9.2753e-01, -1.0195e-01,  ..., -1.3034e+00,\n",
      "           -5.5333e-01,  7.8717e-01],\n",
      "          ...,\n",
      "          [ 3.0330e-01,  5.6536e-01, -1.6562e-01,  ..., -4.3214e-01,\n",
      "            8.1307e-01, -1.0961e+00],\n",
      "          [ 2.5555e-01,  5.4820e-01, -1.6793e-01,  ..., -4.9978e-01,\n",
      "            7.7078e-01, -1.1238e+00],\n",
      "          [ 1.9612e-01,  5.9349e-01, -1.8360e-01,  ..., -4.9591e-01,\n",
      "            6.9034e-01, -1.1528e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.4605e-01,  5.6840e-01, -1.2724e-01,  ..., -8.8549e-01,\n",
      "            2.3892e-01, -4.7429e-02],\n",
      "          [-2.9836e-01,  6.5694e-01, -4.3021e-02,  ..., -7.9590e-01,\n",
      "           -4.8547e-02,  6.9820e-03],\n",
      "          [-2.4385e-01,  7.8312e-01, -1.5088e-01,  ..., -7.4042e-01,\n",
      "           -1.1205e-02, -1.8218e-01],\n",
      "          ...,\n",
      "          [ 2.4956e-01,  4.1463e-01,  1.8246e-01,  ..., -6.5354e-01,\n",
      "            6.6012e-01, -6.1819e-01],\n",
      "          [ 2.1525e-01,  3.8774e-01,  1.6804e-01,  ..., -7.0956e-01,\n",
      "            5.6460e-01, -6.4193e-01],\n",
      "          [ 2.1167e-01,  4.6714e-01,  1.5457e-01,  ..., -7.5466e-01,\n",
      "            4.2558e-01, -7.3783e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.9786e-02,  8.3233e-01, -6.3781e-01,  ..., -9.9351e-01,\n",
      "           -3.8757e-01,  5.0548e-01],\n",
      "          [-4.7386e-01,  3.7711e-01, -3.7838e-01,  ..., -1.4289e+00,\n",
      "           -3.7240e-01,  3.7340e-01],\n",
      "          [-1.9992e-01,  7.0557e-01, -5.3282e-01,  ..., -1.4644e+00,\n",
      "           -4.7029e-01,  3.5272e-01],\n",
      "          ...,\n",
      "          [ 1.7306e-01,  2.7365e-01, -4.1768e-01,  ..., -5.2757e-01,\n",
      "            1.0200e+00, -6.4414e-01],\n",
      "          [ 1.3461e-01,  2.5797e-01, -4.0978e-01,  ..., -6.0554e-01,\n",
      "            9.7331e-01, -6.7459e-01],\n",
      "          [ 9.1834e-02,  2.9253e-01, -4.4777e-01,  ..., -6.6705e-01,\n",
      "            8.5069e-01, -7.3226e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1079e-03,  6.3906e-01, -3.7075e-01,  ...,  6.1045e-02,\n",
      "            4.8204e-01, -7.0561e-01],\n",
      "          [-7.1559e-01,  8.8620e-01, -8.6314e-01,  ..., -1.0228e+00,\n",
      "           -7.8279e-02,  3.6261e-01],\n",
      "          [-7.3915e-01,  9.5906e-01, -9.6266e-01,  ..., -9.0995e-01,\n",
      "           -2.5056e-01,  5.2402e-01],\n",
      "          ...,\n",
      "          [ 2.6459e-01,  8.9010e-01, -7.3348e-01,  ..., -3.4571e-01,\n",
      "            1.0399e+00, -7.8219e-01],\n",
      "          [ 2.6262e-01,  8.7228e-01, -7.3262e-01,  ..., -4.3136e-01,\n",
      "            1.0127e+00, -8.0836e-01],\n",
      "          [ 2.4843e-01,  9.7343e-01, -7.0353e-01,  ..., -3.9096e-01,\n",
      "            9.0015e-01, -8.5546e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7553e-01,  1.3258e+00, -4.6088e-01,  ..., -1.2592e+00,\n",
      "           -6.9117e-02,  1.3243e-01],\n",
      "          [-7.6487e-01,  1.1642e+00, -7.1430e-01,  ..., -9.6146e-01,\n",
      "            3.1694e-01,  2.9812e-01],\n",
      "          [-1.0400e+00,  9.1940e-01,  1.1979e-03,  ..., -1.0822e+00,\n",
      "            8.6942e-02,  3.8960e-01],\n",
      "          ...,\n",
      "          [ 8.4763e-02,  6.5394e-01, -4.3859e-01,  ..., -2.6062e-01,\n",
      "            9.1267e-01, -7.3243e-01],\n",
      "          [ 6.1922e-02,  6.3366e-01, -4.6109e-01,  ..., -3.6773e-01,\n",
      "            8.9984e-01, -7.6298e-01],\n",
      "          [-2.3638e-02,  6.7422e-01, -5.0255e-01,  ..., -3.7825e-01,\n",
      "            7.9753e-01, -8.3936e-01]]]])\n",
      "\n",
      "Sample label size:  torch.Size([20])\n",
      "Sample label: \n",
      " tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# check sizes\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccefed",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">SIMPLE RNN</font><br>\n",
    "<font size=\"2.5\">Number of hidden dimension : 20</font> <br>\n",
    "<font size=\"2.5\">Number of layers: 1</font> <br>\n",
    "<font size=\"2.5\">Number of epochs: 5</font> <br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f35604d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(RNNet, self).__init__()\n",
    "\n",
    "         # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=1, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5c62989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNet(\n",
      "  (rnn): RNN(768, 20, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "HIDDEN_DIM = 20\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "model_rnn = RNNet(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1090e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RNN(model, train_loader, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        \n",
    "        train  = Variable(batch[0].view(-1, 512, 768))\n",
    "        labels = Variable(batch[1])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        output = model(train)\n",
    "        \n",
    "        loss = criterion(output, labels) \n",
    "        \n",
    "        acc = binary_accuracy(output.argmax(-1), labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4a1f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac0dd4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    \"\"\"\n",
    "    correct = (preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53e1f120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 22s\n",
      "\tTrain Loss:     0.672 | Train Acc: 71.82%\n",
      "Epoch: 02 | Epoch Time: 0m 16s\n",
      "\tTrain Loss:     0.653 | Train Acc: 75.35%\n",
      "Epoch: 03 | Epoch Time: 0m 15s\n",
      "\tTrain Loss:     0.642 | Train Acc: 73.78%\n",
      "Epoch: 04 | Epoch Time: 0m 16s\n",
      "\tTrain Loss:     0.640 | Train Acc: 72.45%\n",
      "Epoch: 05 | Epoch Time: 0m 18s\n",
      "\tTrain Loss:     0.638 | Train Acc: 71.45%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1/train_fair, 1/train_unfair]))\n",
    "# criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer_rnn = optim.Adam(model_rnn.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    rnn_train_loss, rnn_train_acc = train_RNN(model_rnn,\n",
    "                                      train_loader,\n",
    "                                      optimizer_rnn,\n",
    "                                      criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: \\\n",
    "    {rnn_train_loss:.3f} | Train Acc: {rnn_train_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d4ffec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple RNN : 0.7413701415061951\n",
      "F1 score of simple RNN : 0.5635073184967041\n",
      "Precision of simple RNN : 0.5633978843688965\n",
      "Recall of simple RNN : 0.6227356195449829\n"
     ]
    }
   ],
   "source": [
    "test_loader_predict = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1,\n",
    "    num_workers=0)\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        test  = Variable(batch.view(-1, 512, 768))\n",
    "        outputs = model(test)\n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        prediction_list.append(predicted.cpu())\n",
    "    return prediction_list\n",
    "\n",
    "predictions_rnn = predict(model_rnn, test_loader_predict)\n",
    "\n",
    "a_tensor = torch.IntTensor(predictions_rnn)\n",
    "b_tensor = torch.IntTensor(test_targets)\n",
    "\n",
    "accuracy = Accuracy()\n",
    "rnn_test_acc = accuracy(a_tensor, b_tensor).item()\n",
    "\n",
    "f1 = F1Score(num_classes=2, average='macro') # checked if weighted can be used\n",
    "rnn_f1_score = f1(a_tensor, b_tensor).item()\n",
    "\n",
    "precision = Precision(average='macro', num_classes=2)\n",
    "rnn_precision = precision(a_tensor, b_tensor).item()\n",
    "\n",
    "recall = Recall(average='macro', num_classes=2)\n",
    "rnn_recall = recall(a_tensor, b_tensor).item()\n",
    "\n",
    "print(\"Accuracy of simple RNN :\", rnn_test_acc)\n",
    "print(\"F1 score of simple RNN :\", rnn_f1_score)\n",
    "print(\"Precision of simple RNN :\", rnn_precision)\n",
    "print(\"Recall of simple RNN :\", rnn_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0669984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "|   Model    | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+============+================+===============+==========+===========+=========+\n",
      "| Simple RNN | 0.71450        | 0.74137       | 0.56351  | 0.56340   | 0.62274 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = Texttable()\n",
    "table.set_cols_dtype(['a','f','f','f','f','f'])\n",
    "table.set_precision(5)\n",
    "table.add_rows([[\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "                [\"Simple RNN\", rnn_train_acc, rnn_test_acc, rnn_f1_score, rnn_precision, rnn_recall]])\n",
    "print(table.draw(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe86eec",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">Gated RNN</font><br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e40ad5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(GRU_Network, self).__init__()\n",
    "\n",
    "         # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ace29e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_Network(\n",
      "  (rnn): GRU(768, 20, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_gru = GRU_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc5174a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GRU(model, train_loader, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        \n",
    "        train  = Variable(batch[0].view(-1, 512, 768))\n",
    "        labels = Variable(batch[1])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        output = model(train)\n",
    "        \n",
    "        loss = criterion(output, labels) \n",
    "        \n",
    "        acc = binary_accuracy(output.argmax(-1), labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec37270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 31s\n",
      "\tTrain Loss:     0.679 | Train Acc: 74.31%\n",
      "Epoch: 02 | Epoch Time: 0m 26s\n",
      "\tTrain Loss:     0.656 | Train Acc: 73.69%\n",
      "Epoch: 03 | Epoch Time: 0m 27s\n",
      "\tTrain Loss:     0.644 | Train Acc: 72.74%\n",
      "Epoch: 04 | Epoch Time: 0m 26s\n",
      "\tTrain Loss:     0.633 | Train Acc: 74.21%\n",
      "Epoch: 05 | Epoch Time: 0m 26s\n",
      "\tTrain Loss:     0.627 | Train Acc: 72.91%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1/train_fair, 1/train_unfair]))\n",
    "# criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer_gru = optim.Adam(model_gru.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gru_train_loss, gru_train_acc = train_RNN(model_gru,\n",
    "                                      train_loader,\n",
    "                                      optimizer_gru,\n",
    "                                      criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: \\\n",
    "    {gru_train_loss:.3f} | Train Acc: {gru_train_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d4fca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gated RNN : 0.6611789464950562\n",
      "F1 score of Gated RNN : 0.535663366317749\n",
      "Precision of Gated RNN : 0.5644705295562744\n",
      "Recall of Gated RNN : 0.6543599367141724\n"
     ]
    }
   ],
   "source": [
    "test_loader_predict = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1,\n",
    "    num_workers=0)\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        test  = Variable(batch.view(-1, 512, 768))\n",
    "        outputs = model(test)\n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        prediction_list.append(predicted.cpu())\n",
    "    return prediction_list\n",
    "\n",
    "predictions_gru = predict(model_gru, test_loader_predict)\n",
    "\n",
    "a_tensor = torch.IntTensor(predictions_gru)\n",
    "b_tensor = torch.IntTensor(test_targets)\n",
    "\n",
    "accuracy = Accuracy()\n",
    "gru_test_acc = accuracy(a_tensor, b_tensor).item()\n",
    "\n",
    "f1 = F1Score(num_classes=2, average='macro') # checked if weighted can be used\n",
    "gru_f1_score = f1(a_tensor, b_tensor).item()\n",
    "\n",
    "precision = Precision(average='macro', num_classes=2)\n",
    "gru_precision = precision(a_tensor, b_tensor).item()\n",
    "\n",
    "recall = Recall(average='macro', num_classes=2)\n",
    "gru_recall = recall(a_tensor, b_tensor).item()\n",
    "\n",
    "print(\"Accuracy of Gated RNN :\", gru_test_acc)\n",
    "print(\"F1 score of Gated RNN :\", gru_f1_score)\n",
    "print(\"Precision of Gated RNN :\", gru_precision)\n",
    "print(\"Recall of Gated RNN :\", gru_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32490444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------------+----------+-----------+---------+\n",
      "|   Model   | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+===========+================+===============+==========+===========+=========+\n",
      "| Gated RNN | 0.72912        | 0.66118       | 0.53566  | 0.56447   | 0.65436 |\n",
      "+-----------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = Texttable()\n",
    "table.set_cols_dtype(['a','f','f','f','f','f'])\n",
    "table.set_precision(5)\n",
    "table.add_rows([[\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "                [\"Gated RNN\", gru_train_acc, gru_test_acc, gru_f1_score, gru_precision, gru_recall]])\n",
    "print(table.draw(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdd129",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">LSTM</font><br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95d8d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "class LSTM_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(LSTM_Network, self).__init__()\n",
    "\n",
    "         # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "        c0 = Variable(torch.zeros(1, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # One time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e84b0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTM(model, train_loader, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        \n",
    "        train  = Variable(batch[0].view(-1, 512, 768))\n",
    "        labels = Variable(batch[1])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        output = model(train)\n",
    "        \n",
    "        loss = criterion(output, labels) \n",
    "        \n",
    "        acc = binary_accuracy(output.argmax(-1), labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05618834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Network(\n",
      "  (lstm): LSTM(768, 20, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_lstm = LSTM_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6f054f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 31s\n",
      "\tTrain Loss:     0.672 | Train Acc: 74.67%\n",
      "Epoch: 02 | Epoch Time: 0m 27s\n",
      "\tTrain Loss:     0.652 | Train Acc: 73.81%\n",
      "Epoch: 03 | Epoch Time: 0m 27s\n",
      "\tTrain Loss:     0.643 | Train Acc: 74.06%\n",
      "Epoch: 04 | Epoch Time: 0m 27s\n",
      "\tTrain Loss:     0.634 | Train Acc: 73.18%\n",
      "Epoch: 05 | Epoch Time: 0m 28s\n",
      "\tTrain Loss:     0.630 | Train Acc: 74.97%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1/train_fair, 1/train_unfair]))\n",
    "\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    lstm_train_loss, lstm_train_acc = train_LSTM(model_lstm,\n",
    "                                      train_loader,\n",
    "                                      optimizer,\n",
    "                                      criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: \\\n",
    "    {lstm_train_loss:.3f} | Train Acc: {lstm_train_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb28b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LSTM : 0.7456187009811401\n",
      "F1 score of LSTM : 0.5636465549468994\n",
      "Precision of LSTM : 0.562571108341217\n",
      "Recall of of LSTM : 0.6187337636947632\n"
     ]
    }
   ],
   "source": [
    "test_loader_predict = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        test  = Variable(batch.view(-1, 512, 768))\n",
    "        outputs = model(test)\n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        prediction_list.append(predicted.cpu())\n",
    "    return prediction_list\n",
    "\n",
    "predictions_lstm = predict(model_lstm, test_loader_predict)\n",
    "\n",
    "a_tensor = torch.IntTensor(predictions_lstm)\n",
    "b_tensor = torch.IntTensor(test_targets)\n",
    "\n",
    "accuracy = Accuracy()\n",
    "lstm_test_acc = accuracy(a_tensor, b_tensor).item()\n",
    "\n",
    "f1 = F1Score(num_classes=2, average='macro') # checked if weighted can be used\n",
    "lstm_f1_score = f1(a_tensor, b_tensor).item()\n",
    "\n",
    "precision = Precision(average='macro', num_classes=2)\n",
    "lstm_precision = precision(a_tensor, b_tensor).item()\n",
    "\n",
    "recall = Recall(average='macro', num_classes=2)\n",
    "lstm_recall = recall(a_tensor, b_tensor).item()\n",
    "\n",
    "print(\"Accuracy of LSTM :\", lstm_test_acc)\n",
    "print(\"F1 score of LSTM :\", lstm_f1_score)\n",
    "print(\"Precision of LSTM :\", lstm_precision)\n",
    "print(\"Recall of of LSTM :\", lstm_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5d21d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+---------------+----------+-----------+---------+\n",
      "| Model | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+=======+================+===============+==========+===========+=========+\n",
      "| LSTM  | 0.74970        | 0.74562       | 0.56365  | 0.56257   | 0.61873 |\n",
      "+-------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = Texttable()\n",
    "table.set_cols_dtype(['a','f','f','f','f','f'])\n",
    "table.set_precision(5)\n",
    "table.add_rows([[\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "                [\"LSTM\", lstm_train_acc, lstm_test_acc, lstm_f1_score, lstm_precision, lstm_recall]])\n",
    "print(table.draw(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cff721",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"5\">Bi-LSTM</font><br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3bcb948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "class Bi_LSTM_Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(Bi_LSTM_Network, self).__init__()\n",
    "\n",
    "         # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(1 * 2, x.size(0), self.hidden_dim))\n",
    "        c0 = Variable(torch.zeros(1 * 2, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # One time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a4693f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Bi_LSTM(model, train_loader, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        \n",
    "        train  = Variable(batch[0].view(-1, 512, 768))\n",
    "        labels = Variable(batch[1])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        output = model(train)\n",
    "        \n",
    "        loss = criterion(output, labels) \n",
    "        \n",
    "        acc = binary_accuracy(output.argmax(-1), labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24a277bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi_LSTM_Network(\n",
      "  (lstm): LSTM(768, 20, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=40, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_bi_lstm = Bi_LSTM_Network(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model_bi_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b75537cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 51s\n",
      "\tTrain Loss:     0.664 | Train Acc: 76.07%\n",
      "Epoch: 02 | Epoch Time: 0m 50s\n",
      "\tTrain Loss:     0.644 | Train Acc: 73.88%\n",
      "Epoch: 03 | Epoch Time: 0m 47s\n",
      "\tTrain Loss:     0.632 | Train Acc: 73.15%\n",
      "Epoch: 04 | Epoch Time: 0m 46s\n",
      "\tTrain Loss:     0.626 | Train Acc: 73.60%\n",
      "Epoch: 05 | Epoch Time: 0m 46s\n",
      "\tTrain Loss:     0.617 | Train Acc: 73.32%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1/train_fair, 1/train_unfair]))\n",
    "\n",
    "optimizer = optim.Adam(model_bi_lstm.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    bi_lstm_train_loss, bi_lstm_train_acc = train_Bi_LSTM(model_bi_lstm,\n",
    "                                      train_loader,\n",
    "                                      optimizer,\n",
    "                                      criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: \\\n",
    "    {bi_lstm_train_loss:.3f} | Train Acc: {bi_lstm_train_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44a07e8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LSTM : 0.759957492351532\n",
      "F1 score of LSTM : 0.5818121433258057\n",
      "Precision of LSTM : 0.5761378407478333\n",
      "Recall of of LSTM : 0.6416870951652527\n"
     ]
    }
   ],
   "source": [
    "test_loader_predict = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        test  = Variable(batch.view(-1, 512, 768))\n",
    "        outputs = model(test)\n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        prediction_list.append(predicted.cpu())\n",
    "    return prediction_list\n",
    "\n",
    "predictions_bi_lstm = predict(model_bi_lstm, test_loader_predict)\n",
    "\n",
    "a_tensor = torch.IntTensor(predictions_bi_lstm)\n",
    "b_tensor = torch.IntTensor(test_targets)\n",
    "\n",
    "accuracy = Accuracy()\n",
    "bi_lstm_test_acc = accuracy(a_tensor, b_tensor).item()\n",
    "\n",
    "f1 = F1Score(num_classes=2, average='macro') # checked if weighted can be used\n",
    "bi_lstm_f1_score = f1(a_tensor, b_tensor).item()\n",
    "\n",
    "precision = Precision(average='macro', num_classes=2)\n",
    "bi_lstm_precision = precision(a_tensor, b_tensor).item()\n",
    "\n",
    "recall = Recall(average='macro', num_classes=2)\n",
    "bi_lstm_recall = recall(a_tensor, b_tensor).item()\n",
    "\n",
    "print(\"Accuracy of LSTM :\", bi_lstm_test_acc)\n",
    "print(\"F1 score of LSTM :\", bi_lstm_f1_score)\n",
    "print(\"Precision of LSTM :\", bi_lstm_precision)\n",
    "print(\"Recall of of LSTM :\", bi_lstm_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e99372b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+----------+-----------+---------+\n",
      "|  Model  | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+=========+================+===============+==========+===========+=========+\n",
      "| Bi-LSTM | 0.73320        | 0.75996       | 0.58181  | 0.57614   | 0.64169 |\n",
      "+---------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = Texttable()\n",
    "table.set_cols_dtype(['a','f','f','f','f','f'])\n",
    "table.set_precision(5)\n",
    "table.add_rows([[\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "                [\"Bi-LSTM\", bi_lstm_train_acc, bi_lstm_test_acc, bi_lstm_f1_score, bi_lstm_precision, bi_lstm_recall]])\n",
    "print(table.draw(),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23f916ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "|   Model    | Train accuracy | Test Accuracy | F1-score | Precision | Recall  |\n",
      "+============+================+===============+==========+===========+=========+\n",
      "| Simple RNN | 0.71450        | 0.74137       | 0.56351  | 0.56340   | 0.62274 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "| Gated RNN  | 0.72912        | 0.66118       | 0.53566  | 0.56447   | 0.65436 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "| LSTM       | 0.74970        | 0.74562       | 0.56365  | 0.56257   | 0.61873 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+\n",
      "| Bi-LSTM    | 0.73320        | 0.75996       | 0.58181  | 0.57614   | 0.64169 |\n",
      "+------------+----------------+---------------+----------+-----------+---------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare all\n",
    "table = Texttable()\n",
    "table.set_cols_dtype(['a','f','f','f','f','f'])\n",
    "table.set_precision(5)\n",
    "table.add_rows([[\"Model\", \"Train accuracy\", \"Test Accuracy\", \"F1-score\", \"Precision\", \"Recall\"],\n",
    "                [\"Simple RNN\", rnn_train_acc, rnn_test_acc, rnn_f1_score, rnn_precision, rnn_recall],\n",
    "                [\"Gated RNN\", gru_train_acc, gru_test_acc, gru_f1_score, gru_precision, gru_recall],\n",
    "                [\"LSTM\", lstm_train_acc, lstm_test_acc, lstm_f1_score, lstm_precision, lstm_recall],\n",
    "                [\"Bi-LSTM\", bi_lstm_train_acc, bi_lstm_test_acc, bi_lstm_f1_score, bi_lstm_precision, bi_lstm_recall]])\n",
    "print(table.draw(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7eb4d",
   "metadata": {},
   "source": [
    "<span style=\"color:darkviolet\">\n",
    "<font size=\"3\">Best Performance : Bi-LSTM</font><br>\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
