{"cells":[{"cell_type":"markdown","metadata":{"id":"jmV9H6mqvWD9"},"source":["# Using XLNet Tokenizer and XLNet Model from Huggingface"]},{"cell_type":"markdown","metadata":{},"source":["Resources:\n","\n","- https://github.com/shanayghag/Sentiment-classification-using-XLNet/blob/master/Sentiment_Analysis_Series_part_1.ipynb\n","- https://medium.com/swlh/using-xlnet-for-sentiment-classification-cfa948e65e85\n","- https://stackoverflow.com/questions/70951556/how-to-get-pre-trained-xlnet-sentence-embeddings\n","- https://huggingface.co/xlnet-base-cased?text=My+name+is+Thomas+and+my+main\n","\n","\n","Next Steps:\n","\n","- Using XLNet Classification"]},{"cell_type":"markdown","metadata":{"id":"VxZbM6Hova5G"},"source":["# Aggregated Preprocessing Steps"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":450,"status":"ok","timestamp":1667269770868,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"mVEJFD3J5d0F"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6819,"status":"ok","timestamp":1667269777685,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"8z9-51v1vkfZ","outputId":"7d3a00af-d969-4802-894a-60c149fdc86e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: contractions in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (0.1.72)\n","Requirement already satisfied: textsearch>=0.0.21 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from contractions) (0.0.21)\n","Requirement already satisfied: pyahocorasick in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n","Requirement already satisfied: anyascii in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install contractions"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":681,"status":"ok","timestamp":1667269778359,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"nr-qJW_pvSwv"},"outputs":[],"source":["# Convert all reviews to lower case (optional according to study)\n","def to_lower(data: pd.Series):\n","    return data.str.lower()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1667269778360,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"55QDEpu44_l-"},"outputs":[],"source":["def remove_accented_characters(data: pd.Series):\n","    import unicodedata\n","\n","    \"\"\"Removes accented characters from the Series\n","\n","    Args:\n","        data (pd.Series): Series of string\n","\n","    Returns:\n","        _type_: pd.Series\n","    \"\"\"\n","    import unicodedata\n","\n","    return data.apply(lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\"))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667269778360,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"xgxvlVyH4_j4"},"outputs":[],"source":["def remove_html_encodings(data: pd.Series):\n","  return data.str.replace(r\"&#\\d+;\", \" \", regex=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778360,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"Jj_laKmv4_h0"},"outputs":[],"source":["def remove_html_tags(data: pd.Series):\n","  return data.str.replace(r\"<[a-zA-Z]+\\s?/?>\", \" \", regex=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667269778361,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"2SCBxfm54_fe"},"outputs":[],"source":["def remove_url(data: pd.Series):\n","  return data.str.replace(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \" \", regex=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778361,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"6k59XuMR4_dY"},"outputs":[],"source":["def remove_html_and_url(data: pd.Series):\n","    \"\"\"Function to remove\n","             1. HTML encodings\n","             2. HTML tags (both closed and open)\n","             3. URLs\n","\n","    Args:\n","        data (pd.Series): A Pandas series of type string\n","\n","    Returns:\n","        _type_: pd.Series\n","    \"\"\"\n","    # Remove HTML encodings\n","    data.str.replace(r\"&#\\d+;\", \" \", regex=True)\n","\n","    # Remove HTML tags (both open and closed)\n","    data.str.replace(r\"<[a-zA-Z]+\\s?/?>\", \" \", regex=True)\n","\n","    # Remove URLs\n","    data.str.replace(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \" \", regex=True)\n","\n","    return data\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778361,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"nAxCkw3Z4_bT"},"outputs":[],"source":["# Remove non-alphabetical characters\n","def remove_non_alpha_characters(data: pd.Series):\n","    return data.str.replace(r\"_+|\\\\|[^a-zA-Z0-9\\s]\", \" \", regex=True)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778362,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"oH9UdmFv5LFZ"},"outputs":[],"source":["# Remove extra spaces\n","def remove_extra_spaces(data: pd.Series):\n","    return data.str.replace(r\"^\\s*|\\s\\s*\", \" \", regex=True)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778362,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"ax3lfFii5LDV"},"outputs":[],"source":["# Expanding contractions\n","def fix_contractions(data: pd.Series):\n","    import contractions\n","\n","    def contraction_fixer(txt: str):\n","        return \" \".join([contractions.fix(word) for word in txt.split()])\n","\n","    return data.apply(contraction_fixer)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1667269778362,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"DvY0sG_X5LBN"},"outputs":[],"source":["# remove \"-lrb-\"\n","def remove_special_words(data: pd.Series):\n","  return data.str.replace(r\"\\-[^a-zA-Z]{3}\\-\", \" \", regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778363,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"MVJX0mwP5K_A"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778363,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"4crTpw3L4_ZN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667269778364,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"_PkNC2de4_XI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (0.1.97)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4108,"status":"ok","timestamp":1667269782462,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"VIX2JXAxviGT","outputId":"ba45a576-4871-457a-cf9c-dbc1e8a52df7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (4.24.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (0.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (0.10.1)\n","Requirement already satisfied: packaging>=20.0 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (2.28.1)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (2022.8.17)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (1.23.2)\n","Requirement already satisfied: filelock in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from requests->transformers) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"UtsBNBqGByOh"},"source":["### Load Data"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667269783589,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"c6kHIKwDw1H3"},"outputs":[],"source":["train_dataset_path = \"./data/tos_clauses_train.csv\"\n","test_dataset_path = \"./data/tos_clauses_dev.csv\""]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":508,"status":"ok","timestamp":1667269784093,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"6QspixPvxmPg"},"outputs":[],"source":["train_df = pd.read_csv(train_dataset_path, header=0)\n","test_df = pd.read_csv(test_dataset_path, header=0)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667269784094,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"mEBefSaI5vxl","outputId":"c999b389-8548-4271-b4bd-df15e80a0fdc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>sentences</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>content license and intellectual property rights</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>reactivated skype credit is not refundable .</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>spotify may change the price for the paid subs...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>the term of your licenses under this eula shal...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>the arbitrator may award declaratory or injunc...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                          sentences\n","0      0   content license and intellectual property rights\n","1      0       reactivated skype credit is not refundable .\n","2      1  spotify may change the price for the paid subs...\n","3      0  the term of your licenses under this eula shal...\n","4      0  the arbitrator may award declaratory or injunc..."]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"jCUaVzt5B3bl"},"source":["### Clean the Data"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24870,"status":"ok","timestamp":1667269808957,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"2jTvjwxN5q4k","outputId":"97b0fc2b-18a5-4685-9ff6-2effb2b6a2fb"},"outputs":[],"source":["# A dictionary containing the columns and a list of functions to perform on it in order\n","def cleaning(df):\n","  data_cleaning_pipeline = {\n","      \"sentences\": [\n","          to_lower,\n","          remove_special_words,\n","          remove_accented_characters,\n","          remove_html_encodings,\n","          remove_html_tags,\n","          remove_url,\n","          fix_contractions,\n","          remove_non_alpha_characters,\n","          remove_extra_spaces,\n","      ]\n","  }\n","\n","  cleaned_data = df.copy()\n","\n","  # Process all the cleaning instructions\n","  for col, pipeline in data_cleaning_pipeline.items():\n","      # Get the column to perform cleaning on\n","      temp_data = cleaned_data[col].copy()\n","\n","      # Perform all the cleaning functions sequencially\n","      for func in pipeline:\n","          print(f\"Starting: {func.__name__}\")\n","          temp_data = func(temp_data)\n","          print(f\"Ended: {func.__name__}\")\n","\n","      # Replace the old column with cleaned one.\n","      cleaned_data[col] = temp_data.copy()\n","\n","  return cleaned_data\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1667269808958,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"pPqnz5yVxn4_","outputId":"03140c2f-da0b-43d3-dfb7-6eaff9a7295e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting: to_lower\n","Ended: to_lower\n","Starting: remove_special_words\n","Ended: remove_special_words\n","Starting: remove_accented_characters\n","Ended: remove_accented_characters\n","Starting: remove_html_encodings\n","Ended: remove_html_encodings\n","Starting: remove_html_tags\n","Ended: remove_html_tags\n","Starting: remove_url\n","Ended: remove_url\n","Starting: fix_contractions\n","Ended: fix_contractions\n","Starting: remove_non_alpha_characters\n","Ended: remove_non_alpha_characters\n","Starting: remove_extra_spaces\n","Ended: remove_extra_spaces\n","Starting: to_lower\n","Ended: to_lower\n","Starting: remove_special_words\n","Ended: remove_special_words\n","Starting: remove_accented_characters\n","Ended: remove_accented_characters\n","Starting: remove_html_encodings\n","Ended: remove_html_encodings\n","Starting: remove_html_tags\n","Ended: remove_html_tags\n","Starting: remove_url\n","Ended: remove_url\n","Starting: fix_contractions\n","Ended: fix_contractions\n","Starting: remove_non_alpha_characters\n","Ended: remove_non_alpha_characters\n","Starting: remove_extra_spaces\n","Ended: remove_extra_spaces\n"]},{"data":{"text/plain":["(   label                                          sentences\n"," 0      0   content license and intellectual property rights\n"," 1      0        reactivated skype credit is not refundable \n"," 2      1   spotify may change the price for the paid sub...\n"," 3      0   the term of your licenses under this eula sha...\n"," 4      0   the arbitrator may award declaratory or injun...,\n","    label                                          sentences\n"," 0      0   uber reserves the right to withhold or deduct...\n"," 1      0   niantic s failure to enforce any right or pro...\n"," 2      0   14 3 if you feel that any member you interact...\n"," 3      0   blizzard entertainment has the right to obtai...\n"," 4      0   myfitnesspal does not lrb i rrb guarantee the...)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["train_df = cleaning(train_df)\n","test_df = cleaning(test_df)\n","\n","train_df.head(), test_df.head()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":868,"status":"ok","timestamp":1667269809815,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"RfwfN8nB6utM","outputId":"d2619bf2-a6dc-4106-c6f4-ed0b1f09921e"},"outputs":[{"data":{"text/plain":["' spotify may change the price for the paid subscriptions pre paid period lrb for periods not yet paid for rrb or codes from time to time and will communicate any price changes to you in advance and if applicable how to accept those changes '"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_df[\"sentences\"][2]"]},{"cell_type":"markdown","metadata":{"id":"sCcsbzgVB7Xb"},"source":["### Using XLNet Tokenizer and XLNet Model to get Embeddings"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2261,"status":"ok","timestamp":1667269812058,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"ipO7FNbD3fnz"},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import logging\n","import torch\n","import numpy as np\n","import warnings\n","from transformers import XLNetTokenizer, XLNetModel\n"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667269812058,"user":{"displayName":"Aditya Ashok Dave","userId":"14468981213441884031"},"user_tz":420},"id":"3dwEs6Z44PS2"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Functions"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["cls = \"[CLS]\"\n","sep = \"[SEP]\"\n","pad = \"[PAD]\"\n","max_pad_length=512"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def create_tensors_XLNET(text):\n","  \"\"\"\n","    Tokenize using BERT Tokenizer for the pd.Series\n","  \"\"\"\n","  print(\"Tokenizing text...\")\n","  logging.basicConfig(level = logging.INFO)\n","\n","  # Load the `bert-base-uncased` model\n","  tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","\n","  # Tokenize every sentence in the pd.Series\n","  tokenized_text = [tokenizer.tokenize(x) for x in text]\n","\n","  # Pad the tokens to be used for BERT Model; BERT takes fixed lengend sequence\n","  tokenized_text = [x + ([pad] * (max_pad_length - len(x))) for x in tokenized_text]\n","\n","  # Convert the tokens to their IDs\n","  indexed_text = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n","\n","  # BERTModel has Q&A format, so setting the context to one for every sentence\n","  segment_ids = [[1] * len(x) for x in tokenized_text]\n","\n","  # Convert to tensor\n","  torch_idx_text = torch.LongTensor(indexed_text)\n","  torch_seg_ids = torch.LongTensor(segment_ids)\n","  \n","  return tokenized_text, torch_idx_text, torch_seg_ids "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["#takes in the index and segment tensors and returns the bert embeddings as a list\n","def get_embeddings(torch_idx_text, torch_seg_ids):\n","    \"\"\"\n","      Create BERT embeddings from tokens\n","    \"\"\"\n","    print(\"Getting Embeddings...\")\n","\n","    # Load pretrained `bert-base-uncased` model, and set to inference\n","    model = XLNetModel.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states = True)\n","    model.eval()\n","\n","    torch_idx_text, torch_seg_ids = torch_idx_text.to(\"cpu\"), torch_seg_ids.to(\"cpu\")\n","    model.to(device)\n","\n","    # Disable gradient and get BERT embeddings\n","    with torch.no_grad():\n","        bert_embeddings = []\n","        for i in range(len(torch_idx_text)):\n","            print(i, end = \"\\r\")\n","            text_temp = torch.unsqueeze(torch_idx_text[i], dim = 0).to(device)\n","            sgmt_temp = torch.unsqueeze(torch_seg_ids[i], dim = 0).to(device)\n","            output = model(text_temp, sgmt_temp)\n","            bert_embeddings.append(output[0])\n","            del text_temp, sgmt_temp\n","    del model\n","  \n","    return bert_embeddings\n"]},{"cell_type":"markdown","metadata":{"id":"l-47_yioCIYR"},"source":["### Tokenize and Create Embeddings"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenizing text...\n","Tokenizing text...\n"]}],"source":["train_tokenized_text, train_torch_idx_text, train_torch_seg_ids = create_tensors_XLNET(train_df.sentences)\n","test_tokenized_text, test_torch_idx_text, test_torch_seg_ids = create_tensors_XLNET(test_df.sentences)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Getting Embeddings...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Getting Embeddings...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["1882\r"]}],"source":["train_xlnet_embeddings = get_embeddings(train_torch_idx_text, train_torch_seg_ids)\n","test_xlnet_embeddings = get_embeddings(test_torch_idx_text, test_torch_seg_ids)\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["train_xlnet_embeddings = torch.cat(train_xlnet_embeddings)\n","test_xlnet_embeddings = torch.cat(test_xlnet_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle as pkl\n","train_embeddings_file_path = \"./embeddings/train_xlnet_embeddings.pkl\"\n","test_embeddings_file_path = \"./embeddings/test_xlnet_embeddings.pkl\"\n","\n","def save_embeddings(embeddings_file_path, embeddings):\n","  with open(embeddings_file_path, mode=\"wb\") as file:\n","    pkl.dump({\"embeddings\": embeddings}, file, protocol=pkl.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_embeddings(train_embeddings_file_path, train_xlnet_embeddings)\n","save_embeddings(test_embeddings_file_path, test_xlnet_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOc+htn8Uy0hVIj5B2XsCMZ","collapsed_sections":[],"mount_file_id":"19OZi3COrM1wJnuYgifQAA5bZmnfbzuce","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.6 64-bit ('csci544')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e78917e7f90f3892e7e12462ef46781cf5994bd706032ea53be00d0b1f29dcb9"}}},"nbformat":4,"nbformat_minor":0}
